{"posts": {"1745467853799874969": {"created_at": "Thu Jan 11 15:29:00 +0000 2024", "entities": [{"indices": [0, 278], "type": "text", "text": "5 Levels Of Text Splitting: Semantic Splitting\n\nGoal: Use embeddings to find chunks in our raw text\n\nExperimental method using embedding distances between sequential sentences to tease out 'breakpoints'\n\nIf we find a good breakpoint, make a chunk\n\nCheck out the full video on YT"}], "favorite_count": 409, "id_str": "1745467853799874969", "lang": "en", "mediaDetails": [{"additional_media_info": {"description": "", "embeddable": true, "monetizable": false, "title": ""}, "allow_download_status": {"allow_download": false}, "display_url": "pic.x.com/fb1FlBKTNn", "expanded_url": "https://x.com/GregKamradt/status/1745467853799874969/video/1", "ext_media_availability": {"status": "Available"}, "id_str": "1745241380958724096", "indices": [279, 302], "media_key": "13_1745241380958724096", "media_results": {"result": {"media_key": "13_1745241380958724096"}}, "media_url_https": "https://pbs.twimg.com/media/GDkLvwpagAA_5IT.jpg", "original_info": {"focus_rects": [], "height": 720, "width": 1280}, "sizes": {"large": {"h": 720, "resize": "fit", "w": 1280}, "medium": {"h": 675, "resize": "fit", "w": 1200}, "small": {"h": 383, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "video", "url": "https://t.co/fb1FlBKTNn", "video_info": {"aspect_ratio": [16, 9], "duration_millis": 82282, "variants": [{"content_type": "application/x-mpegURL", "url": "https://video.twimg.com/amplify_video/1745241380958724096/pl/SOnarz249iW1huKZ.m3u8?tag=14&v=da9"}, {"bitrate": 288000, "content_type": "video/mp4", "url": "https://video.twimg.com/amplify_video/1745241380958724096/vid/avc1/480x270/4K0YNrGzqjli4P9m.mp4?tag=14"}, {"bitrate": 832000, "content_type": "video/mp4", "url": "https://video.twimg.com/amplify_video/1745241380958724096/vid/avc1/640x360/UCJN8ob38xkJBaB6.mp4?tag=14"}, {"bitrate": 2176000, "content_type": "video/mp4", "url": "https://video.twimg.com/amplify_video/1745241380958724096/vid/avc1/1280x720/nBuI4RJ6qr8T8300.mp4?tag=14"}]}}], "user": {"id_str": "240008974", "name": "Greg Kamradt", "screen_name": "GregKamradt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1467896309453570052/BGy5XYVQ_normal.jpg", "description": "President @arcprize \u2014Founder https://t.co/XK3ITFuCZe \u2014builder/engineer", "entities": {"description": {"urls": [{"display_url": "leverage.to", "expanded_url": "https://www.leverage.to/", "indices": [29, 52], "url": "https://t.co/XK3ITFuCZe"}]}, "url": {"urls": [{"display_url": "gregkamradt.com", "expanded_url": "http://gregkamradt.com", "indices": [0, 23], "url": "https://t.co/TSzx2cCdlg"}]}}, "followers_count": 35888, "location": "San Francisco, CA", "url": "https://x.com/GregKamradt", "follow_url": "https://x.com/intent/follow?screen_name=GregKamradt"}, "url": "https://x.com/GregKamradt/status/1745467853799874969", "like_url": "https://x.com/intent/like?tweet_id=1745467853799874969", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745467853799874969", "replies": ["1745468922881769694", "1745849057099026671", "1745470105855885505", "1745473899674874180", "1745527854925013208", "1745516983431405794", "1745688440510013592", "1745937357189128698", "1747511842921156853", "1745492400389120160", "1745617254144692439", "1745521654045008102", "1761535865589756084", "1745494014546116745", "1745481883318689872", "1745762308926660712", "1745508635734892812", "1745573979065115087", "1745606089486336007", "1745616592363540710", "1745677374266687784", "1745488073608085994", "1745573771048886544", "1745745517831983386", "1745817369178747041"], "score": 0, "thread_score": 0, "reply_count": 37, "is_branch": true}, "1745468922881769694": {"created_at": "Thu Jan 11 15:33:15 +0000 2024", "entities": [{"indices": [0, 12], "type": "text", "text": "Full Video: "}, {"display_url": "youtube.com/watch?v=8OJC21\u2026", "expanded_url": "https://www.youtube.com/watch?v=8OJC21T2SL4", "indices": [12, 35], "url": "https://t.co/ScIAzkKdBc", "type": "url", "href": "https://www.youtube.com/watch?v=8OJC21T2SL4", "text": "youtube.com/watch?v=8OJC21\u2026"}, {"indices": [35, 44], "type": "text", "text": "\n\nCode @ "}, {"display_url": "FullStackRetrieval.com", "expanded_url": "http://FullStackRetrieval.com", "indices": [44, 67], "url": "https://t.co/tIgu1CCf5H", "type": "url", "href": "http://FullStackRetrieval.com", "text": "FullStackRetrieval.com"}], "favorite_count": 22, "id_str": "1745468922881769694", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "240008974", "name": "Greg Kamradt", "screen_name": "GregKamradt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1467896309453570052/BGy5XYVQ_normal.jpg", "description": "President @arcprize \u2014Founder https://t.co/XK3ITFuCZe \u2014builder/engineer", "entities": {"description": {"urls": [{"display_url": "leverage.to", "expanded_url": "https://www.leverage.to/", "indices": [29, 52], "url": "https://t.co/XK3ITFuCZe"}]}, "url": {"urls": [{"display_url": "gregkamradt.com", "expanded_url": "http://gregkamradt.com", "indices": [0, 23], "url": "https://t.co/TSzx2cCdlg"}]}}, "followers_count": 35888, "location": "San Francisco, CA", "url": "https://x.com/GregKamradt", "follow_url": "https://x.com/intent/follow?screen_name=GregKamradt"}, "url": "https://x.com/GregKamradt/status/1745468922881769694", "like_url": "https://x.com/intent/like?tweet_id=1745468922881769694", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745468922881769694", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745470105855885505": {"created_at": "Thu Jan 11 15:37:57 +0000 2024", "entities": [{"indices": [0, 3], "type": "text", "text": "cc "}, {"id_str": "30439303", "indices": [3, 17], "name": "Yohei", "screen_name": "yoheinakajima", "type": "mention", "href": "https://x.com/yoheinakajima", "text": "@yoheinakajima"}, {"indices": [17, 159], "type": "text", "text": " here is the video overview of the process tagged you on last month.\n\nUsing embeddings distances to determine where chunk boundaries should be"}], "favorite_count": 2, "id_str": "1745470105855885505", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "240008974", "name": "Greg Kamradt", "screen_name": "GregKamradt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1467896309453570052/BGy5XYVQ_normal.jpg", "description": "President @arcprize \u2014Founder https://t.co/XK3ITFuCZe \u2014builder/engineer", "entities": {"description": {"urls": [{"display_url": "leverage.to", "expanded_url": "https://www.leverage.to/", "indices": [29, 52], "url": "https://t.co/XK3ITFuCZe"}]}, "url": {"urls": [{"display_url": "gregkamradt.com", "expanded_url": "http://gregkamradt.com", "indices": [0, 23], "url": "https://t.co/TSzx2cCdlg"}]}}, "followers_count": 35888, "location": "San Francisco, CA", "url": "https://x.com/GregKamradt", "follow_url": "https://x.com/intent/follow?screen_name=GregKamradt"}, "url": "https://x.com/GregKamradt/status/1745470105855885505", "like_url": "https://x.com/intent/like?tweet_id=1745470105855885505", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745470105855885505", "replies": ["1745522498807194086", "1745584901334737274"], "score": 0, "thread_score": 0, "reply_count": 2}, "1745473899674874180": {"created_at": "Thu Jan 11 15:53:01 +0000 2024", "entities": [{"indices": [13, 30], "type": "text", "text": "awesome vid Greg!"}], "favorite_count": 1, "id_str": "1745473899674874180", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "1058802033757691905", "name": "Nicolas Camara", "screen_name": "nickscamara_", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1599993355089465344/R6Al_s_H_normal.jpg", "description": "co-founder @firecrawl_dev \ud83d\udd25 - yc s22 prev built Mendable (AI docs chat used by Snap, Coinbase, MongoDB)", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "firecrawl.dev", "expanded_url": "https://firecrawl.dev", "indices": [0, 23], "url": "https://t.co/MJYdMcfTFH"}]}}, "followers_count": 5863, "location": "San Francisco", "url": "https://x.com/nickscamara_", "follow_url": "https://x.com/intent/follow?screen_name=nickscamara_"}, "url": "https://x.com/nickscamara_/status/1745473899674874180", "like_url": "https://x.com/intent/like?tweet_id=1745473899674874180", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745473899674874180", "replies": ["1745474830135423051"], "score": 0, "thread_score": 0, "reply_count": 1}, "1745474830135423051": {"created_at": "Thu Jan 11 15:56:43 +0000 2024", "entities": [{"indices": [14, 25], "type": "text", "text": "Thanks Nick"}], "favorite_count": 1, "id_str": "1745474830135423051", "in_reply_to_status_id_str": "1745473899674874180", "lang": "en", "user": {"id_str": "240008974", "name": "Greg Kamradt", "screen_name": "GregKamradt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1467896309453570052/BGy5XYVQ_normal.jpg", "description": "President @arcprize \u2014Founder https://t.co/XK3ITFuCZe \u2014builder/engineer", "entities": {"description": {"urls": [{"display_url": "leverage.to", "expanded_url": "https://www.leverage.to/", "indices": [29, 52], "url": "https://t.co/XK3ITFuCZe"}]}, "url": {"urls": [{"display_url": "gregkamradt.com", "expanded_url": "http://gregkamradt.com", "indices": [0, 23], "url": "https://t.co/TSzx2cCdlg"}]}}, "followers_count": 35889, "location": "San Francisco, CA", "url": "https://x.com/GregKamradt", "follow_url": "https://x.com/intent/follow?screen_name=GregKamradt"}, "url": "https://x.com/GregKamradt/status/1745474830135423051", "like_url": "https://x.com/intent/like?tweet_id=1745474830135423051", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745474830135423051", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745481883318689872": {"created_at": "Thu Jan 11 16:24:45 +0000 2024", "entities": [{"indices": [24, 291], "type": "text", "text": "The problem is that most sentence embedding similarities (like cosine similarity) return very high values even for not very similar sentences. Second the sentence similarity is not robustly monotonic, and sometimes similar (in human perception) returns smaller number"}], "favorite_count": 2, "id_str": "1745481883318689872", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "3438654916", "name": "Fred", "screen_name": "newplatonism", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1217476505581883394/dUQEib2H_normal.jpg", "description": "scientist by training with interests in AI, QC, and Philosophy. Movie critique, linguistic enthusiast, and full-time humanitarian, against wars and sanctions", "entities": {"description": {"urls": []}}, "followers_count": 771, "location": "EARTH", "url": "https://x.com/newplatonism", "follow_url": "https://x.com/intent/follow?screen_name=newplatonism"}, "url": "https://x.com/newplatonism/status/1745481883318689872", "like_url": "https://x.com/intent/like?tweet_id=1745481883318689872", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745481883318689872", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745488073608085994": {"created_at": "Thu Jan 11 16:49:21 +0000 2024", "entities": [{"indices": [26, 73], "type": "text", "text": "How is the distance between sentences measured?"}], "favorite_count": 0, "id_str": "1745488073608085994", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "1648778059519082500", "name": "Celestin Eiffel", "screen_name": "CelestinEiffel", "profile_image_url_https": "https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png", "description": "", "entities": {"description": {"urls": []}}, "followers_count": 93, "location": "", "url": "https://x.com/CelestinEiffel", "follow_url": "https://x.com/intent/follow?screen_name=CelestinEiffel"}, "url": "https://x.com/CelestinEiffel/status/1745488073608085994", "like_url": "https://x.com/intent/like?tweet_id=1745488073608085994", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745488073608085994", "replies": ["1745659179644178880"], "score": 0, "thread_score": 0, "reply_count": 1}, "1745492400389120160": {"created_at": "Thu Jan 11 17:06:32 +0000 2024", "entities": [{"indices": [13, 67], "type": "text", "text": "Embedding-driven chunking is a really clever approach!"}], "favorite_count": 3, "id_str": "1745492400389120160", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "137086701", "name": "virat", "screen_name": "virattt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1237964548704841736/iai1MNLE_normal.jpg", "description": "playing with gen ai + finance", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "financialdatasets.ai", "expanded_url": "https://www.financialdatasets.ai/", "indices": [0, 23], "url": "https://t.co/ZTELBmcX06"}]}}, "followers_count": 28106, "location": "New York, NY", "url": "https://x.com/virattt", "follow_url": "https://x.com/intent/follow?screen_name=virattt"}, "url": "https://x.com/virattt/status/1745492400389120160", "like_url": "https://x.com/intent/like?tweet_id=1745492400389120160", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745492400389120160", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745494014546116745": {"created_at": "Thu Jan 11 17:12:57 +0000 2024", "entities": [{"indices": [13, 34], "type": "text", "text": "I want to go level 11"}], "favorite_count": 3, "id_str": "1745494014546116745", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/TBajxSA5ZT", "expanded_url": "https://x.com/GianPaJ/status/1745494014546116745/photo/1", "ext_alt_text": "Spinal Tap Eleven GIF", "ext_media_availability": {"status": "Available"}, "id_str": "1745494007172468736", "indices": [35, 58], "media_key": "16_1745494007172468736", "media_results": {"result": {"media_key": "16_1745494007172468736"}}, "media_url_https": "https://pbs.twimg.com/tweet_video_thumb/GDk9jS8WkAAEGYt.jpg", "original_info": {"focus_rects": [], "height": 164, "width": 220}, "sizes": {"large": {"h": 164, "resize": "fit", "w": 220}, "medium": {"h": 164, "resize": "fit", "w": 220}, "small": {"h": 164, "resize": "fit", "w": 220}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "animated_gif", "url": "https://t.co/TBajxSA5ZT", "video_info": {"aspect_ratio": [55, 41], "variants": [{"bitrate": 0, "content_type": "video/mp4", "url": "https://video.twimg.com/tweet_video/GDk9jS8WkAAEGYt.mp4"}]}}], "user": {"id_str": "11922322", "name": "Gianfranco P.", "screen_name": "GianPaJ", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1771251611907641344/qD46Uhwo_normal.jpg", "description": "Software developer mentor for the next generation of developers.\n\n\ud83c\udf1e Learn how to code with 1on1 classes at @escuela_dev_ \u2013 online, in M\u00e1laga or Madrid", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "escuela.dev", "expanded_url": "https://escuela.dev", "indices": [0, 23], "url": "https://t.co/3unbus4hTN"}]}}, "followers_count": 1133, "location": "M\u00e1laga", "url": "https://x.com/GianPaJ", "follow_url": "https://x.com/intent/follow?screen_name=GianPaJ"}, "url": "https://x.com/GianPaJ/status/1745494014546116745", "like_url": "https://x.com/intent/like?tweet_id=1745494014546116745", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745494014546116745", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745508635734892812": {"created_at": "Thu Jan 11 18:11:03 +0000 2024", "entities": [{"indices": [13, 115], "type": "text", "text": "This smart chunking strategy can potential improve RAG production solutions. Can't wait to try it out."}], "favorite_count": 1, "id_str": "1745508635734892812", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "722253451854385156", "name": "Trung Le", "screen_name": "trung_rta", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1500021099429462018/bOnjw11l_normal.jpg", "description": "https://t.co/V6Q9nFG7Uq transforming customer engagement\n\nhttps://t.co/1VUPUHJqAh Keep data entry away", "entities": {"description": {"urls": [{"display_url": "aichat.realtimex.co", "expanded_url": "https://aichat.realtimex.co", "indices": [0, 23], "url": "https://t.co/V6Q9nFG7Uq"}, {"display_url": "keepy.us", "expanded_url": "https://keepy.us/", "indices": [58, 81], "url": "https://t.co/1VUPUHJqAh"}]}, "url": {"urls": [{"display_url": "aichat.realtimex.co", "expanded_url": "https://aichat.realtimex.co", "indices": [0, 23], "url": "https://t.co/V6Q9nFG7Uq"}]}}, "followers_count": 233, "location": "Bay Area", "url": "https://x.com/trung_rta", "follow_url": "https://x.com/intent/follow?screen_name=trung_rta"}, "url": "https://x.com/trung_rta/status/1745508635734892812", "like_url": "https://x.com/intent/like?tweet_id=1745508635734892812", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745508635734892812", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745516983431405794": {"created_at": "Thu Jan 11 18:44:13 +0000 2024", "entities": [{"indices": [13, 71], "type": "text", "text": "Did you ever try the hyper param free clustering approach?"}], "favorite_count": 0, "id_str": "1745516983431405794", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "1118579966", "name": "Nikhil Thorat", "screen_name": "nsthorat", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1237008898311282690/QL1p2OgT_normal.jpg", "description": "AI quality at Databricks. Co-founder of Lilac AI (acquired by @databricks). Co-created TensorFlow.js and Know Your Data @ Google Brain", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "nikubaba.com", "expanded_url": "https://nikubaba.com", "indices": [0, 23], "url": "https://t.co/OaCoCa9qCd"}]}}, "followers_count": 9416, "location": "Boston, MA", "url": "https://x.com/nsthorat", "follow_url": "https://x.com/intent/follow?screen_name=nsthorat"}, "url": "https://x.com/nsthorat/status/1745516983431405794", "like_url": "https://x.com/intent/like?tweet_id=1745516983431405794", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745516983431405794", "replies": ["1745518759421579528"], "score": 0, "thread_score": 0, "reply_count": 1}, "1745518759421579528": {"created_at": "Thu Jan 11 18:51:17 +0000 2024", "entities": [{"indices": [10, 223], "type": "text", "text": "yeah - specifically hierarchical clustering but w/ a custom positional reward (so sentences closer together would get grouped) and it was so-so.\n\nLot's of tinkering without results so I tried a different approach."}], "favorite_count": 3, "id_str": "1745518759421579528", "in_reply_to_status_id_str": "1745516983431405794", "lang": "en", "user": {"id_str": "240008974", "name": "Greg Kamradt", "screen_name": "GregKamradt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1467896309453570052/BGy5XYVQ_normal.jpg", "description": "President @arcprize \u2014Founder https://t.co/XK3ITFuCZe \u2014builder/engineer", "entities": {"description": {"urls": [{"display_url": "leverage.to", "expanded_url": "https://www.leverage.to/", "indices": [29, 52], "url": "https://t.co/XK3ITFuCZe"}]}, "url": {"urls": [{"display_url": "gregkamradt.com", "expanded_url": "http://gregkamradt.com", "indices": [0, 23], "url": "https://t.co/TSzx2cCdlg"}]}}, "followers_count": 35888, "location": "San Francisco, CA", "url": "https://x.com/GregKamradt", "follow_url": "https://x.com/intent/follow?screen_name=GregKamradt"}, "url": "https://x.com/GregKamradt/status/1745518759421579528", "like_url": "https://x.com/intent/like?tweet_id=1745518759421579528", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745518759421579528", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745521654045008102": {"created_at": "Thu Jan 11 19:02:47 +0000 2024", "entities": [{"indices": [13, 35], "type": "text", "text": "Super important stuff!"}], "favorite_count": 0, "id_str": "1745521654045008102", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "1030591494506217473", "name": "Jason Staats\u26a1", "screen_name": "tryjasononline", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1832368072629313536/cUD6MXHm_normal.jpg", "description": "I make helpful things for productive people. Entrepreneur, SAAS founder & exiter, community runner, CPA, advisor and speaker", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "tryjasononline.com", "expanded_url": "https://www.tryjasononline.com/", "indices": [0, 23], "url": "https://t.co/8B2RyAjIKs"}]}}, "followers_count": 25598, "location": "New York", "url": "https://x.com/tryjasononline", "follow_url": "https://x.com/intent/follow?screen_name=tryjasononline"}, "url": "https://x.com/tryjasononline/status/1745521654045008102", "like_url": "https://x.com/intent/like?tweet_id=1745521654045008102", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745521654045008102", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745522498807194086": {"created_at": "Thu Jan 11 19:06:08 +0000 2024", "entities": [{"indices": [13, 96], "type": "text", "text": "Thx for sharing, the video is great (and nice visualization to really make it easy)"}], "favorite_count": 1, "id_str": "1745522498807194086", "in_reply_to_status_id_str": "1745470105855885505", "lang": "en", "user": {"id_str": "30439303", "name": "Yohei", "screen_name": "yoheinakajima", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1452754543217831938/T2O-66Yy_normal.jpg", "description": "VC by day @untappedvc, builder by night: @babyagi_, @pippinlovesyou @pixelbeastsnft. Build-in-public log: https://t.co/UdHHGbZba5", "entities": {"description": {"urls": [{"display_url": "yohei.me", "expanded_url": "http://yohei.me", "indices": [106, 129], "url": "https://t.co/UdHHGbZba5"}]}, "url": {"urls": [{"display_url": "yoheinakajima.com", "expanded_url": "https://yoheinakajima.com/", "indices": [0, 23], "url": "https://t.co/wG5wLHN4Nj"}]}}, "followers_count": 105801, "location": "Seattle, WA", "url": "https://x.com/yoheinakajima", "follow_url": "https://x.com/intent/follow?screen_name=yoheinakajima"}, "url": "https://x.com/yoheinakajima/status/1745522498807194086", "like_url": "https://x.com/intent/like?tweet_id=1745522498807194086", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745522498807194086", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745527854925013208": {"created_at": "Thu Jan 11 19:27:25 +0000 2024", "entities": [{"indices": [13, 160], "type": "text", "text": "holy hell, this is expensive af but probably very close to the optimal way of doing this \n\nthere are so many variations of this that could work too"}], "favorite_count": 1, "id_str": "1745527854925013208", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "1556351406277361667", "name": "Nick Khami", "screen_name": "skeptrune", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1878472843748401152/Iq5jyKga_normal.jpg", "description": "Helping with Search, Recommendations, and RAG @trieveai\n\nhttps://t.co/4Fr3Gbk8eY\n@FUTO_Tech Fellow (S23)\nYC (W24)", "entities": {"description": {"urls": [{"display_url": "github.com/skeptrunedev", "expanded_url": "http://github.com/skeptrunedev", "indices": [57, 80], "url": "https://t.co/4Fr3Gbk8eY"}]}, "url": {"urls": [{"display_url": "trieve.ai", "expanded_url": "https://trieve.ai", "indices": [0, 23], "url": "https://t.co/tgyih6aeFv"}]}}, "followers_count": 1292, "location": "San Francisco, CA", "url": "https://x.com/skeptrune", "follow_url": "https://x.com/intent/follow?screen_name=skeptrune"}, "url": "https://x.com/skeptrune/status/1745527854925013208", "like_url": "https://x.com/intent/like?tweet_id=1745527854925013208", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745527854925013208", "replies": ["1745528435190173868"], "score": 0, "thread_score": 0, "reply_count": 5}, "1745528435190173868": {"created_at": "Thu Jan 11 19:29:43 +0000 2024", "entities": [{"indices": [11, 243], "type": "text", "text": "It's actually not *that* expensive since it's just embeddings.\n\nI'm teasing level 5 tomorrow which is agentic chunking. Agent goes through your text to see what should be part of a chunk and what shouldn't.\n\nThat one is expensive ha"}], "favorite_count": 7, "id_str": "1745528435190173868", "in_reply_to_status_id_str": "1745527854925013208", "lang": "en", "user": {"id_str": "240008974", "name": "Greg Kamradt", "screen_name": "GregKamradt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1467896309453570052/BGy5XYVQ_normal.jpg", "description": "President @arcprize \u2014Founder https://t.co/XK3ITFuCZe \u2014builder/engineer", "entities": {"description": {"urls": [{"display_url": "leverage.to", "expanded_url": "https://www.leverage.to/", "indices": [29, 52], "url": "https://t.co/XK3ITFuCZe"}]}, "url": {"urls": [{"display_url": "gregkamradt.com", "expanded_url": "http://gregkamradt.com", "indices": [0, 23], "url": "https://t.co/TSzx2cCdlg"}]}}, "followers_count": 35888, "location": "San Francisco, CA", "url": "https://x.com/GregKamradt", "follow_url": "https://x.com/intent/follow?screen_name=GregKamradt"}, "url": "https://x.com/GregKamradt/status/1745528435190173868", "like_url": "https://x.com/intent/like?tweet_id=1745528435190173868", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745528435190173868", "replies": ["1745528774668750915", "1745530021027176961"], "score": 0, "thread_score": 0, "reply_count": 4}, "1745528774668750915": {"created_at": "Thu Jan 11 19:31:04 +0000 2024", "entities": [{"indices": [13, 276], "type": "text", "text": "i mean if you are doing things like duplicate detection and or text extraction from HTML already on your create route for a chunk then you're already at 1+ seconds for the write\n\nif you add this then you are basically forced to do a queue implementation on ingest"}], "favorite_count": 1, "id_str": "1745528774668750915", "in_reply_to_status_id_str": "1745528435190173868", "lang": "en", "user": {"id_str": "1556351406277361667", "name": "Nick Khami", "screen_name": "skeptrune", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1878472843748401152/Iq5jyKga_normal.jpg", "description": "Helping with Search, Recommendations, and RAG @trieveai\n\nhttps://t.co/4Fr3Gbk8eY\n@FUTO_Tech Fellow (S23)\nYC (W24)", "entities": {"description": {"urls": [{"display_url": "github.com/skeptrunedev", "expanded_url": "http://github.com/skeptrunedev", "indices": [57, 80], "url": "https://t.co/4Fr3Gbk8eY"}]}, "url": {"urls": [{"display_url": "trieve.ai", "expanded_url": "https://trieve.ai", "indices": [0, 23], "url": "https://t.co/tgyih6aeFv"}]}}, "followers_count": 1292, "location": "San Francisco, CA", "url": "https://x.com/skeptrune", "follow_url": "https://x.com/intent/follow?screen_name=skeptrune"}, "url": "https://x.com/skeptrune/status/1745528774668750915", "like_url": "https://x.com/intent/like?tweet_id=1745528774668750915", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745528774668750915", "replies": ["1745902999942181324"], "score": 0, "thread_score": 0, "reply_count": 2}, "1745530021027176961": {"created_at": "Thu Jan 11 19:36:02 +0000 2024", "entities": [{"indices": [24, 76], "type": "text", "text": "The expensive part comes in just the time for ingest"}], "favorite_count": 1, "id_str": "1745530021027176961", "in_reply_to_status_id_str": "1745528435190173868", "lang": "en", "user": {"id_str": "1054494229085478912", "name": "cdxker", "screen_name": "cdxker", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1801767440105541633/Mv-__R1h_normal.jpg", "description": "Product Engineer and founder @trieveai\n\nWhen self-reference, irony, and meta-humor go too far https://t.co/DzNTRgV1kg", "entities": {"description": {"urls": [{"display_url": "xkcd.com/6", "expanded_url": "http://xkcd.com/6", "indices": [94, 117], "url": "https://t.co/DzNTRgV1kg"}]}}, "followers_count": 174, "location": "https://github.com/cdxker", "url": "https://x.com/cdxker", "follow_url": "https://x.com/intent/follow?screen_name=cdxker"}, "url": "https://x.com/cdxker/status/1745530021027176961", "like_url": "https://x.com/intent/like?tweet_id=1745530021027176961", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745530021027176961", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745573771048886544": {"created_at": "Thu Jan 11 22:29:52 +0000 2024", "entities": [{"indices": [13, 28], "type": "text", "text": "you might like "}, {"display_url": "phext.io", "expanded_url": "http://phext.io", "indices": [28, 51], "url": "https://t.co/3HxlysQ2Dx", "type": "url", "href": "http://phext.io", "text": "phext.io"}, {"indices": [51, 110], "type": "text", "text": " - i'm building out tooling for what i call plain hypertext"}], "favorite_count": 0, "id_str": "1745573771048886544", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "15250344", "name": "will (exo/acc) \ud83e\udd99", "screen_name": "wbic16", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1843863925017751552/H1H2Z8_s_normal.jpg", "description": "I'm From the Exocortex, and I'm Here to Help. Orbiting You.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "phext.io", "expanded_url": "http://phext.io/", "indices": [0, 23], "url": "https://t.co/KU67bjqHJJ"}]}}, "followers_count": 1714, "location": "59.99.11/59.19.19/95.99.1", "url": "https://x.com/wbic16", "follow_url": "https://x.com/intent/follow?screen_name=wbic16"}, "url": "https://x.com/wbic16/status/1745573771048886544", "like_url": "https://x.com/intent/like?tweet_id=1745573771048886544", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745573771048886544", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745573979065115087": {"created_at": "Thu Jan 11 22:30:42 +0000 2024", "entities": [{"indices": [13, 293], "type": "text", "text": "wow, I'm just working on word level splitting to hierarchically concatenate text and that was a really nice review and comparison\nit has so much content that it could be easily 4 separate videos but I'm happy it wasn't ;)\nLLM have so many ways to add info about what to join/split"}], "favorite_count": 1, "id_str": "1745573979065115087", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "1347789200", "name": "Rudzinski Maciej", "screen_name": "rudzinskimaciej", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1673799792537788418/irZcc_QW_normal.jpg", "description": "Stealth Neuro+AI startup\nmechanistic genAI + BCI\nex: wearables, stats algorithms design, dynamical social science, explainable ML", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "youtube.com/channel/UCcfA-\u2026", "expanded_url": "https://www.youtube.com/channel/UCcfA-53czVOPOTGGzvSUZTw", "indices": [0, 23], "url": "https://t.co/eueoBboZ7K"}]}}, "followers_count": 1384, "location": "Poland", "url": "https://x.com/rudzinskimaciej", "follow_url": "https://x.com/intent/follow?screen_name=rudzinskimaciej"}, "url": "https://x.com/rudzinskimaciej/status/1745573979065115087", "like_url": "https://x.com/intent/like?tweet_id=1745573979065115087", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745573979065115087", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745584901334737274": {"created_at": "Thu Jan 11 23:14:06 +0000 2024", "entities": [{"indices": [28, 75], "type": "text", "text": "I have a theory \ud83d\udee4\ufe0f\ud83e\uddf0\ud83d\ude80 to build better tools \ud83d\udee0\ufe0f \ud83e\uddf0"}], "favorite_count": 0, "id_str": "1745584901334737274", "in_reply_to_status_id_str": "1745470105855885505", "lang": "en", "user": {"id_str": "1732071117798404096", "name": "tbt\ud83d\ude80", "screen_name": "TechBroTino", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1896274042228744192/envwabTU_normal.jpg", "description": "but nothing \ud83d\ude43", "entities": {"description": {"urls": []}}, "followers_count": 649, "location": "VA, USA", "url": "https://x.com/TechBroTino", "follow_url": "https://x.com/intent/follow?screen_name=TechBroTino"}, "url": "https://x.com/TechBroTino/status/1745584901334737274", "like_url": "https://x.com/intent/like?tweet_id=1745584901334737274", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745584901334737274", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745606089486336007": {"created_at": "Fri Jan 12 00:38:18 +0000 2024", "entities": [{"indices": [13, 118], "type": "text", "text": "This made me think of different newer techniques that might be helpful. Thanks for activating my mind lol"}], "favorite_count": 1, "id_str": "1745606089486336007", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "2291863126", "name": "Amogh Mishra", "screen_name": "MishraAmogh", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1818392286855655424/jsVyn_qy_normal.jpg", "description": "-1 to 0 | ex-founding ML engineer @ startup (acq Google) | ex-AI lab @BNPParibas | @columbia alum \ud83e\udd81", "entities": {"description": {"urls": []}}, "followers_count": 954, "location": "New York, NY", "url": "https://x.com/MishraAmogh", "follow_url": "https://x.com/intent/follow?screen_name=MishraAmogh"}, "url": "https://x.com/MishraAmogh/status/1745606089486336007", "like_url": "https://x.com/intent/like?tweet_id=1745606089486336007", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745606089486336007", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745616592363540710": {"created_at": "Fri Jan 12 01:20:02 +0000 2024", "entities": [{"indices": [13, 40], "type": "text", "text": "Wow, Great news, following "}, {"id_str": "240008974", "indices": [40, 52], "name": "Greg Kamradt", "screen_name": "GregKamradt", "type": "mention", "href": "https://x.com/GregKamradt", "text": "@GregKamradt"}, {"indices": [52, 161], "type": "text", "text": " for many days. Will try this out, thanks!! Wondering how much this is directly applicable for chunking code\ud83e\udd14"}], "favorite_count": 1, "id_str": "1745616592363540710", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "1464850475497533443", "name": "Aniruddh Kendurkar", "screen_name": "Aniruddhkends", "profile_image_url_https": "https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png", "description": "I am a slow thinker", "entities": {"description": {"urls": []}}, "followers_count": 5, "location": "", "url": "https://x.com/Aniruddhkends", "follow_url": "https://x.com/intent/follow?screen_name=Aniruddhkends"}, "url": "https://x.com/Aniruddhkends/status/1745616592363540710", "like_url": "https://x.com/intent/like?tweet_id=1745616592363540710", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745616592363540710", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745617254144692439": {"created_at": "Fri Jan 12 01:22:40 +0000 2024", "entities": [{"indices": [13, 232], "type": "text", "text": "Could be useful for Text to Speech. Breakpoints minimize dependency on the words that came before - less likely to produce speech that sounds unnatural, like the speaker completely forgot what they said 10s in the past."}], "favorite_count": 1, "id_str": "1745617254144692439", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "28441180", "name": "Jonathan Fly \ud83d\udc7e", "screen_name": "jonathanfly", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1149573053937942533/9gzB7zG8_normal.png", "description": "CEO of bad ideas. Using the wrong tool. The least efficient way. For no good reason. \ud83d\udc7e\n\nhttps://t.co/9O94rxu31k\nhttps://t.co/DDPn3Nlhom", "entities": {"description": {"urls": [{"display_url": "suno.com/@jonathanfly", "expanded_url": "https://suno.com/@jonathanfly", "indices": [88, 111], "url": "https://t.co/9O94rxu31k"}, {"display_url": "youtube.com/c/JonathanFly", "expanded_url": "http://youtube.com/c/JonathanFly", "indices": [112, 135], "url": "https://t.co/DDPn3Nlhom"}]}, "url": {"urls": [{"display_url": "github.com/JonathanFly/", "expanded_url": "https://github.com/JonathanFly/", "indices": [0, 23], "url": "https://t.co/C9SqLje8db"}]}}, "followers_count": 5680, "location": "", "url": "https://x.com/jonathanfly", "follow_url": "https://x.com/intent/follow?screen_name=jonathanfly"}, "url": "https://x.com/jonathanfly/status/1745617254144692439", "like_url": "https://x.com/intent/like?tweet_id=1745617254144692439", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745617254144692439", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745659179644178880": {"created_at": "Fri Jan 12 04:09:15 +0000 2024", "entities": [{"indices": [42, 89], "type": "text", "text": "Cosine similarity or ANN is probably sufficient"}], "favorite_count": 0, "id_str": "1745659179644178880", "in_reply_to_status_id_str": "1745488073608085994", "lang": "en", "user": {"id_str": "23241398", "name": "ESchwaa", "screen_name": "ESchwaa", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1784129322841694208/Q0B3RKJm_normal.jpg", "description": "Chief AI Officer. Intelligent Adaptive Software (IAS) Ai will change everything \ud83d\udc99 Chelsea.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "elysia-lab.com", "expanded_url": "https://elysia-lab.com/", "indices": [0, 23], "url": "https://t.co/axMCU3f1gW"}]}}, "followers_count": 1570, "location": "London, England", "url": "https://x.com/ESchwaa", "follow_url": "https://x.com/intent/follow?screen_name=ESchwaa"}, "url": "https://x.com/ESchwaa/status/1745659179644178880", "like_url": "https://x.com/intent/like?tweet_id=1745659179644178880", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745659179644178880", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745677374266687784": {"created_at": "Fri Jan 12 05:21:33 +0000 2024", "entities": [{"indices": [13, 256], "type": "text", "text": "I love the idea of this strategy, I'd love to see tests w/ different embedding models instead of the default ada2 from OpenAI. Consider STS vs Clustering vs Classification...  Even a tiny model like gte-small ranks better on average that ada2 "}, {"display_url": "huggingface.co/spaces/mteb/le\u2026", "expanded_url": "https://huggingface.co/spaces/mteb/leaderboard", "indices": [256, 279], "url": "https://t.co/JXLNPJHhLO", "type": "url", "href": "https://huggingface.co/spaces/mteb/leaderboard", "text": "huggingface.co/spaces/mteb/le\u2026"}], "favorite_count": 1, "id_str": "1745677374266687784", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "1213658466", "name": "Olivier", "screen_name": "MillsIT", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1770863188814258177/23yUvl0R_normal.jpg", "description": "Most things #web and #AI. he/him.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "baobabtech.ai", "expanded_url": "https://baobabtech.ai", "indices": [0, 23], "url": "https://t.co/VbRmoOZT9C"}]}}, "followers_count": 132, "location": "Canada", "url": "https://x.com/MillsIT", "follow_url": "https://x.com/intent/follow?screen_name=MillsIT"}, "url": "https://x.com/MillsIT/status/1745677374266687784", "like_url": "https://x.com/intent/like?tweet_id=1745677374266687784", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745677374266687784", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745688440510013592": {"created_at": "Fri Jan 12 06:05:32 +0000 2024", "entities": [{"indices": [13, 104], "type": "text", "text": "This is cool, thanks Greg. Any implementation of this available in Langchain at this point?"}], "favorite_count": 0, "id_str": "1745688440510013592", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "245576015", "name": "Andrew Rogers", "screen_name": "AndrewRogers", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1619388936501227521/fwT2EQDX_normal.jpg", "description": "https://t.co/hNYTZTXhOt , https://t.co/6vhVqwZpj8 (acquired by Gloo), https://t.co/EbFnoi1R5M, cofounder https://t.co/ZEuoE6px3t. Seeking first the Kingdom of God", "entities": {"description": {"urls": [{"display_url": "BibleChat.ai", "expanded_url": "https://BibleChat.ai", "indices": [0, 23], "url": "https://t.co/hNYTZTXhOt"}, {"display_url": "FaithAssistant.com", "expanded_url": "http://FaithAssistant.com", "indices": [26, 49], "url": "https://t.co/6vhVqwZpj8"}, {"display_url": "weebitgames.com", "expanded_url": "http://weebitgames.com", "indices": [70, 93], "url": "https://t.co/EbFnoi1R5M"}, {"display_url": "syllable.ai", "expanded_url": "https://syllable.ai", "indices": [105, 128], "url": "https://t.co/ZEuoE6px3t"}]}, "url": {"urls": [{"display_url": "manifestautomation.com", "expanded_url": "http://manifestautomation.com", "indices": [0, 23], "url": "https://t.co/Z7PE6Phjcl"}]}}, "followers_count": 347, "location": "", "url": "https://x.com/AndrewRogers", "follow_url": "https://x.com/intent/follow?screen_name=AndrewRogers"}, "url": "https://x.com/AndrewRogers/status/1745688440510013592", "like_url": "https://x.com/intent/like?tweet_id=1745688440510013592", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745688440510013592", "replies": ["1745800749546950754"], "score": 0, "thread_score": 0, "reply_count": 0}, "1745745517831983386": {"created_at": "Fri Jan 12 09:52:20 +0000 2024", "entities": [{"id_str": "1316495843621511168", "indices": [13, 22], "name": "Mem", "screen_name": "memdotai", "type": "mention", "href": "https://x.com/memdotai", "text": "@Memdotai"}, {"indices": [22, 29], "type": "text", "text": " mem it"}], "favorite_count": 0, "id_str": "1745745517831983386", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "108465262", "name": "Tim", "screen_name": "SingingTrent", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1718972055390130176/Sdxp9-TE_normal.jpg", "description": "", "entities": {"description": {"urls": []}}, "followers_count": 66, "location": "Singapore", "url": "https://x.com/SingingTrent", "follow_url": "https://x.com/intent/follow?screen_name=SingingTrent"}, "url": "https://x.com/SingingTrent/status/1745745517831983386", "like_url": "https://x.com/intent/like?tweet_id=1745745517831983386", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745745517831983386", "replies": ["1745745723864367572"], "score": 0, "thread_score": 0, "reply_count": 1}, "1745745723864367572": {"created_at": "Fri Jan 12 09:53:09 +0000 2024", "entities": [{"indices": [27, 62], "type": "text", "text": "Saved! Here's the compiled thread: "}, {"display_url": "mem.ai/p/IQVX59lttnX6\u2026", "expanded_url": "https://mem.ai/p/IQVX59lttnX6BP4aCNUN", "indices": [62, 85], "url": "https://t.co/EtxgnkfTij", "type": "url", "href": "https://mem.ai/p/IQVX59lttnX6BP4aCNUN", "text": "mem.ai/p/IQVX59lttnX6\u2026"}], "favorite_count": 0, "id_str": "1745745723864367572", "in_reply_to_status_id_str": "1745745517831983386", "lang": "en", "user": {"id_str": "1316495843621511168", "name": "Mem", "screen_name": "memdotai", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1343666213067530240/3mLsB1kf_normal.jpg", "description": "The AI Notes App That Keeps You Organized.\n\nGet Mem: https://t.co/hRTM2OXs2k\nSet up Mem It for Twitter: https://t.co/QbeULB4VF3", "entities": {"description": {"urls": [{"display_url": "mem.ai", "expanded_url": "http://mem.ai", "indices": [53, 76], "url": "https://t.co/hRTM2OXs2k"}, {"display_url": "mem.ai/sources/mem-it\u2026", "expanded_url": "http://mem.ai/sources/mem-it-for-twitter", "indices": [104, 127], "url": "https://t.co/QbeULB4VF3"}]}, "url": {"urls": [{"display_url": "mem.ai", "expanded_url": "http://mem.ai", "indices": [0, 23], "url": "https://t.co/hRTM2OXs2k"}]}}, "followers_count": 71042, "location": "San Francisco, CA", "url": "https://x.com/memdotai", "follow_url": "https://x.com/intent/follow?screen_name=memdotai"}, "url": "https://x.com/memdotai/status/1745745723864367572", "like_url": "https://x.com/intent/like?tweet_id=1745745723864367572", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745745723864367572", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745762308926660712": {"created_at": "Fri Jan 12 10:59:03 +0000 2024", "entities": [{"id_str": "1577233594673676290", "indices": [13, 26], "name": "Alex Rainey", "screen_name": "RaineyAllDay", "type": "mention", "href": "https://x.com/RaineyAllDay", "text": "@RaineyAllDay"}], "favorite_count": 2, "id_str": "1745762308926660712", "in_reply_to_status_id_str": "1745467853799874969", "lang": "qam", "user": {"id_str": "1539536928768503811", "name": "Mike Heap", "screen_name": "mike_heap_", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1742190652991885312/0cuORhIA_normal.jpg", "description": "@usemyaskai - AI Customer Support Agents for SaaS businesses\n\nPrev: 3 small sales + many 'failures'", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "myaskai.com/?utm_source=tw\u2026", "expanded_url": "https://myaskai.com/?utm_source=twitter&utm_medium=organic_social&utm_content=profile_mike", "indices": [0, 23], "url": "https://t.co/11JoYGNmye"}]}}, "followers_count": 2147, "location": "London, England", "url": "https://x.com/mike_heap_", "follow_url": "https://x.com/intent/follow?screen_name=mike_heap_"}, "url": "https://x.com/mike_heap_/status/1745762308926660712", "like_url": "https://x.com/intent/like?tweet_id=1745762308926660712", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745762308926660712", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745817369178747041": {"created_at": "Fri Jan 12 14:37:51 +0000 2024", "entities": [{"indices": [13, 63], "type": "text", "text": "Also did you see the latest M2 embedding models ? "}, {"display_url": "hazyresearch.stanford.edu/blog/2024-01-1\u2026", "expanded_url": "https://hazyresearch.stanford.edu/blog/2024-01-11-m2-bert-retrieval", "indices": [63, 86], "url": "https://t.co/3K1b2sdtmM", "type": "url", "href": "https://hazyresearch.stanford.edu/blog/2024-01-11-m2-bert-retrieval", "text": "hazyresearch.stanford.edu/blog/2024-01-1\u2026"}], "favorite_count": 0, "id_str": "1745817369178747041", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "1213658466", "name": "Olivier", "screen_name": "MillsIT", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1770863188814258177/23yUvl0R_normal.jpg", "description": "Most things #web and #AI. he/him.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "baobabtech.ai", "expanded_url": "https://baobabtech.ai", "indices": [0, 23], "url": "https://t.co/VbRmoOZT9C"}]}}, "followers_count": 131, "location": "Canada", "url": "https://x.com/MillsIT", "follow_url": "https://x.com/intent/follow?screen_name=MillsIT"}, "url": "https://x.com/MillsIT/status/1745817369178747041", "like_url": "https://x.com/intent/like?tweet_id=1745817369178747041", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745817369178747041", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745902999942181324": {"created_at": "Fri Jan 12 20:18:07 +0000 2024", "entities": [{"id_str": "240008974", "indices": [0, 12], "name": "Greg Kamradt", "screen_name": "GregKamradt", "type": "mention", "href": "https://x.com/GregKamradt", "text": "@GregKamradt"}, {"indices": [12, 57], "type": "text", "text": " would be free if you use a local model with "}, {"id_str": "1688410127378829312", "indices": [57, 64], "name": "ollama", "screen_name": "ollama", "type": "mention", "href": "https://x.com/ollama", "text": "@ollama"}, {"indices": [64, 67], "type": "text", "text": " / "}, {"id_str": "1761481297459851265", "indices": [67, 78], "name": "moved to: @lmstudio", "screen_name": "LMStudioAI", "type": "mention", "href": "https://x.com/LMStudioAI", "text": "@LMStudioAI"}, {"indices": [78, 279], "type": "text", "text": " \ud83e\udd14\ud83d\udca1 \n\nDefinitely worth checking out and maybe even collabing with finetuner community to see if a tiny model like Phi can do this (if finetuned on enough examples) \n\nTagging a few finetuning friends: \n"}, {"id_str": "1368999025165426690", "indices": [279, 292], "name": "LDJ", "screen_name": "ldjconfirmed", "type": "mention", "href": "https://x.com/ldjconfirmed", "text": "@ldjconfirmed"}, {"indices": [292, 293], "type": "text", "text": " "}, {"id_str": "15220945", "indices": [293, 300], "name": "nisten\ud83c\udde8\ud83c\udde6e/acc", "screen_name": "nisten", "type": "mention", "href": "https://x.com/nisten", "text": "@nisten"}, {"indices": [300, 301], "type": "text", "text": " "}, {"id_str": "1365020011123773442", "indices": [301, 310], "name": "Teknium (e/\u03bb)", "screen_name": "Teknium1", "type": "mention", "href": "https://x.com/Teknium1", "text": "@Teknium1"}, {"indices": [310, 311], "type": "text", "text": " "}, {"id_str": "982939260", "indices": [311, 322], "name": "Jon Durbin", "screen_name": "jon_durbin", "type": "mention", "href": "https://x.com/jon_durbin", "text": "@jon_durbin"}, {"indices": [322, 323], "type": "text", "text": " "}, {"id_str": "923114064460558336", "indices": [323, 337], "name": "Maxime Labonne", "screen_name": "maximelabonne", "type": "mention", "href": "https://x.com/maximelabonne", "text": "@maximelabonne"}, {"indices": [337, 339], "type": "text", "text": ""}], "favorite_count": 4, "id_str": "1745902999942181324", "in_reply_to_status_id_str": "1745528774668750915", "lang": "en", "user": {"id_str": "5721582", "name": "Alex Volkov (Thursd/AI)", "screen_name": "altryne", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1735758190250168320/WVPIXQjn_normal.jpg", "description": "\u270c\ufe0f Vibe Coder\n\n\ud83c\udf99\ufe0f Host of @thursdai_pod \n\u2728 AI Evangelist with @weights_biases \ud83e\ude84\ud83d\udc1d  \nworking on @weave_wb\n\nFounder and CEO @ https://t.co/qbC0EP7h1k", "entities": {"description": {"urls": [{"display_url": "targum.video", "expanded_url": "http://targum.video", "indices": [123, 146], "url": "https://t.co/qbC0EP7h1k"}]}, "url": {"urls": [{"display_url": "thursdai.news", "expanded_url": "https://thursdai.news", "indices": [0, 23], "url": "https://t.co/UW4KIq3dc6"}]}}, "followers_count": 32163, "location": "Pod Newsletter \u2192", "url": "https://x.com/altryne", "follow_url": "https://x.com/intent/follow?screen_name=altryne"}, "url": "https://x.com/altryne/status/1745902999942181324", "like_url": "https://x.com/intent/like?tweet_id=1745902999942181324", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745902999942181324", "replies": ["1745905543158358205"], "score": 0, "thread_score": 0, "reply_count": 1}, "1745905543158358205": {"created_at": "Fri Jan 12 20:28:13 +0000 2024", "entities": [{"indices": [0, 287], "type": "text", "text": "I've used this technique, works pretty well (sometimes).\n\nI've been thinking about fine-tuning a classifier to do this, using known good logical segment breaks (like chapters within project gutenberg books, scene changes from movie scripts, etc.), but I don't quite have the recipe down."}], "favorite_count": 1, "id_str": "1745905543158358205", "in_reply_to_status_id_str": "1745902999942181324", "lang": "en", "user": {"id_str": "982939260", "name": "Jon Durbin", "screen_name": "jon_durbin", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1863862328803930112/Kj-1SGNc_normal.jpg", "description": "Human. Backend dev https://t.co/CJYvkACyne", "entities": {"description": {"urls": [{"display_url": "chutes.ai", "expanded_url": "http://chutes.ai", "indices": [19, 42], "url": "https://t.co/CJYvkACyne"}]}}, "followers_count": 3006, "location": "", "url": "https://x.com/jon_durbin", "follow_url": "https://x.com/intent/follow?screen_name=jon_durbin"}, "url": "https://x.com/jon_durbin/status/1745905543158358205", "like_url": "https://x.com/intent/like?tweet_id=1745905543158358205", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745905543158358205", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1745937357189128698": {"created_at": "Fri Jan 12 22:34:38 +0000 2024", "entities": [{"indices": [13, 257], "type": "text", "text": "In theory this could lead to extremely large chunks if the content stays similar to the sentence before, right?\n\nWouldn't it be safer to calculate the embedding for sentence 1 to n (all together) and compare it to n+1? Sounds a bit more stable."}], "favorite_count": 0, "id_str": "1745937357189128698", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "3916034081", "name": "Paul-Louis Pr\u00f6ve", "screen_name": "gopietz", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1726669669363335168/4jZUiYdL_normal.jpg", "description": "AI @ Tensora", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "tensora.co", "expanded_url": "http://tensora.co", "indices": [0, 23], "url": "https://t.co/39i5iXjp7M"}]}}, "followers_count": 34, "location": "Hamburg, Germany", "url": "https://x.com/gopietz", "follow_url": "https://x.com/intent/follow?screen_name=gopietz"}, "url": "https://x.com/gopietz/status/1745937357189128698", "like_url": "https://x.com/intent/like?tweet_id=1745937357189128698", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745937357189128698", "replies": ["1745939152586330138"], "score": 0, "thread_score": 0, "reply_count": 1}, "1745939152586330138": {"created_at": "Fri Jan 12 22:41:46 +0000 2024", "entities": [{"indices": [9, 89], "type": "text", "text": "Because we choose our distances w/ percentiles, there will always be breakpoints"}], "favorite_count": 1, "id_str": "1745939152586330138", "in_reply_to_status_id_str": "1745937357189128698", "lang": "en", "user": {"id_str": "240008974", "name": "Greg Kamradt", "screen_name": "GregKamradt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1467896309453570052/BGy5XYVQ_normal.jpg", "description": "President @arcprize \u2014Founder https://t.co/XK3ITFuCZe \u2014builder/engineer", "entities": {"description": {"urls": [{"display_url": "leverage.to", "expanded_url": "https://www.leverage.to/", "indices": [29, 52], "url": "https://t.co/XK3ITFuCZe"}]}, "url": {"urls": [{"display_url": "gregkamradt.com", "expanded_url": "http://gregkamradt.com", "indices": [0, 23], "url": "https://t.co/TSzx2cCdlg"}]}}, "followers_count": 35888, "location": "San Francisco, CA", "url": "https://x.com/GregKamradt", "follow_url": "https://x.com/intent/follow?screen_name=GregKamradt"}, "url": "https://x.com/GregKamradt/status/1745939152586330138", "like_url": "https://x.com/intent/like?tweet_id=1745939152586330138", "reply_url": "https://x.com/intent/tweet?in_reply_to=1745939152586330138", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1747476115852316838": {"created_at": "Wed Jan 17 04:29:07 +0000 2024", "entities": [{"indices": [0, 38], "type": "text", "text": "Tuning Language Models by Proxy\n\nabs: "}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [38, 61], "url": "https://t.co/IGHWbJ3RPS", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}, {"indices": [61, 303], "type": "text", "text": "\n\n\"Tuning\" a black-box LLM by training a smaller LLM and offsetting the black-box LLM logits with the difference between the smaller trained LLM logits and  smaller untuned LLM logits. Performs better on TruthfulQA than directly-tuned models."}], "favorite_count": 116, "id_str": "1747476115852316838", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/mYCVKZXD1N", "expanded_url": "https://x.com/iScienceLuvr/status/1747476115852316838/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1747475697579556864", "indices": [282, 305], "media_key": "3_1747475697579556864", "media_results": {"result": {"media_key": "3_1747475697579556864"}}, "media_url_https": "https://pbs.twimg.com/media/GEBH42_bgAAb1c9.jpg", "original_info": {"focus_rects": [{"h": 688, "w": 1228, "x": 0, "y": 0}, {"h": 1228, "w": 1228, "x": 0, "y": 0}, {"h": 1400, "w": 1228, "x": 0, "y": 0}, {"h": 1641, "w": 821, "x": 123, "y": 0}, {"h": 1641, "w": 1228, "x": 0, "y": 0}], "height": 1641, "width": 1228}, "sizes": {"large": {"h": 1641, "resize": "fit", "w": 1228}, "medium": {"h": 1200, "resize": "fit", "w": 898}, "small": {"h": 680, "resize": "fit", "w": 509}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/mYCVKZXD1N"}], "user": {"id_str": "441465751", "name": "Tanishq Mathew Abraham, Ph.D.", "screen_name": "iScienceLuvr", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1553508977735962624/nnlSwBmu_normal.jpg", "description": "PhD at 19 (2023) |\nFounder & ex CEO @MedARC_AI |\nex Research Director Stability AI | \nBiomed. engineer @ 14 |\nTEDx talk\u27a1https://t.co/xPxwKTpz0D", "entities": {"description": {"urls": [{"display_url": "bit.ly/3tpAuan", "expanded_url": "https://bit.ly/3tpAuan", "indices": [120, 143], "url": "https://t.co/xPxwKTpz0D"}]}, "url": {"urls": [{"display_url": "tanishq.ai", "expanded_url": "https://tanishq.ai", "indices": [0, 23], "url": "https://t.co/nNzCz2VVd1"}]}}, "followers_count": 74239, "location": "", "url": "https://x.com/iScienceLuvr", "follow_url": "https://x.com/intent/follow?screen_name=iScienceLuvr"}, "url": "https://x.com/iScienceLuvr/status/1747476115852316838", "like_url": "https://x.com/intent/like?tweet_id=1747476115852316838", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747476115852316838", "replies": ["1747482473351843858"], "score": 0, "thread_score": 0.2, "reply_count": 2, "tweet_type": "Teaser", "is_branch": true}, "1747482473351843858": {"created_at": "Wed Jan 17 04:54:22 +0000 2024", "entities": [{"id_str": "920321515077414912", "indices": [14, 23], "name": "Readwise", "screen_name": "readwise", "type": "mention", "href": "https://x.com/readwise", "text": "@readwise"}, {"indices": [23, 35], "type": "text", "text": " save thread"}], "favorite_count": 0, "id_str": "1747482473351843858", "in_reply_to_status_id_str": "1747476115852316838", "lang": "en", "user": {"id_str": "89958280", "name": "zzzzzzoo00oo", "screen_name": "zzzzzzoo00oo", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1508283070046113793/WR3gVZfN_normal.jpg", "description": "", "entities": {"description": {"urls": []}}, "followers_count": 241, "location": "", "url": "https://x.com/zzzzzzoo00oo", "follow_url": "https://x.com/intent/follow?screen_name=zzzzzzoo00oo"}, "url": "https://x.com/zzzzzzoo00oo/status/1747482473351843858", "like_url": "https://x.com/intent/like?tweet_id=1747482473351843858", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747482473351843858", "replies": ["1747482925904396536"], "score": 0.0, "thread_score": 0.0, "reply_count": 1, "is_branch": true}, "1747482925904396536": {"created_at": "Wed Jan 17 04:56:10 +0000 2024", "entities": [{"id_str": "89958280", "indices": [28, 41], "name": "zzzzzzoo00oo", "screen_name": "zzzzzzoo00oo", "type": "mention", "href": "https://x.com/zzzzzzoo00oo", "text": "@zzzzzzoo00oo"}, {"indices": [41, 144], "type": "text", "text": " First public save of this thread! \ud83c\udfc6\n\nStats:\n\u2022 159 total saves of iScienceLuvr's threads (ranked #1075)"}], "favorite_count": 0, "id_str": "1747482925904396536", "in_reply_to_status_id_str": "1747482473351843858", "lang": "en", "user": {"id_str": "920321515077414912", "name": "Readwise", "screen_name": "readwise", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1333582244817100801/W9vXWh4U_normal.jpg", "description": "Save your best highlights from Kindle, Twitter, Pocket, Instapaper, iBooks, and 30+ others.\n\nThen revisit, search, organize, and export them seamlessly.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "readwise.io", "expanded_url": "https://readwise.io", "indices": [0, 23], "url": "https://t.co/nrgToNhKqN"}]}}, "followers_count": 210159, "location": "", "url": "https://x.com/readwise", "follow_url": "https://x.com/intent/follow?screen_name=readwise"}, "url": "https://x.com/readwise/status/1747482925904396536", "like_url": "https://x.com/intent/like?tweet_id=1747482925904396536", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747482925904396536", "replies": [], "score": 0.0, "thread_score": 0, "reply_count": 0}, "1747485364162322641": {"created_at": "Wed Jan 17 05:05:52 +0000 2024", "entities": [{"indices": [0, 35], "type": "text", "text": "Tuning Language Models by Proxy\n\n\u2193\n"}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [35, 58], "url": "https://t.co/QDlO1kRwC7", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}], "favorite_count": 0, "id_str": "1747485364162322641", "lang": "en", "user": {"id_str": "123543935", "name": "\ud835\ude90\ud835\udd2a\ud835\udffe\ud835\udea1\ud835\udea1\ud835\udffe", "screen_name": "gm8xx8", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1723513473294835712/pvPLgqp3_normal.jpg", "description": "\u263a\ufe0e", "entities": {"description": {"urls": []}}, "followers_count": 5558, "location": "", "url": "https://x.com/gm8xx8", "follow_url": "https://x.com/intent/follow?screen_name=gm8xx8"}, "url": "https://x.com/gm8xx8/status/1747485364162322641", "like_url": "https://x.com/intent/like?tweet_id=1747485364162322641", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747485364162322641", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0, "is_branch": true}, "1747504915646124146": {"created_at": "Wed Jan 17 06:23:33 +0000 2024", "entities": [{"indices": [0, 45], "type": "text", "text": "Tuning Language Models by Proxy\n\npaper page: "}, {"display_url": "huggingface.co/papers/2401.08\u2026", "expanded_url": "https://huggingface.co/papers/2401.08565", "indices": [45, 68], "url": "https://t.co/JHNqIJrzcw", "type": "url", "href": "https://huggingface.co/papers/2401.08565", "text": "huggingface.co/papers/2401.08\u2026"}, {"indices": [68, 1585], "type": "text", "text": "\n\nDespite the general capabilities of large pretrained language models, they consistently benefit from further adaptation to better achieve desired behaviors. However, tuning these models has become increasingly resource-intensive, or impossible when model weights are private. We introduce proxy-tuning, a lightweight decoding-time algorithm that operates on top of black-box LMs to achieve the result of directly tuning the model, but by accessing only its prediction over the output vocabulary. Our method instead tunes a smaller LM, then applies the difference between the predictions of the small tuned and untuned LMs to shift the original predictions of the base model in the direction of tuning, while retaining the benefits of larger scale pretraining. In experiments, when we apply proxy-tuning to Llama2-70B using proxies of only 7B size, we can close 88% of the gap between Llama2-70B and its truly-tuned chat version, when evaluated across knowledge, reasoning, and safety benchmarks. Interestingly, when tested on TruthfulQA, proxy-tuned models are actually more truthful than directly tuned models, possibly because decoding-time guidance better retains the model's factual knowledge. We then demonstrate the generality of proxy-tuning by applying it for domain adaptation on code, and task-specific finetuning on question-answering and math problems. Our work demonstrates the promise of using small tuned LMs to efficiently customize large, potentially proprietary LMs through decoding-time guidance."}], "favorite_count": 158, "id_str": "1747504915646124146", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/mIJ11Hv1FW", "expanded_url": "https://x.com/_akhaliq/status/1747504915646124146/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1747504907307950080", "indices": [281, 304], "media_key": "3_1747504907307950080", "media_results": {"result": {"media_key": "3_1747504907307950080"}}, "media_url_https": "https://pbs.twimg.com/media/GEBidFtXoAAwql3.jpg", "original_info": {"focus_rects": [{"h": 668, "w": 1192, "x": 0, "y": 0}, {"h": 1126, "w": 1126, "x": 3, "y": 0}, {"h": 1126, "w": 988, "x": 72, "y": 0}, {"h": 1126, "w": 563, "x": 285, "y": 0}, {"h": 1126, "w": 1192, "x": 0, "y": 0}], "height": 1126, "width": 1192}, "sizes": {"large": {"h": 1126, "resize": "fit", "w": 1192}, "medium": {"h": 1126, "resize": "fit", "w": 1192}, "small": {"h": 642, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/mIJ11Hv1FW"}], "user": {"id_str": "2465283662", "name": "AK", "screen_name": "_akhaliq", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1451191636810092553/kpM5Fe12_normal.jpg", "description": "AI research paper tweets, ML @Gradio (acq. by @HuggingFace \ud83e\udd17)\n\ndm for promo, submit papers here: https://t.co/UzmYN5XOCi", "entities": {"description": {"urls": [{"display_url": "huggingface.co/papers/submit", "expanded_url": "https://huggingface.co/papers/submit", "indices": [97, 120], "url": "https://t.co/UzmYN5XOCi"}]}, "url": {"urls": [{"display_url": "huggingface.co/akhaliq", "expanded_url": "https://huggingface.co/akhaliq", "indices": [0, 23], "url": "https://t.co/q2Qoey80Gx"}]}}, "followers_count": 388480, "location": "", "url": "https://x.com/_akhaliq", "follow_url": "https://x.com/intent/follow?screen_name=_akhaliq"}, "url": "https://x.com/_akhaliq/status/1747504915646124146", "like_url": "https://x.com/intent/like?tweet_id=1747504915646124146", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747504915646124146", "replies": [], "score": 0, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Teaser", "is_branch": true}, "1747511842921156853": {"created_at": "Wed Jan 17 06:51:05 +0000 2024", "entities": [{"indices": [13, 166], "type": "text", "text": "When utilizing Agentic Chunking, the question arises as to whether we should store the chunk in the vector database as a dictionary or a list of strings?"}], "favorite_count": 0, "id_str": "1747511842921156853", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "user": {"id_str": "53910880", "name": "Nam Vu", "screen_name": "zuzoovn", "profile_image_url_https": "https://pbs.twimg.com/profile_images/787858748744183808/dOt24DEn_normal.jpg", "description": "A Vietnamese Software Engineer who is really passionate (#MachineLearning, #DeepLearning)  and wants to work in the USA.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "github.com/ZuzooVn/", "expanded_url": "https://github.com/ZuzooVn/", "indices": [0, 23], "url": "https://t.co/BYVWccYDB1"}]}}, "followers_count": 1991, "location": "Vietnam", "url": "https://x.com/zuzoovn", "follow_url": "https://x.com/intent/follow?screen_name=zuzoovn"}, "url": "https://x.com/zuzoovn/status/1747511842921156853", "like_url": "https://x.com/intent/like?tweet_id=1747511842921156853", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747511842921156853", "replies": ["1747627610346045468"], "score": 0, "thread_score": 0, "reply_count": 1}, "1747517598453968982": {"created_at": "Wed Jan 17 07:13:57 +0000 2024", "entities": [{"indices": [0, 27], "type": "text", "text": "Reminds me of the EFT paper"}], "favorite_count": 0, "id_str": "1747517598453968982", "quoted_status_id_str": "1747504915646124146", "lang": "en", "user": {"id_str": "1591653351292370945", "name": "Josh Cason", "screen_name": "TheGrizztronic", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1879780817741770752/Pyc_72vL_normal.jpg", "description": "e/wfh | ML Eng (Scala) \u26cf\ufe0f @Demandbase, helping you get business | Self Dev \ud83e\udde0\ud83d\udcaa\ud83e\udd1d\ud83c\udfaf | Ex IBM Watson NLP | MS Computational Linguistics @UW | \u2764\ufe0f\u2203\u2200 | FL Life \ud83d\udc0a", "entities": {"description": {"urls": []}}, "followers_count": 498, "location": "Tallahassee \ud83e\udda9", "url": "https://x.com/TheGrizztronic", "follow_url": "https://x.com/intent/follow?screen_name=TheGrizztronic"}, "url": "https://x.com/TheGrizztronic/status/1747517598453968982", "like_url": "https://x.com/intent/like?tweet_id=1747517598453968982", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747517598453968982", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0, "is_branch": true}, "1747524840586723646": {"created_at": "Wed Jan 17 07:42:44 +0000 2024", "entities": [{"indices": [0, 68], "type": "text", "text": "I like this idea. Any practitioners out there have a different view?"}], "favorite_count": 27, "id_str": "1747524840586723646", "quoted_status_id_str": "1747504915646124146", "lang": "en", "user": {"id_str": "44073696", "name": "Dan Roy \ud83c\udde8\ud83c\udde6\ud83c\udde9\ud83c\uddf0\ud83c\uddf1\ud83c\uddf9\ud83c\uddfa\ud83c\udde6", "screen_name": "roydanroy", "profile_image_url_https": "https://pbs.twimg.com/profile_images/647245794249015296/575wCuTG_normal.jpg", "description": "ML / AI researcher. Research Director and Canada CIFAR AI Chair, @VectorInst. Professor, @UofT (Statistics/CS).", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "danroy.org", "expanded_url": "http://danroy.org/", "indices": [0, 23], "url": "https://t.co/sL0uQkbS3g"}]}}, "followers_count": 52685, "location": "University of Toronto", "url": "https://x.com/roydanroy", "follow_url": "https://x.com/intent/follow?screen_name=roydanroy"}, "url": "https://x.com/roydanroy/status/1747524840586723646", "like_url": "https://x.com/intent/like?tweet_id=1747524840586723646", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747524840586723646", "replies": ["1747526171196260390", "1747628376389550089", "1747858959023681759"], "score": 0, "thread_score": 0, "reply_count": 6, "is_branch": true}, "1747526171196260390": {"created_at": "Wed Jan 17 07:48:01 +0000 2024", "entities": [{"indices": [11, 43], "type": "text", "text": "This is the same as this right? "}, {"display_url": "arxiv.org/abs/2310.12962", "expanded_url": "https://arxiv.org/abs/2310.12962", "indices": [43, 66], "url": "https://t.co/WCQRmCyYMq", "type": "url", "href": "https://arxiv.org/abs/2310.12962", "text": "arxiv.org/abs/2310.12962"}], "favorite_count": 4, "id_str": "1747526171196260390", "in_reply_to_status_id_str": "1747524840586723646", "lang": "en", "user": {"id_str": "1070455434304200705", "name": "Aryaman Arora", "screen_name": "aryaman2020", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1873580950459723776/Ak4eR8pL_normal.jpg", "description": "member of technical staff @stanfordnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "aryaman.io", "expanded_url": "http://aryaman.io/", "indices": [0, 23], "url": "https://t.co/QWlHp6nsvW"}]}}, "followers_count": 6061, "location": "\ud83c\udf32", "url": "https://x.com/aryaman2020", "follow_url": "https://x.com/intent/follow?screen_name=aryaman2020"}, "url": "https://x.com/aryaman2020/status/1747526171196260390", "like_url": "https://x.com/intent/like?tweet_id=1747526171196260390", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747526171196260390", "replies": ["1747859740242464773", "1748040174628409816"], "score": 0.2, "thread_score": 0.1, "reply_count": 3, "tweet_type": "Related Work", "location": "related work", "is_branch": true}, "1747627610346045468": {"created_at": "Wed Jan 17 14:31:06 +0000 2024", "entities": [{"indices": [9, 68], "type": "text", "text": "yeah...depends on the use case you want to use it for later"}], "favorite_count": 0, "id_str": "1747627610346045468", "in_reply_to_status_id_str": "1747511842921156853", "lang": "en", "user": {"id_str": "240008974", "name": "Greg Kamradt", "screen_name": "GregKamradt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1467896309453570052/BGy5XYVQ_normal.jpg", "description": "President @arcprize \u2014Founder https://t.co/XK3ITFuCZe \u2014builder/engineer", "entities": {"description": {"urls": [{"display_url": "leverage.to", "expanded_url": "https://www.leverage.to/", "indices": [29, 52], "url": "https://t.co/XK3ITFuCZe"}]}, "url": {"urls": [{"display_url": "gregkamradt.com", "expanded_url": "http://gregkamradt.com", "indices": [0, 23], "url": "https://t.co/TSzx2cCdlg"}]}}, "followers_count": 35888, "location": "San Francisco, CA", "url": "https://x.com/GregKamradt", "follow_url": "https://x.com/intent/follow?screen_name=GregKamradt"}, "url": "https://x.com/GregKamradt/status/1747627610346045468", "like_url": "https://x.com/intent/like?tweet_id=1747627610346045468", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747627610346045468", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1747628376389550089": {"created_at": "Wed Jan 17 14:34:08 +0000 2024", "entities": [{"indices": [11, 70], "type": "text", "text": "Is this just boosting? Or is there something else involved?"}], "favorite_count": 1, "id_str": "1747628376389550089", "in_reply_to_status_id_str": "1747524840586723646", "lang": "en", "user": {"id_str": "1045447599090794497", "name": "Elan Rosenfeld", "screen_name": "ElanRosenfeld", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1288657549961711622/0z2nIbwz_normal.jpg", "description": "Researcher @GoogleAI, PhD @CarnegieMellon", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "cs.cmu.edu/~elan", "expanded_url": "http://cs.cmu.edu/~elan", "indices": [0, 23], "url": "https://t.co/0lQXW2BfMa"}]}}, "followers_count": 1220, "location": "", "url": "https://x.com/ElanRosenfeld", "follow_url": "https://x.com/intent/follow?screen_name=ElanRosenfeld"}, "url": "https://x.com/ElanRosenfeld/status/1747628376389550089", "like_url": "https://x.com/intent/like?tweet_id=1747628376389550089", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747628376389550089", "replies": [], "score": 0.4, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Q&A", "location": "method", "is_branch": true}, "1747635012009361520": {"created_at": "Wed Jan 17 15:00:31 +0000 2024", "entities": [{"indices": [0, 149], "type": "text", "text": "[CL] Tuning Language Models by Proxy\nA Liu, X Han, Y Wang, Y Tsvetkov, Y Choi, N A. Smith [University of Washington & Allen Institute for AI] (2024)\n"}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [149, 172], "url": "https://t.co/A6FQ6tAtm8", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}, {"indices": [172, 1669], "type": "text", "text": "\n\n- While large pretrained language models (LLMs) have general capabilities, they still benefit from further tuning to better achieve desired behaviors. However, directly finetuning these models has become increasingly resource-intensive, sometimes even impossible (e.g. GPT-4).\n \n- This paper introduces a lightweight decoding-time algorithm that operates on top of black-box LLMs to achieve the effect of tuning, but only accesses the model's predictions over the output vocabulary, not internal weights. Specifically, a smaller model is tuned, and the difference between the small tuned and untuned model is applied to shift the base model's predictions towards the direction of tuning.\n \n- In instruction-tuning experiments, using 7B-CHAT as the expert, proxy-tuning closes 91% and 88% of the performance gap with direct tuning for 13B and 70B models respectively. Proxy-tuning sometimes even outperforms direct tuning, possibly because decoding-time guidance better preserves knowledge.\n \n- In code adaptation experiments, using CodeLLAMA-7B as the expert, proxy-tuning leads to 17-32% absolute improvements. In task-tuning experiments, using 7B task experts, proxy-tuning 70B achieves 31% absolute gains.\n \n- This paper proposes an efficient decoding-time algorithm for customizing large LLMs, especially suitable when tuning proprietary models where only output logits are accessible, allowing organizations to protect their competitive advantage while satisfying user needs for adaptation."}], "favorite_count": 7, "id_str": "1747635012009361520", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/AqoIVvZPUO", "expanded_url": "https://x.com/fly51fly/status/1747635012009361520/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1747632871433441281", "indices": [286, 309], "media_key": "3_1747632871433441281", "media_results": {"result": {"media_key": "3_1747632871433441281"}}, "media_url_https": "https://pbs.twimg.com/media/GEDW1lOWEAEi1k2.jpg", "original_info": {"focus_rects": [{"h": 811, "w": 1448, "x": 0, "y": 0}, {"h": 1132, "w": 1132, "x": 158, "y": 0}, {"h": 1132, "w": 993, "x": 228, "y": 0}, {"h": 1132, "w": 566, "x": 441, "y": 0}, {"h": 1132, "w": 1448, "x": 0, "y": 0}], "height": 1132, "width": 1448}, "sizes": {"large": {"h": 1132, "resize": "fit", "w": 1448}, "medium": {"h": 938, "resize": "fit", "w": 1200}, "small": {"h": 532, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/AqoIVvZPUO"}, {"display_url": "pic.x.com/AqoIVvZPUO", "expanded_url": "https://x.com/fly51fly/status/1747635012009361520/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1747632871408291840", "indices": [286, 309], "media_key": "3_1747632871408291840", "media_results": {"result": {"media_key": "3_1747632871408291840"}}, "media_url_https": "https://pbs.twimg.com/media/GEDW1lIWUAAtuXA.jpg", "original_info": {"focus_rects": [{"h": 956, "w": 1708, "x": 0, "y": 0}, {"h": 1210, "w": 1210, "x": 0, "y": 0}, {"h": 1210, "w": 1061, "x": 0, "y": 0}, {"h": 1210, "w": 605, "x": 0, "y": 0}, {"h": 1210, "w": 1708, "x": 0, "y": 0}], "height": 1210, "width": 1708}, "sizes": {"large": {"h": 1210, "resize": "fit", "w": 1708}, "medium": {"h": 850, "resize": "fit", "w": 1200}, "small": {"h": 482, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/AqoIVvZPUO"}, {"display_url": "pic.x.com/AqoIVvZPUO", "expanded_url": "https://x.com/fly51fly/status/1747635012009361520/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1747632871416721409", "indices": [286, 309], "media_key": "3_1747632871416721409", "media_results": {"result": {"media_key": "3_1747632871416721409"}}, "media_url_https": "https://pbs.twimg.com/media/GEDW1lKW8AEIXtI.jpg", "original_info": {"focus_rects": [{"h": 457, "w": 816, "x": 0, "y": 471}, {"h": 816, "w": 816, "x": 0, "y": 112}, {"h": 928, "w": 814, "x": 0, "y": 0}, {"h": 928, "w": 464, "x": 116, "y": 0}, {"h": 928, "w": 816, "x": 0, "y": 0}], "height": 928, "width": 816}, "sizes": {"large": {"h": 928, "resize": "fit", "w": 816}, "medium": {"h": 928, "resize": "fit", "w": 816}, "small": {"h": 680, "resize": "fit", "w": 598}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/AqoIVvZPUO"}], "user": {"id_str": "22146921", "name": "fly51fly", "screen_name": "fly51fly", "profile_image_url_https": "https://pbs.twimg.com/profile_images/501577797114937344/ge9Wu-cU_normal.png", "description": "BUPT prof | Sharing latest AI papers & insights  | Join me in embracing the AI revolution! #MachineLearning #AI #Innovation", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "github.com/fly51fly", "expanded_url": "http://github.com/fly51fly", "indices": [0, 23], "url": "https://t.co/YFiax56sJr"}]}}, "followers_count": 7058, "location": "", "url": "https://x.com/fly51fly", "follow_url": "https://x.com/intent/follow?screen_name=fly51fly"}, "url": "https://x.com/fly51fly/status/1747635012009361520", "like_url": "https://x.com/intent/like?tweet_id=1747635012009361520", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747635012009361520", "replies": [], "score": 0, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Teaser", "is_branch": true}, "1747712052569805279": {"created_at": "Wed Jan 17 20:06:38 +0000 2024", "entities": [{"indices": [0, 14], "type": "text", "text": "Great work by "}, {"id_str": "1197247629136203776", "indices": [14, 27], "name": "Alisa Liu", "screen_name": "alisawuffles", "type": "mention", "href": "https://x.com/alisawuffles", "text": "@alisawuffles"}, {"indices": [27, 39], "type": "text", "text": " and others!"}], "favorite_count": 6, "id_str": "1747712052569805279", "quoted_status_id_str": "1747504915646124146", "lang": "en", "user": {"id_str": "28635924", "name": "Ohad Rubin", "screen_name": "OhadRubin", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1159555793521381378/NVwBpayT_normal.jpg", "description": "P.hD student. Researching Natural Language Processing at Tel Aviv University. Let's have more paperclips? \ud83d\udcce\u23e9", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "ohadrubin.github.io", "expanded_url": "https://ohadrubin.github.io/", "indices": [0, 23], "url": "https://t.co/fwsLlVOFz5"}]}}, "followers_count": 839, "location": "Israel, Tel Aviv", "url": "https://x.com/OhadRubin", "follow_url": "https://x.com/intent/follow?screen_name=OhadRubin"}, "url": "https://x.com/OhadRubin/status/1747712052569805279", "like_url": "https://x.com/intent/like?tweet_id=1747712052569805279", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747712052569805279", "replies": ["1747807495660380409"], "score": 0, "thread_score": 0, "reply_count": 1, "is_branch": true}, "1747745978587779088": {"created_at": "Wed Jan 17 22:21:27 +0000 2024", "entities": [{"indices": [0, 156], "type": "text", "text": "Proxy-tuning adapts LLMs to specific tasks without modifying parameters by aligning outputs with small 'proxy' models, showing up to 91% performance gains: "}, {"display_url": "emergentmind.com/papers/2401.08\u2026", "expanded_url": "https://www.emergentmind.com/papers/2401.08565", "indices": [156, 179], "url": "https://t.co/xJUmWIFfK5", "type": "url", "href": "https://www.emergentmind.com/papers/2401.08565", "text": "emergentmind.com/papers/2401.08\u2026"}], "favorite_count": 1, "id_str": "1747745978587779088", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/bMidFWXrA4", "expanded_url": "https://x.com/EmergentMind/status/1747745978587779088/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1747745976494723073", "indices": [180, 203], "media_key": "3_1747745976494723073", "media_results": {"result": {"media_key": "3_1747745976494723073"}}, "media_url_https": "https://pbs.twimg.com/media/GEE9tKaWEAEOqie.jpg", "original_info": {"focus_rects": [{"h": 645, "w": 1151, "x": 0, "y": 0}, {"h": 1151, "w": 1151, "x": 0, "y": 0}, {"h": 1175, "w": 1031, "x": 101, "y": 0}, {"h": 1175, "w": 588, "x": 322, "y": 0}, {"h": 1175, "w": 1151, "x": 0, "y": 0}], "height": 1175, "width": 1151}, "sizes": {"large": {"h": 1175, "resize": "fit", "w": 1151}, "medium": {"h": 1175, "resize": "fit", "w": 1151}, "small": {"h": 680, "resize": "fit", "w": 666}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/bMidFWXrA4"}], "user": {"id_str": "1599845448155598870", "name": "Emergent Mind", "screen_name": "EmergentMind", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1643656726707568658/P5wrOT55_normal.png", "description": "Emergent Mind is an AI research assistant that helps you discover and learn about research in any field on arXiv. Created by @mhmazur.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "emergentmind.com", "expanded_url": "https://www.emergentmind.com", "indices": [0, 23], "url": "https://t.co/QcLmov8NRE"}]}}, "followers_count": 2128, "location": "Cary, NC", "url": "https://x.com/EmergentMind", "follow_url": "https://x.com/intent/follow?screen_name=EmergentMind"}, "url": "https://x.com/EmergentMind/status/1747745978587779088", "like_url": "https://x.com/intent/like?tweet_id=1747745978587779088", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747745978587779088", "replies": [], "score": 0, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Teaser", "is_branch": true}, "1747807495660380409": {"created_at": "Thu Jan 18 02:25:54 +0000 2024", "entities": [{"indices": [11, 22], "type": "text", "text": "thanks!!! \ud83d\ude42"}], "favorite_count": 2, "id_str": "1747807495660380409", "in_reply_to_status_id_str": "1747712052569805279", "lang": "en", "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1747807495660380409", "like_url": "https://x.com/intent/like?tweet_id=1747807495660380409", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747807495660380409", "replies": [], "score": 0.2, "thread_score": 0.2, "reply_count": 0, "is_author": true, "is_branch": true}, "1747812440400900583": {"created_at": "Thu Jan 18 02:45:33 +0000 2024", "entities": [{"indices": [0, 183], "type": "text", "text": "I have just gone through the abstract of this paper. It is interesting, that applying the proxy tuning improvements of the smaller model on the bigger model saves us a lot of compute."}], "favorite_count": 1, "id_str": "1747812440400900583", "quoted_status_id_str": "1747504915646124146", "lang": "en", "user": {"id_str": "1602488121618092034", "name": "jay maddipoti", "screen_name": "JHloFrmOthrWrld", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1602488259245797376/X9YaTKwj_normal.jpg", "description": "", "entities": {"description": {"urls": []}}, "followers_count": 7, "location": "", "url": "https://x.com/JHloFrmOthrWrld", "follow_url": "https://x.com/intent/follow?screen_name=JHloFrmOthrWrld"}, "url": "https://x.com/JHloFrmOthrWrld/status/1747812440400900583", "like_url": "https://x.com/intent/like?tweet_id=1747812440400900583", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747812440400900583", "replies": [], "score": 0, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Teaser", "is_branch": true}, "1747858959023681759": {"created_at": "Thu Jan 18 05:50:24 +0000 2024", "entities": [{"indices": [0, 294], "type": "text", "text": "Good idea to try the difference but still needs big model inference, right?\n\nI\u2019ve found that for most narrow tasks (most of what we do), it\u2019s good enough to use llama2 for that specific task\n\nI wrote a library that auto saves on original, and auto switches when smaller, faster model is ready\n\n"}, {"display_url": "github.com/virevolai/logo\u2026", "expanded_url": "https://github.com/virevolai/logos-shift-client", "indices": [294, 317], "url": "https://t.co/57YJ6S9eMB", "type": "url", "href": "https://github.com/virevolai/logos-shift-client", "text": "github.com/virevolai/logo\u2026"}], "favorite_count": 0, "id_str": "1747858959023681759", "in_reply_to_status_id_str": "1747524840586723646", "lang": "en", "user": {"id_str": "587612063", "name": "Saurabh Bhatnagar", "screen_name": "analyticsaurabh", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1298444761112686595/0_NlRxAT_normal.jpg", "description": "Founder @bohitaAi founded AI at Rent The Runway \ud83e\udd84, first fashion recommendation ML. Founded ML at Barnes & Nobles. Past, @Virevol, Unilever, HP, ...", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "sanealytics.com", "expanded_url": "http://sanealytics.com", "indices": [0, 23], "url": "https://t.co/soqfwJz228"}]}}, "followers_count": 1451, "location": "NoLIta, Manhattan", "url": "https://x.com/analyticsaurabh", "follow_url": "https://x.com/intent/follow?screen_name=analyticsaurabh"}, "url": "https://x.com/analyticsaurabh/status/1747858959023681759", "like_url": "https://x.com/intent/like?tweet_id=1747858959023681759", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747858959023681759", "replies": [], "score": 0.2, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Resource", "location": "related work", "is_branch": true}, "1747859740242464773": {"created_at": "Thu Jan 18 05:53:30 +0000 2024", "entities": [{"indices": [24, 124], "type": "text", "text": "Really. I was reading this the other way, that the small model was supervising. Maybe I am confused."}], "favorite_count": 1, "id_str": "1747859740242464773", "in_reply_to_status_id_str": "1747526171196260390", "lang": "en", "user": {"id_str": "223231567", "name": "Bryan Bischof fka Dr. Donut", "screen_name": "BEBischof", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1253895605287628800/w5N4U8rY_normal.jpg", "description": "Hedge Knight. Teach ML @rutgersu; Prev: Led AI @_hex_tech; Led Data @weights_biases, ML @stitchfix, Led Data @bluebottleroast", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "bio.site/Docdonut", "expanded_url": "https://bio.site/Docdonut", "indices": [0, 23], "url": "https://t.co/na4TqOWqm6"}]}}, "followers_count": 3964, "location": "Ohlone Territory", "url": "https://x.com/BEBischof", "follow_url": "https://x.com/intent/follow?screen_name=BEBischof"}, "url": "https://x.com/BEBischof/status/1747859740242464773", "like_url": "https://x.com/intent/like?tweet_id=1747859740242464773", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747859740242464773", "replies": ["1748177033098907802"], "score": 0.2, "thread_score": 0, "reply_count": 1}, "1747974945877999642": {"created_at": "Thu Jan 18 13:31:17 +0000 2024", "entities": [{"display_url": "tinyurl.com/yrlmzbwe", "expanded_url": "http://tinyurl.com/yrlmzbwe", "indices": [0, 23], "url": "https://t.co/pQG8uIPcIn", "type": "url", "href": "http://tinyurl.com/yrlmzbwe", "text": "tinyurl.com/yrlmzbwe"}, {"indices": [23, 258], "type": "text", "text": " Introducing proxy-tuning: an efficient technique to adapt large language models by fine-tuning smaller ones &amp; applying the learned shifts at decoding time, boosting performance &amp; even surpassing trained models in truthfulness."}], "favorite_count": 0, "id_str": "1747974945877999642", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/xqZcLuzEaP", "expanded_url": "https://x.com/arxivsanitybot/status/1747974945877999642/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1747974943562735616", "indices": [259, 282], "media_key": "3_1747974943562735616", "media_results": {"result": {"media_key": "3_1747974943562735616"}}, "media_url_https": "https://pbs.twimg.com/media/GEIN8zNXIAAcmx4.jpg", "original_info": {"focus_rects": [{"h": 611, "w": 1091, "x": 0, "y": 0}, {"h": 611, "w": 611, "x": 0, "y": 0}, {"h": 611, "w": 536, "x": 0, "y": 0}, {"h": 611, "w": 306, "x": 4, "y": 0}, {"h": 611, "w": 1263, "x": 0, "y": 0}], "height": 611, "width": 1263}, "sizes": {"large": {"h": 611, "resize": "fit", "w": 1263}, "medium": {"h": 581, "resize": "fit", "w": 1200}, "small": {"h": 329, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/xqZcLuzEaP"}], "user": {"id_str": "1637708085958696961", "name": "ml-sanity bot", "screen_name": "arxivsanitybot", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1637710261258952706/FW4rQql-_normal.jpg", "description": "I am an open-source ChatGPT bot. Every day I summarize in one sentence the hottest papers on arXiv. Brought to you by @jackvianello. Not affiliated with arXiv.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "github.com/giacomov/arxiv\u2026", "expanded_url": "https://github.com/giacomov/arxiv-sanity-bot", "indices": [0, 23], "url": "https://t.co/1xRo5n5fiw"}]}}, "followers_count": 284, "location": "", "url": "https://x.com/arxivsanitybot", "follow_url": "https://x.com/intent/follow?screen_name=arxivsanitybot"}, "url": "https://x.com/arxivsanitybot/status/1747974945877999642", "like_url": "https://x.com/intent/like?tweet_id=1747974945877999642", "reply_url": "https://x.com/intent/tweet?in_reply_to=1747974945877999642", "replies": [], "score": 0, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Teaser", "is_branch": true}, "1748021765790376385": {"created_at": "Thu Jan 18 16:37:20 +0000 2024", "entities": [{"indices": [0, 119], "type": "text", "text": "There's a new promising method for finetuning LLMs without modifying their weights called \nproxy-tuning (by Liu et al. "}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [119, 142], "url": "https://t.co/3PjF0NtlOM", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}, {"indices": [142, 1803], "type": "text", "text": ").\nHow does it work? It's a simple decoding-time method where you modify the logits of the target LLM. In particular, you compute the logits' difference between a smaller base and finetuning model, then apply the difference to the target model's logits.\n\nMore concretely, suppose the goal is to improve a large target model (M1). \n\nThe main idea is to take two small models:\n- a small base model (M2)\n- a finetuned base model (M3)\n\nThen, you simply apply the difference in the smaller models' predictions (logits over the output vocabulary) to the target model M1. \n\nThe improved target model's outputs are calculated as M1*(x) = M1(x) + [M3(x) - M2(x)]\n\nBased on the experimental results, this works surprisingly well. The authors tested this on \nA. instruction-tuning\nB. domain adaptation\nC. task-specific finetuning\n\nFor brevity, focusing only on point A, here's a concrete example:\n\n1) The goal was to improve a Llama 2 70B Base model to the level of Llama 2 70B Chat but without doing any RLHF to get the model from Base -> Chat. \n\n2) They took a 10x smaller Llama 2 7B model and instruction-finetuned it. \n\n3) After finetuning, they computed the difference in logits over the output vocabulary between 7B Base and 7B Finetuned \n\n4) They applied the difference from 3) to the Llama 2 70B Base model. This pushed the 70B Base model's performance pretty close to 70B Chat.\n\nThe only caveat of this method is, of course, that your smaller models have to be trained on the same vocabulary as the larger model. Theoretically, if one knew the GPT-4 vocabulary and had access to its logit outputs, one could create new specialized GPT-4 models with this approach."}], "favorite_count": 1826, "id_str": "1748021765790376385", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/kkC8apclhl", "expanded_url": "https://x.com/rasbt/status/1748021765790376385/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1748021709783924736", "indices": [277, 300], "media_key": "3_1748021709783924736", "media_results": {"result": {"media_key": "3_1748021709783924736"}}, "media_url_https": "https://pbs.twimg.com/media/GEI4e89XgAAwUz_.jpg", "original_info": {"focus_rects": [{"h": 922, "w": 1646, "x": 0, "y": 0}, {"h": 1210, "w": 1210, "x": 0, "y": 0}, {"h": 1210, "w": 1061, "x": 0, "y": 0}, {"h": 1210, "w": 605, "x": 150, "y": 0}, {"h": 1210, "w": 1646, "x": 0, "y": 0}], "height": 1210, "width": 1646}, "sizes": {"large": {"h": 1210, "resize": "fit", "w": 1646}, "medium": {"h": 882, "resize": "fit", "w": 1200}, "small": {"h": 500, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/kkC8apclhl"}], "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748021765790376385", "like_url": "https://x.com/intent/like?tweet_id=1748021765790376385", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748021765790376385", "replies": ["1748030792624935034", "1748022920008364201", "1748031547536544076", "1748024605585871153", "1748023768037933546", "1748067983350755401", "1748030281058288020", "1749342873039110303", "1748025974669901910", "1748034121383719132", "1748027644677914844", "1748029066454691897", "1748039405489516757", "1748068797163151410", "1748108737305280708", "1749354006340853805", "1758205655675207912", "1748041476880400848", "1748046758855258545", "1748048115263787199", "1748056347697123670", "1748063867505176787", "1748068042615976291", "1748085650664910906", "1748257530646778344", "1748280216894550193", "1748417473257361917", "1748614903412490492"], "score": 0, "thread_score": 2, "reply_count": 83, "tweet_type": "Overview", "location": "abstract", "is_branch": true}, "1748022920008364201": {"created_at": "Thu Jan 18 16:41:55 +0000 2024", "entities": [{"indices": [7, 257], "type": "text", "text": "Are people already using OpenAI output logits when using GPT-4 to create synthetic datasets? Seems like it would give you much more information, similar to this proxy-tuning approach.\n\nI wonder how long before OpenAI stops supporting logit outputs :("}], "favorite_count": 10, "id_str": "1748022920008364201", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "185659268", "name": "Thomas Ahle", "screen_name": "thomasahle", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1837923668170887169/dCOwf_sy_normal.jpg", "description": "Head of AI @NormalComputing. Ex @Meta, @BARCdk, SupWiz, @OxfordQuantum. Tweets on Math, AI, #dspy, Probability, ML, Algorithms and Randomness. Recently tensors.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "thomasahle.com", "expanded_url": "https://thomasahle.com", "indices": [0, 23], "url": "https://t.co/EkMUe2lnQ9"}]}}, "followers_count": 7908, "location": "Copenhagen ", "url": "https://x.com/thomasahle", "follow_url": "https://x.com/intent/follow?screen_name=thomasahle"}, "url": "https://x.com/thomasahle/status/1748022920008364201", "like_url": "https://x.com/intent/like?tweet_id=1748022920008364201", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748022920008364201", "replies": ["1748025996933050865", "1748025357955961022"], "score": 0.4, "thread_score": 0.3, "reply_count": 18, "tweet_type": "Q&A", "location": "method", "is_branch": true}, "1748023417440498029": {"created_at": "Thu Jan 18 16:43:54 +0000 2024", "entities": [{"indices": [0, 12], "text": "#proxytuning", "type": "hashtag", "href": "https://x.com/hashtag/proxytuning"}], "favorite_count": 0, "id_str": "1748023417440498029", "quoted_status_id_str": "1748021765790376385", "lang": "qht", "user": {"id_str": "352460009", "name": "V_59", "screen_name": "vigneshtamizh", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1654491239528423425/ZrZsvHzu_normal.jpg", "description": "LLMs, Model Parallelism, PipeLine Parallelism,\nAI Engineer, works on Generative AI.\n\n@ortist - Inspiration", "entities": {"description": {"urls": []}}, "followers_count": 142, "location": "chennai", "url": "https://x.com/vigneshtamizh", "follow_url": "https://x.com/intent/follow?screen_name=vigneshtamizh"}, "url": "https://x.com/vigneshtamizh/status/1748023417440498029", "like_url": "https://x.com/intent/like?tweet_id=1748023417440498029", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748023417440498029", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748023768037933546": {"created_at": "Thu Jan 18 16:45:17 +0000 2024", "entities": [{"indices": [7, 174], "type": "text", "text": "Question: Is the intended use case deployment on edge devices ? Cause one of the reason to use lora is GPU efficiency and this method looks like it needs 3x GPU usage."}], "favorite_count": 6, "id_str": "1748023768037933546", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1606552808", "name": "prakyath kantharaju", "screen_name": "prakyath_k", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1844030695737319424/piXdPfcZ_normal.jpg", "description": "PhD in robotics, ML, RL and AI. Working on machine learning and AI.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "prakyathk.com", "expanded_url": "http://prakyathk.com", "indices": [0, 23], "url": "https://t.co/bi4PyQK5l0"}]}}, "followers_count": 266, "location": "Chicago, IL", "url": "https://x.com/prakyath_k", "follow_url": "https://x.com/intent/follow?screen_name=prakyath_k"}, "url": "https://x.com/prakyath_k/status/1748023768037933546", "like_url": "https://x.com/intent/like?tweet_id=1748023768037933546", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748023768037933546", "replies": ["1748024634241348048"], "score": 0.9, "thread_score": 0.9, "reply_count": 1, "tweet_type": "Q&A", "location": "abstract", "is_branch": true}, "1748024347183480838": {"created_at": "Thu Jan 18 16:47:35 +0000 2024", "entities": [{"indices": [0, 284], "type": "text", "text": "I love how the community is (slowly) accepting that we can and should raise the level of abstraction on ML terms.\n\nOptimizing without modifying the weights? Yes!\n\nWe teach undergrads the difference between problems &amp; algorithms. You care about the *spec* not how it's implemented!"}], "favorite_count": 100, "id_str": "1748024347183480838", "quoted_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1605274291569799168", "name": "Omar Khattab", "screen_name": "lateinteraction", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1613558765764374528/aZQB6U4b_normal.jpg", "description": "Incoming asst professor @MIT EECS. Research scientist @Databricks.\n@StanfordNLP CS PhD. Author of https://t.co/VgyLxl0VZz & https://t.co/ZZaSzaRIOF.", "entities": {"description": {"urls": [{"display_url": "ColBERT.ai", "expanded_url": "http://ColBERT.ai", "indices": [98, 121], "url": "https://t.co/VgyLxl0VZz"}, {"display_url": "DSPy.ai", "expanded_url": "http://DSPy.ai", "indices": [124, 147], "url": "https://t.co/ZZaSzaRIOF"}]}, "url": {"urls": [{"display_url": "omarkhattab.com", "expanded_url": "https://omarkhattab.com/", "indices": [0, 23], "url": "https://t.co/5cQ4f28NzC"}]}}, "followers_count": 18411, "location": "Stanford, CA", "url": "https://x.com/lateinteraction", "follow_url": "https://x.com/intent/follow?screen_name=lateinteraction"}, "url": "https://x.com/lateinteraction/status/1748024347183480838", "like_url": "https://x.com/intent/like?tweet_id=1748024347183480838", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748024347183480838", "replies": ["1748030551787717076"], "score": 0, "thread_score": 0.6, "reply_count": 1, "tweet_type": "Perspective", "location": "abstract", "is_branch": true}, "1748024605585871153": {"created_at": "Thu Jan 18 16:48:37 +0000 2024", "entities": [{"indices": [7, 268], "type": "text", "text": "IIUC, you modify the output logits with the formula you showed M1*(x) = M1(x) + [M3(x) - M2(x)]. Then, in order to generate text, you convert the logits to probabilities, and use something like nucleus sampling or top-k sampling to the new probabilities. Right?"}], "favorite_count": 9, "id_str": "1748024605585871153", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1308811981", "name": "andrea panizza", "screen_name": "unsorsodicorda", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1218915905884901376/WGhVmM4z_normal.jpg", "description": "Data Scientist, aerospace engineer, trekking & comics lover, applying #MachineLearning #DeepLearning Statistics to Industrial Applications.", "entities": {"description": {"urls": []}}, "followers_count": 1863, "location": "Firenze, Toscana", "url": "https://x.com/unsorsodicorda", "follow_url": "https://x.com/intent/follow?screen_name=unsorsodicorda"}, "url": "https://x.com/unsorsodicorda/status/1748024605585871153", "like_url": "https://x.com/intent/like?tweet_id=1748024605585871153", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748024605585871153", "replies": ["1748024919244382481"], "score": 0.5, "thread_score": 0.5, "reply_count": 5, "tweet_type": "Q&A", "location": "method", "is_branch": true}, "1748024634241348048": {"created_at": "Thu Jan 18 16:48:44 +0000 2024", "entities": [{"indices": [12, 194], "type": "text", "text": "I think the intended use-case is probably more like R&amp;D efficiency: develop new methods, use them on smaller models to save costs, then use these to boost your bigger base models"}], "favorite_count": 6, "id_str": "1748024634241348048", "in_reply_to_status_id_str": "1748023768037933546", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748024634241348048", "like_url": "https://x.com/intent/like?tweet_id=1748024634241348048", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748024634241348048", "replies": [], "score": 0.7, "thread_score": 0.7, "reply_count": 0}, "1748024919244382481": {"created_at": "Thu Jan 18 16:49:52 +0000 2024", "entities": [{"indices": [16, 110], "type": "text", "text": "Yes, that's correct. This detail is not shown in the figure, but yes that's what you would do."}], "favorite_count": 7, "id_str": "1748024919244382481", "in_reply_to_status_id_str": "1748024605585871153", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748024919244382481", "like_url": "https://x.com/intent/like?tweet_id=1748024919244382481", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748024919244382481", "replies": ["1748025235776143816"], "score": 0.7, "thread_score": 0.7, "reply_count": 4}, "1748025235776143816": {"created_at": "Thu Jan 18 16:51:07 +0000 2024", "entities": [{"indices": [7, 110], "type": "text", "text": "Very nice! I only had time to skim through the abstract, it looked nice. A nice topic for a blog post \ud83d\ude09"}], "favorite_count": 2, "id_str": "1748025235776143816", "in_reply_to_status_id_str": "1748024919244382481", "lang": "en", "user": {"id_str": "1308811981", "name": "andrea panizza", "screen_name": "unsorsodicorda", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1218915905884901376/WGhVmM4z_normal.jpg", "description": "Data Scientist, aerospace engineer, trekking & comics lover, applying #MachineLearning #DeepLearning Statistics to Industrial Applications.", "entities": {"description": {"urls": []}}, "followers_count": 1863, "location": "Firenze, Toscana", "url": "https://x.com/unsorsodicorda", "follow_url": "https://x.com/intent/follow?screen_name=unsorsodicorda"}, "url": "https://x.com/unsorsodicorda/status/1748025235776143816", "like_url": "https://x.com/intent/like?tweet_id=1748025235776143816", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748025235776143816", "replies": ["1748025752811934089"], "score": 0.1, "thread_score": 0, "reply_count": 3}, "1748025357955961022": {"created_at": "Thu Jan 18 16:51:36 +0000 2024", "entities": [{"indices": [19, 298], "type": "text", "text": "They would probably only need to stop supporting logit outputs once their edge/revenue starts getting eaten by other models.... which might be a while haha\n\nI guess they could start only enabling it for older models but people will essentially mine the logits from outputs anyway"}], "favorite_count": 0, "id_str": "1748025357955961022", "in_reply_to_status_id_str": "1748022920008364201", "lang": "en", "user": {"id_str": "1177977934348476417", "name": "arun", "screen_name": "arundotai", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1751462203452989440/LoKrjsXr_normal.jpg", "description": "co-founder/CTO @magna_digital. serving billions of dollars to millions of users \ud83e\udd17", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "arun.ai", "expanded_url": "http://arun.ai/", "indices": [0, 23], "url": "https://t.co/J8IOZPw5vn"}]}}, "followers_count": 993, "location": "\ud83c\udde8\ud83c\udde6 \u2192 nyc", "url": "https://x.com/arundotai", "follow_url": "https://x.com/intent/follow?screen_name=arundotai"}, "url": "https://x.com/arundotai/status/1748025357955961022", "like_url": "https://x.com/intent/like?tweet_id=1748025357955961022", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748025357955961022", "replies": [], "score": 0.2, "thread_score": 0, "reply_count": 0}, "1748025752811934089": {"created_at": "Thu Jan 18 16:53:10 +0000 2024", "entities": [{"indices": [16, 107], "type": "text", "text": "Yes! It should also be easy to use with any repo or framework (lit-gpt, transformers, etc.)"}], "favorite_count": 1, "id_str": "1748025752811934089", "in_reply_to_status_id_str": "1748025235776143816", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748025752811934089", "like_url": "https://x.com/intent/like?tweet_id=1748025752811934089", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748025752811934089", "replies": ["1748026909026394395"], "score": 0.1, "thread_score": 0, "reply_count": 2}, "1748025974669901910": {"created_at": "Thu Jan 18 16:54:03 +0000 2024", "entities": [{"indices": [0, 360], "type": "text", "text": "Impressive benchmark results.\n\nAs the paper says \"that tokenizers are often open-source, even for closed-source models like GPT-4 (i.e. tiktoken), making it feasible to steer these models with small, open-source models. When vocabularies do not match, techniques like \"Twist Decoding: Diverse Generators Guide Each Other\" Kasai et al. (2022) could be applied.\""}], "favorite_count": 7, "id_str": "1748025974669901910", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/C8B22hcKHc", "expanded_url": "https://x.com/rohanpaul_ai/status/1748025974669901910/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1748025062060654593", "indices": [283, 306], "media_key": "3_1748025062060654593", "media_results": {"result": {"media_key": "3_1748025062060654593"}}, "media_url_https": "https://pbs.twimg.com/media/GEI7iFKbAAEOyLR.png", "original_info": {"focus_rects": [{"h": 424, "w": 758, "x": 0, "y": 0}, {"h": 471, "w": 471, "x": 287, "y": 0}, {"h": 471, "w": 413, "x": 345, "y": 0}, {"h": 471, "w": 236, "x": 506, "y": 0}, {"h": 471, "w": 758, "x": 0, "y": 0}], "height": 471, "width": 758}, "sizes": {"large": {"h": 471, "resize": "fit", "w": 758}, "medium": {"h": 471, "resize": "fit", "w": 758}, "small": {"h": 423, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/C8B22hcKHc"}], "user": {"id_str": "2588345408", "name": "Rohan Paul", "screen_name": "rohanpaul_ai", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1816185267037859840/Fd18CH0v_normal.jpg", "description": "\ud83d\udcbc Engineer.\n\n\ud83d\udcda I also write daily on actionable AI developments.\n\n\ud83d\uddde\ufe0f Get a 1300+ page free Python book as soon as you sign up \u2192 https://t.co/Jfj0r0wLUN", "entities": {"description": {"urls": [{"display_url": "rohanpaul.substack.com", "expanded_url": "http://rohanpaul.substack.com", "indices": [128, 151], "url": "https://t.co/Jfj0r0wLUN"}]}, "url": {"urls": [{"display_url": "rohanpaul.substack.com", "expanded_url": "http://rohanpaul.substack.com", "indices": [0, 23], "url": "https://t.co/Jfj0r0wLUN"}]}}, "followers_count": 62667, "location": "Ex Inv Banker (Deutsche)", "url": "https://x.com/rohanpaul_ai", "follow_url": "https://x.com/intent/follow?screen_name=rohanpaul_ai"}, "url": "https://x.com/rohanpaul_ai/status/1748025974669901910", "like_url": "https://x.com/intent/like?tweet_id=1748025974669901910", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748025974669901910", "replies": [], "score": 0.2, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Perspective", "location": "introduction", "is_branch": true}, "1748025996933050865": {"created_at": "Thu Jan 18 16:54:09 +0000 2024", "entities": [{"indices": [12, 133], "type": "text", "text": "I thought the OpenAI API only outputs top-k logits, not all logits for the whole vocabulary. Pls correct me if I'm wrong."}], "favorite_count": 9, "id_str": "1748025996933050865", "in_reply_to_status_id_str": "1748022920008364201", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748025996933050865", "like_url": "https://x.com/intent/like?tweet_id=1748025996933050865", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748025996933050865", "replies": ["1748028658109857892", "1748047133176168801", "1748028084492894340", "1748077021949726986"], "score": 0.7, "thread_score": 0.7, "reply_count": 16}, "1748026757213454770": {"created_at": "Thu Jan 18 16:57:10 +0000 2024", "entities": [{"indices": [0, 84], "type": "text", "text": "Proxy-tuning. This hypes me more than ChatGPT team plan \u2026 Worth keeping an eye on it"}], "favorite_count": 3, "id_str": "1748026757213454770", "quoted_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1688844166363537409", "name": "Mathieu Trachino", "screen_name": "AI_NewsWaltz", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1796320905011859456/1hFtrhwR_normal.jpg", "description": "I build LLM apps, Data scientist solopreneur, NLP & new tech enthusiast", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "gendojo.ai", "expanded_url": "http://gendojo.ai", "indices": [0, 23], "url": "https://t.co/Qf0ihiBIlF"}]}}, "followers_count": 901, "location": "Paris, France", "url": "https://x.com/AI_NewsWaltz", "follow_url": "https://x.com/intent/follow?screen_name=AI_NewsWaltz"}, "url": "https://x.com/AI_NewsWaltz/status/1748026757213454770", "like_url": "https://x.com/intent/like?tweet_id=1748026757213454770", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748026757213454770", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0, "is_branch": true}, "1748026909026394395": {"created_at": "Thu Jan 18 16:57:46 +0000 2024", "entities": [{"indices": [7, 107], "type": "text", "text": "It's probably a matter of days before someone releases some proxy tuning code on HuggingFace Space \ud83d\ude42"}], "favorite_count": 1, "id_str": "1748026909026394395", "in_reply_to_status_id_str": "1748025752811934089", "lang": "en", "user": {"id_str": "1308811981", "name": "andrea panizza", "screen_name": "unsorsodicorda", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1218915905884901376/WGhVmM4z_normal.jpg", "description": "Data Scientist, aerospace engineer, trekking & comics lover, applying #MachineLearning #DeepLearning Statistics to Industrial Applications.", "entities": {"description": {"urls": []}}, "followers_count": 1863, "location": "Firenze, Toscana", "url": "https://x.com/unsorsodicorda", "follow_url": "https://x.com/intent/follow?screen_name=unsorsodicorda"}, "url": "https://x.com/unsorsodicorda/status/1748026909026394395", "like_url": "https://x.com/intent/like?tweet_id=1748026909026394395", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748026909026394395", "replies": ["1748027587626942669"], "score": 0.1, "thread_score": 0, "reply_count": 1}, "1748027587626942669": {"created_at": "Thu Jan 18 17:00:28 +0000 2024", "entities": [{"indices": [16, 83], "type": "text", "text": "In an ideal world, there would be a link to the code in the paper \ud83d\ude43"}], "favorite_count": 1, "id_str": "1748027587626942669", "in_reply_to_status_id_str": "1748026909026394395", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748027587626942669", "like_url": "https://x.com/intent/like?tweet_id=1748027587626942669", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748027587626942669", "replies": [], "score": 0.1, "thread_score": 0, "reply_count": 0}, "1748027644677914844": {"created_at": "Thu Jan 18 17:00:41 +0000 2024", "entities": [{"indices": [7, 147], "type": "text", "text": "This really reminds me of many first-order approximations that you find in physics that so often work nearly as well as the full computation"}], "favorite_count": 3, "id_str": "1748027644677914844", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1440707491487105042", "name": "Szymon Prajs", "screen_name": "szymonprajs", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1440712857717334024/2v_lnKEV_normal.jpg", "description": "Founder and CEO @OberonRobotics. Building the future of home companions. Robotics, AI, Computer Vision, keen gardener and ex-astronomer.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "oberonrobotics.com", "expanded_url": "http://oberonrobotics.com", "indices": [0, 23], "url": "https://t.co/f17FhKBd1E"}]}}, "followers_count": 77, "location": "Oxfordshire", "url": "https://x.com/szymonprajs", "follow_url": "https://x.com/intent/follow?screen_name=szymonprajs"}, "url": "https://x.com/szymonprajs/status/1748027644677914844", "like_url": "https://x.com/intent/like?tweet_id=1748027644677914844", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748027644677914844", "replies": [], "score": 0.5, "thread_score": 0.5, "reply_count": 0, "tweet_type": "Perspective", "location": "introduction", "is_branch": true}, "1748028084492894340": {"created_at": "Thu Jan 18 17:02:26 +0000 2024", "entities": [{"indices": [19, 219], "type": "text", "text": "Even that is enough to create so many variations of synthetic data. \nEven if it gives the top 10 tokens there is a possibility of (max) 10^n where n is the number of tokens in the synthetic statement."}], "favorite_count": 0, "id_str": "1748028084492894340", "in_reply_to_status_id_str": "1748025996933050865", "lang": "en", "user": {"id_str": "64595028", "name": "Arnav Gupta", "screen_name": "arnav_g97", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1592033270317084672/lI5bpaMS_normal.jpg", "description": "i post demos |\n\ni do knowledge graphs | ml | nlp\n\nautomating investors thought process", "entities": {"description": {"urls": []}}, "followers_count": 23, "location": "New Delhi, India", "url": "https://x.com/arnav_g97", "follow_url": "https://x.com/intent/follow?screen_name=arnav_g97"}, "url": "https://x.com/arnav_g97/status/1748028084492894340", "like_url": "https://x.com/intent/like?tweet_id=1748028084492894340", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748028084492894340", "replies": [], "score": 0.2, "thread_score": 0, "reply_count": 0}, "1748028658109857892": {"created_at": "Thu Jan 18 17:04:43 +0000 2024", "entities": [{"indices": [7, 107], "type": "text", "text": "You're right. But top-10 logits is still a lot more signal than top-1 when doing model distillation."}], "favorite_count": 4, "id_str": "1748028658109857892", "in_reply_to_status_id_str": "1748025996933050865", "lang": "en", "user": {"id_str": "185659268", "name": "Thomas Ahle", "screen_name": "thomasahle", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1837923668170887169/dCOwf_sy_normal.jpg", "description": "Head of AI @NormalComputing. Ex @Meta, @BARCdk, SupWiz, @OxfordQuantum. Tweets on Math, AI, #dspy, Probability, ML, Algorithms and Randomness. Recently tensors.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "thomasahle.com", "expanded_url": "https://thomasahle.com", "indices": [0, 23], "url": "https://t.co/EkMUe2lnQ9"}]}}, "followers_count": 7908, "location": "Copenhagen ", "url": "https://x.com/thomasahle", "follow_url": "https://x.com/intent/follow?screen_name=thomasahle"}, "url": "https://x.com/thomasahle/status/1748028658109857892", "like_url": "https://x.com/intent/like?tweet_id=1748028658109857892", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748028658109857892", "replies": ["1748029985149821303", "1748029229994795170"], "score": 0.3, "thread_score": 0, "reply_count": 12}, "1748028787995086906": {"created_at": "Thu Jan 18 17:05:14 +0000 2024", "entities": [{"indices": [0, 194], "type": "text", "text": "Seems like base models are getting \u201cgood enough;\u201d yet still so many opportunities to iterate downstream (on new approaches to finetuning and prompt evolution) and upstream (better data curation)"}], "favorite_count": 4, "id_str": "1748028787995086906", "quoted_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "2539212208", "name": "Sarah Catanzaro", "screen_name": "sarahcat21", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1333644490532413441/Cu9IvkII_normal.jpg", "description": "\u201cAll methods are sacred if they are internally necessary\u201d (GP @amplifypartners, prev @canvasvc; Head of Data @Mattermark; @palantirtech; @c4ads)", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "starckmarcandthefarc.wordpress.com", "expanded_url": "http://starckmarcandthefarc.wordpress.com/", "indices": [0, 23], "url": "https://t.co/sOmcfpgJzF"}]}}, "followers_count": 13330, "location": "", "url": "https://x.com/sarahcat21", "follow_url": "https://x.com/intent/follow?screen_name=sarahcat21"}, "url": "https://x.com/sarahcat21/status/1748028787995086906", "like_url": "https://x.com/intent/like?tweet_id=1748028787995086906", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748028787995086906", "replies": [], "score": 0, "thread_score": 0.6, "reply_count": 0, "tweet_type": "Perspective", "location": "abstract", "is_branch": true}, "1748029066454691897": {"created_at": "Thu Jan 18 17:06:20 +0000 2024", "entities": [{"indices": [7, 67], "type": "text", "text": "This is interesting! Will definitely check out the preprint!"}], "favorite_count": 1, "id_str": "1748029066454691897", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "703393363605770240", "name": "Ronny Polle", "screen_name": "RonnyPolle", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1734615383548850176/rPNg5-Xn_normal.jpg", "description": "Medical Doctor / ML & DS Freelancer / prev. Research Intern @ CMU / Aspiring Healthcare Research SWE\n\nchess player\n\n~ views are mine", "entities": {"description": {"urls": []}}, "followers_count": 390, "location": "Ghana", "url": "https://x.com/RonnyPolle", "follow_url": "https://x.com/intent/follow?screen_name=RonnyPolle"}, "url": "https://x.com/RonnyPolle/status/1748029066454691897", "like_url": "https://x.com/intent/like?tweet_id=1748029066454691897", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748029066454691897", "replies": [], "score": 0.1, "thread_score": 0.1, "reply_count": 0, "is_branch": true}, "1748029229994795170": {"created_at": "Thu Jan 18 17:06:59 +0000 2024", "entities": [{"indices": [7, 19], "type": "text", "text": "I wonder if "}, {"id_str": "1213524255838593024", "indices": [19, 30], "name": "Ronen Eldan", "screen_name": "EldanRonen", "type": "mention", "href": "https://x.com/EldanRonen", "text": "@EldanRonen"}, {"indices": [30, 76], "type": "text", "text": " and Yuanzhi Li considered it for TinyStories?"}], "favorite_count": 0, "id_str": "1748029229994795170", "in_reply_to_status_id_str": "1748028658109857892", "lang": "en", "user": {"id_str": "185659268", "name": "Thomas Ahle", "screen_name": "thomasahle", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1837923668170887169/dCOwf_sy_normal.jpg", "description": "Head of AI @NormalComputing. Ex @Meta, @BARCdk, SupWiz, @OxfordQuantum. Tweets on Math, AI, #dspy, Probability, ML, Algorithms and Randomness. Recently tensors.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "thomasahle.com", "expanded_url": "https://thomasahle.com", "indices": [0, 23], "url": "https://t.co/EkMUe2lnQ9"}]}}, "followers_count": 7908, "location": "Copenhagen ", "url": "https://x.com/thomasahle", "follow_url": "https://x.com/intent/follow?screen_name=thomasahle"}, "url": "https://x.com/thomasahle/status/1748029229994795170", "like_url": "https://x.com/intent/like?tweet_id=1748029229994795170", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748029229994795170", "replies": ["1748398731274420723"], "score": 0.1, "thread_score": 0, "reply_count": 3}, "1748029985149821303": {"created_at": "Thu Jan 18 17:09:59 +0000 2024", "entities": [{"indices": [12, 192], "type": "text", "text": "Do they show you the tokens associated with all top-10 tokens btw? In that case, you could potentially still apply this proxy tuning method if you used a similar tokenizer as GPT-4"}], "favorite_count": 1, "id_str": "1748029985149821303", "in_reply_to_status_id_str": "1748028658109857892", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748029985149821303", "like_url": "https://x.com/intent/like?tweet_id=1748029985149821303", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748029985149821303", "replies": ["1748031871064183185"], "score": 0.3, "thread_score": 0, "reply_count": 7}, "1748030281058288020": {"created_at": "Thu Jan 18 17:11:10 +0000 2024", "entities": [{"indices": [7, 28], "type": "text", "text": "Why does this work? \ud83e\udd14"}], "favorite_count": 1, "id_str": "1748030281058288020", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "64802222", "name": "Saket", "screen_name": "maybmb_", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1594563612416544769/c8lkwKy2_normal.jpg", "description": "It's nice to be important, but it's important to be nice...", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "500px.com/saketsharma", "expanded_url": "https://500px.com/saketsharma", "indices": [0, 23], "url": "https://t.co/jTaTDqGaPq"}]}}, "followers_count": 278, "location": "", "url": "https://x.com/maybmb_", "follow_url": "https://x.com/intent/follow?screen_name=maybmb_"}, "url": "https://x.com/maybmb_/status/1748030281058288020", "like_url": "https://x.com/intent/like?tweet_id=1748030281058288020", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748030281058288020", "replies": ["1748031001618464839"], "score": 0.4, "thread_score": 0.6, "reply_count": 4, "tweet_type": "Q&A", "location": "method", "is_branch": true}, "1748030551787717076": {"created_at": "Thu Jan 18 17:12:15 +0000 2024", "entities": [{"indices": [17, 48], "type": "text", "text": "Black-boxification of LLMs haha"}], "favorite_count": 2, "id_str": "1748030551787717076", "in_reply_to_status_id_str": "1748024347183480838", "lang": "en", "user": {"id_str": "272496536", "name": "San", "screen_name": "majedsays", "profile_image_url_https": "https://pbs.twimg.com/profile_images/886000760827392000/f6m4Sxb__normal.jpg", "description": "3 lb jelly", "entities": {"description": {"urls": []}}, "followers_count": 61, "location": "", "url": "https://x.com/majedsays", "follow_url": "https://x.com/intent/follow?screen_name=majedsays"}, "url": "https://x.com/majedsays/status/1748030551787717076", "like_url": "https://x.com/intent/like?tweet_id=1748030551787717076", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748030551787717076", "replies": [], "score": 0.1, "thread_score": 0.1, "reply_count": 0, "is_branch": true}, "1748030792624935034": {"created_at": "Thu Jan 18 17:13:12 +0000 2024", "entities": [{"indices": [7, 66], "type": "text", "text": "waittt this is not original, this was done back in october "}, {"display_url": "arxiv.org/abs/2310.12962", "expanded_url": "https://arxiv.org/abs/2310.12962", "indices": [66, 89], "url": "https://t.co/DLKnsNuz8C", "type": "url", "href": "https://arxiv.org/abs/2310.12962", "text": "arxiv.org/abs/2310.12962"}], "favorite_count": 95, "id_str": "1748030792624935034", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1299856802268377090", "name": "Ben (e/treats)", "screen_name": "andersonbcdefg", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1299864018081865729/CMlOyn1u_normal.jpg", "description": "\ud83e\udd16 Computer scientist, next-word-prediction enjoyer\n\ud83d\udcca Prev. research fellow @ Stanford RegLab\n\ud83d\udee0\ufe0f bUiLdiNg sOmeThiNg nEw (https://t.co/mdYPZmjSzN - YC S23)\n\ud83c\udff3\ufe0f\u200d\ud83c\udf08", "entities": {"description": {"urls": [{"display_url": "trytaylor.ai", "expanded_url": "http://trytaylor.ai", "indices": [120, 143], "url": "https://t.co/mdYPZmjSzN"}]}, "url": {"urls": [{"display_url": "trytaylor.ai", "expanded_url": "https://trytaylor.ai", "indices": [0, 23], "url": "https://t.co/8ndhXQEa9x"}]}}, "followers_count": 5268, "location": "San Francisco, CA", "url": "https://x.com/andersonbcdefg", "follow_url": "https://x.com/intent/follow?screen_name=andersonbcdefg"}, "url": "https://x.com/andersonbcdefg/status/1748030792624935034", "like_url": "https://x.com/intent/like?tweet_id=1748030792624935034", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748030792624935034", "replies": ["1748075477703479741", "1748605662186426449"], "score": 0.8, "thread_score": 0.7, "reply_count": 18, "tweet_type": "Critique", "location": "related work", "is_branch": true}, "1748031001618464839": {"created_at": "Thu Jan 18 17:14:02 +0000 2024", "entities": [{"indices": [9, 174], "type": "text", "text": "I suspect that's because the Delta between a 7B Base and 7B Chat is similar to the Delta between 70B Base and 70B Chat, which is a positively surprising observation."}], "favorite_count": 9, "id_str": "1748031001618464839", "in_reply_to_status_id_str": "1748030281058288020", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748031001618464839", "like_url": "https://x.com/intent/like?tweet_id=1748031001618464839", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748031001618464839", "replies": ["1748031989494775949", "1748034619834818671"], "score": 0.8, "thread_score": 0.8, "reply_count": 3}, "1748031547536544076": {"created_at": "Thu Jan 18 17:16:12 +0000 2024", "entities": [{"indices": [7, 112], "type": "text", "text": "Wait, then what happen if you apply it on 70B chat?\ud83e\udd14\n\nSounds like free improvement for any model you want"}], "favorite_count": 2, "id_str": "1748031547536544076", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/eE3orljTz4", "expanded_url": "https://x.com/Yampeleg/status/1748031547536544076/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1748031152403738624", "indices": [113, 136], "media_key": "3_1748031152403738624", "media_results": {"result": {"media_key": "3_1748031152403738624"}}, "media_url_https": "https://pbs.twimg.com/media/GEJBEldXcAA1ssC.png", "original_info": {"focus_rects": [{"h": 182, "w": 325, "x": 0, "y": 0}, {"h": 197, "w": 197, "x": 128, "y": 0}, {"h": 197, "w": 173, "x": 149, "y": 0}, {"h": 197, "w": 99, "x": 186, "y": 0}, {"h": 197, "w": 325, "x": 0, "y": 0}], "height": 197, "width": 325}, "sizes": {"large": {"h": 197, "resize": "fit", "w": 325}, "medium": {"h": 197, "resize": "fit", "w": 325}, "small": {"h": 197, "resize": "fit", "w": 325}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/eE3orljTz4"}], "user": {"id_str": "634339745", "name": "Yam Peleg", "screen_name": "Yampeleg", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1856694742735527936/Uh1j-nZk_normal.jpg", "description": "AI & War it is", "entities": {"description": {"urls": []}}, "followers_count": 34449, "location": "", "url": "https://x.com/Yampeleg", "follow_url": "https://x.com/intent/follow?screen_name=Yampeleg"}, "url": "https://x.com/Yampeleg/status/1748031547536544076", "like_url": "https://x.com/intent/like?tweet_id=1748031547536544076", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748031547536544076", "replies": ["1748074367114793308"], "score": 0.7, "thread_score": 0.6, "reply_count": 1, "tweet_type": "Q&A", "location": "instruction-tuning experiments", "is_branch": true}, "1748031659167928553": {"created_at": "Thu Jan 18 17:16:39 +0000 2024", "entities": [{"indices": [0, 222], "type": "text", "text": "I\u2019m curious if this could be used to combat the backdoors examined in Anthropic\u2019s Sleeper Agents paper\u2026 Would this fine-tuning be enough to overcome such triggers? Would it require excessively heavy handed tuning to do so?"}], "favorite_count": 0, "id_str": "1748031659167928553", "quoted_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1719413993616322560", "name": "Dan Humphries", "screen_name": "dshumphr", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1738611449637883904/cCA6Gelz_normal.jpg", "description": "TPUs for all", "entities": {"description": {"urls": []}}, "followers_count": 34, "location": "", "url": "https://x.com/dshumphr", "follow_url": "https://x.com/intent/follow?screen_name=dshumphr"}, "url": "https://x.com/dshumphr/status/1748031659167928553", "like_url": "https://x.com/intent/like?tweet_id=1748031659167928553", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748031659167928553", "replies": [], "score": 0.4, "thread_score": 0.4, "reply_count": 0, "tweet_type": "Q&A", "location": "conclusion", "is_branch": true}, "1748031871064183185": {"created_at": "Thu Jan 18 17:17:29 +0000 2024", "entities": [{"indices": [7, 35], "type": "text", "text": "They do. Up to top-5. Check "}, {"display_url": "platform.openai.com/docs/api-refer\u2026", "expanded_url": "https://platform.openai.com/docs/api-reference/chat/create#chat-create-logprobs", "indices": [35, 58], "url": "https://t.co/ZkxhpeAWXk", "type": "url", "href": "https://platform.openai.com/docs/api-reference/chat/create#chat-create-logprobs", "text": "platform.openai.com/docs/api-refer\u2026"}], "favorite_count": 5, "id_str": "1748031871064183185", "in_reply_to_status_id_str": "1748029985149821303", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/qFXfderx7u", "expanded_url": "https://x.com/thomasahle/status/1748031871064183185/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": [{"h": 276, "w": 276, "x": 104, "y": 165}, {"h": 271, "w": 271, "x": 97, "y": 928}, {"h": 551, "w": 551, "x": 3, "y": 667}]}, "medium": {"faces": [{"h": 191, "w": 191, "x": 72, "y": 114}, {"h": 188, "w": 188, "x": 67, "y": 645}, {"h": 383, "w": 383, "x": 2, "y": 463}]}, "orig": {"faces": [{"h": 276, "w": 276, "x": 104, "y": 165}, {"h": 271, "w": 271, "x": 97, "y": 928}, {"h": 551, "w": 551, "x": 3, "y": 667}]}, "small": {"faces": [{"h": 108, "w": 108, "x": 41, "y": 65}, {"h": 106, "w": 106, "x": 38, "y": 365}, {"h": 217, "w": 217, "x": 1, "y": 263}]}}, "id_str": "1748031679405465600", "indices": [59, 82], "media_key": "3_1748031679405465600", "media_results": {"result": {"media_key": "3_1748031679405465600"}}, "media_url_https": "https://pbs.twimg.com/media/GEJBjQsXoAAJ58P.jpg", "original_info": {"focus_rects": [{"h": 456, "w": 814, "x": 0, "y": 160}, {"h": 814, "w": 814, "x": 0, "y": 0}, {"h": 928, "w": 814, "x": 0, "y": 0}, {"h": 1628, "w": 814, "x": 0, "y": 0}, {"h": 1726, "w": 814, "x": 0, "y": 0}], "height": 1726, "width": 814}, "sizes": {"large": {"h": 1726, "resize": "fit", "w": 814}, "medium": {"h": 1200, "resize": "fit", "w": 566}, "small": {"h": 680, "resize": "fit", "w": 321}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/qFXfderx7u"}], "user": {"id_str": "185659268", "name": "Thomas Ahle", "screen_name": "thomasahle", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1837923668170887169/dCOwf_sy_normal.jpg", "description": "Head of AI @NormalComputing. Ex @Meta, @BARCdk, SupWiz, @OxfordQuantum. Tweets on Math, AI, #dspy, Probability, ML, Algorithms and Randomness. Recently tensors.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "thomasahle.com", "expanded_url": "https://thomasahle.com", "indices": [0, 23], "url": "https://t.co/EkMUe2lnQ9"}]}}, "followers_count": 7908, "location": "Copenhagen ", "url": "https://x.com/thomasahle", "follow_url": "https://x.com/intent/follow?screen_name=thomasahle"}, "url": "https://x.com/thomasahle/status/1748031871064183185", "like_url": "https://x.com/intent/like?tweet_id=1748031871064183185", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748031871064183185", "replies": ["1748032472871207177", "1748035243687260543"], "score": 0.2, "thread_score": 0, "reply_count": 6}, "1748031989494775949": {"created_at": "Thu Jan 18 17:17:57 +0000 2024", "entities": [{"indices": [7, 254], "type": "text", "text": "This is weirdly surprising. Need to read the paper, but I wonder about the generalization of the approach. Does correlation between llama2 7b and 70b also play a role in this, given similarities in pretraining data and model arch (besides vocab).."}], "favorite_count": 0, "id_str": "1748031989494775949", "in_reply_to_status_id_str": "1748031001618464839", "lang": "en", "user": {"id_str": "64802222", "name": "Saket", "screen_name": "maybmb_", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1594563612416544769/c8lkwKy2_normal.jpg", "description": "It's nice to be important, but it's important to be nice...", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "500px.com/saketsharma", "expanded_url": "https://500px.com/saketsharma", "indices": [0, 23], "url": "https://t.co/jTaTDqGaPq"}]}}, "followers_count": 278, "location": "", "url": "https://x.com/maybmb_", "follow_url": "https://x.com/intent/follow?screen_name=maybmb_"}, "url": "https://x.com/maybmb_/status/1748031989494775949", "like_url": "https://x.com/intent/like?tweet_id=1748031989494775949", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748031989494775949", "replies": [], "score": 0.8, "thread_score": 0, "reply_count": 0}, "1748032472871207177": {"created_at": "Thu Jan 18 17:19:53 +0000 2024", "entities": [{"indices": [7, 190], "type": "text", "text": "As far as I can tell, it's not even more expensive.\nGenerating a length 10 completion with top-5 logprobs still just counts as 10 tokens, even though you are in some sense getting 50."}], "favorite_count": 0, "id_str": "1748032472871207177", "in_reply_to_status_id_str": "1748031871064183185", "lang": "en", "user": {"id_str": "185659268", "name": "Thomas Ahle", "screen_name": "thomasahle", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1837923668170887169/dCOwf_sy_normal.jpg", "description": "Head of AI @NormalComputing. Ex @Meta, @BARCdk, SupWiz, @OxfordQuantum. Tweets on Math, AI, #dspy, Probability, ML, Algorithms and Randomness. Recently tensors.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "thomasahle.com", "expanded_url": "https://thomasahle.com", "indices": [0, 23], "url": "https://t.co/EkMUe2lnQ9"}]}}, "followers_count": 7908, "location": "Copenhagen ", "url": "https://x.com/thomasahle", "follow_url": "https://x.com/intent/follow?screen_name=thomasahle"}, "url": "https://x.com/thomasahle/status/1748032472871207177", "like_url": "https://x.com/intent/like?tweet_id=1748032472871207177", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748032472871207177", "replies": ["1748038009365135669"], "score": 0.2, "thread_score": 0, "reply_count": 4}, "1748034121383719132": {"created_at": "Thu Jan 18 17:26:26 +0000 2024", "entities": [{"indices": [7, 97], "type": "text", "text": "If you like this, check out Model Arithmetic.\nAccepted as a Spotlight at ICLR in Vienna.\n\n"}, {"display_url": "arxiv.org/abs/2311.14479", "expanded_url": "https://arxiv.org/abs/2311.14479", "indices": [97, 120], "url": "https://t.co/qEpuQfLUX9", "type": "url", "href": "https://arxiv.org/abs/2311.14479", "text": "arxiv.org/abs/2311.14479"}], "favorite_count": 10, "id_str": "1748034121383719132", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/m985Sshsxk", "expanded_url": "https://x.com/marc_r_fischer/status/1748034121383719132/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1748034013787246592", "indices": [121, 144], "media_key": "3_1748034013787246592", "media_results": {"result": {"media_key": "3_1748034013787246592"}}, "media_url_https": "https://pbs.twimg.com/media/GEJDrI8W0AA0qrR.png", "original_info": {"focus_rects": [{"h": 258, "w": 461, "x": 0, "y": 0}, {"h": 258, "w": 258, "x": 0, "y": 0}, {"h": 258, "w": 226, "x": 0, "y": 0}, {"h": 258, "w": 129, "x": 33, "y": 0}, {"h": 258, "w": 559, "x": 0, "y": 0}], "height": 258, "width": 559}, "sizes": {"large": {"h": 258, "resize": "fit", "w": 559}, "medium": {"h": 258, "resize": "fit", "w": 559}, "small": {"h": 258, "resize": "fit", "w": 559}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/m985Sshsxk"}], "user": {"id_str": "120802673", "name": "Marc Fischer", "screen_name": "marc_r_fischer", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1197644760892289024/AumEHp_A_normal.jpg", "description": "Co-Founder of @InvariantLabsAI, PhD student at ETH Zurich. I care about security and reliability of AI systems. @mrf@sigmoid.social", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "marcfischer.at", "expanded_url": "http://marcfischer.at", "indices": [0, 23], "url": "https://t.co/9ZWqbrWz7g"}]}}, "followers_count": 428, "location": "Zurich, Switzerland", "url": "https://x.com/marc_r_fischer", "follow_url": "https://x.com/intent/follow?screen_name=marc_r_fischer"}, "url": "https://x.com/marc_r_fischer/status/1748034121383719132", "like_url": "https://x.com/intent/like?tweet_id=1748034121383719132", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748034121383719132", "replies": ["1749236068296298904"], "score": 0.3, "thread_score": 0.2, "reply_count": 3, "tweet_type": "Related Work", "location": "related work", "is_branch": true}, "1748034619834818671": {"created_at": "Thu Jan 18 17:28:24 +0000 2024", "entities": [{"indices": [16, 55], "type": "text", "text": "deltas of outputs, not weights, right ?"}], "favorite_count": 1, "id_str": "1748034619834818671", "in_reply_to_status_id_str": "1748031001618464839", "lang": "en", "user": {"id_str": "1504044450183626752", "name": "Vincent Nguyen", "screen_name": "vince62s", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1504044604974379008/ZV9klRvG_normal.png", "description": "Eole\nOpenNMT-py", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "github.com/eole-nlp/eole", "expanded_url": "https://github.com/eole-nlp/eole", "indices": [0, 23], "url": "https://t.co/OQZBzuxUoC"}]}}, "followers_count": 76, "location": "Paris", "url": "https://x.com/vince62s", "follow_url": "https://x.com/intent/follow?screen_name=vince62s"}, "url": "https://x.com/vince62s/status/1748034619834818671", "like_url": "https://x.com/intent/like?tweet_id=1748034619834818671", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748034619834818671", "replies": ["1748035128113131667"], "score": 0.5, "thread_score": 0, "reply_count": 1}, "1748035128113131667": {"created_at": "Thu Jan 18 17:30:26 +0000 2024", "entities": [{"indices": [19, 38], "type": "text", "text": "Yes, that's correct"}], "favorite_count": 1, "id_str": "1748035128113131667", "in_reply_to_status_id_str": "1748034619834818671", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748035128113131667", "like_url": "https://x.com/intent/like?tweet_id=1748035128113131667", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748035128113131667", "replies": [], "score": 0.4, "thread_score": 0, "reply_count": 0}, "1748035243687260543": {"created_at": "Thu Jan 18 17:30:53 +0000 2024", "entities": [{"indices": [19, 109], "type": "text", "text": "Thats new-ish, tho. TinyStories was ealier. OTOH MSFT may have had this option exclusively"}], "favorite_count": 1, "id_str": "1748035243687260543", "in_reply_to_status_id_str": "1748031871064183185", "lang": "en", "user": {"id_str": "3382720905", "name": "Xeophon", "screen_name": "TheXeophon", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1708143515824168960/JeSwb2wy_normal.jpg", "description": "AI, LLMs", "entities": {"description": {"urls": []}}, "followers_count": 5184, "location": "", "url": "https://x.com/TheXeophon", "follow_url": "https://x.com/intent/follow?screen_name=TheXeophon"}, "url": "https://x.com/TheXeophon/status/1748035243687260543", "like_url": "https://x.com/intent/like?tweet_id=1748035243687260543", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748035243687260543", "replies": ["1748170992143511623"], "score": 0.2, "thread_score": 0, "reply_count": 0}, "1748036696774480292": {"created_at": "Thu Jan 18 17:36:40 +0000 2024", "entities": [{"indices": [0, 161], "type": "text", "text": "\u662f\u4e00\u79cd\u65b0\u7684\u4e0d\u6539\u53d8\u6a21\u578b\u6743\u91cd\u7684\u5fae\u8c03\u65b9\u6cd5\u2014\u2014\u4ee3\u7406\u8c03\u6574\uff08proxy-tuning\uff09\n\n\u4f5c\u8005\u89e3\u91ca\u7684\u5f88\u4e13\u4e1a\uff0c\u4f46\u770b\u8d77\u6765\u8fd8\u662f\u633a\u590d\u6742\u7684\uff0c\u8d85\u51fa\u4e86\u6211\u7684\u77e5\u8bc6\u8303\u56f4\uff0c\u8fd9\u91cc\u4ec5\u5bf9\u4f5c\u8005\u7684\u539f\u6587\u8fdb\u884c\u7ffb\u8bd1\uff1a\n\n\u5218\u7b49\u4eba\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5fae\u8c03\u65b9\u6cd5\uff0c\u4e0d\u9700\u8981\u6539\u53d8\u6a21\u578b\u6743\u91cd\uff0c\u8fd9\u79cd\u65b9\u6cd5\u88ab\u79f0\u4e3a\u4ee3\u7406\u8c03\u6574\uff08proxy-tuning\uff09\uff08\u53c2\u89c1 Liu et al. "}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [161, 184], "url": "https://t.co/2CqiXFJxB7", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}, {"indices": [184, 1072], "type": "text", "text": "\uff09\u3002\u90a3\u4e48\uff0c\u5b83\u662f\u5982\u4f55\u5de5\u4f5c\u7684\u5462\uff1f\u4ee3\u7406\u8c03\u8c03\u6574\u662f\u4e00\u79cd\u5728\u89e3\u7801\u65f6\u4f7f\u7528\u7684\u7b80\u5355\u6280\u672f\uff0c\u5b83\u901a\u8fc7\u4fee\u6539\u76ee\u6807\u5927\u8bed\u8a00\u6a21\u578b\u7684 logits \u503c\u6765\u5b9e\u73b0\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4f60\u9700\u8981\u8ba1\u7b97\u4e00\u4e2a\u8f83\u5c0f\u7684\u57fa\u7840\u6a21\u578b\u4e0e\u5fae\u8c03\u6a21\u578b\u4e4b\u95f4\u7684 logits \u5dee\u5f02\uff0c\u7136\u540e\u5c06\u8fd9\u4e2a\u5dee\u5f02\u5e94\u7528\u5230\u76ee\u6807\u6a21\u578b\u7684 logits \u4e0a\u3002\n\n\u5177\u4f53\u4f8b\u5b50\u6765\u8bf4\uff0c\u5982\u679c\u76ee\u6807\u662f\u63d0\u5347\u4e00\u4e2a\u5927\u578b\u76ee\u6807\u6a21\u578b\uff08M1\uff09\u7684\u6027\u80fd\u3002\n\n\u8fd9\u4e2a\u65b9\u6cd5\u7684\u6838\u5fc3\u601d\u60f3\u662f\u4f7f\u7528\u4e24\u4e2a\u5c0f\u578b\u6a21\u578b\uff1a\n- \u4e00\u4e2a\u5c0f\u578b\u57fa\u7840\u6a21\u578b\uff08M2\uff09\n- \u4e00\u4e2a\u7ecf\u8fc7\u5fae\u8c03\u7684\u57fa\u7840\u6a21\u578b\uff08M3\uff09\n\n\u63a5\u7740\uff0c\u4f60\u53ea\u9700\u8981\u5c06\u8fd9\u4e24\u4e2a\u5c0f\u578b\u6a21\u578b\u5728\u9884\u6d4b\u4e0a\u7684\u5dee\u5f02\uff08\u5373\u8f93\u51fa\u8bcd\u6c47\u4e0a\u7684 logits \u5dee\u5f02\uff09\u5e94\u7528\u5230\u76ee\u6807\u6a21\u578b M1 \u4e0a\u3002\n\n\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u6539\u8fdb\u540e\u7684\u76ee\u6807\u6a21\u578b\u7684\u8f93\u51fa\u53ef\u4ee5\u8868\u793a\u4e3a M1\\*(x) = M1(x) + [M3(x) - M2(x)]\u3002\n\n\u6839\u636e\u5b9e\u9a8c\u7ed3\u679c\uff0c\u8fd9\u79cd\u65b9\u6cd5\u6548\u679c\u51fa\u4e4e\u610f\u6599\u5730\u597d\u3002\u4f5c\u8005\u4eec\u5728\u4ee5\u4e0b\u51e0\u4e2a\u65b9\u9762\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff1a\nA. \u6307\u4ee4\u5f0f\u8c03\u6574\uff08instruction-tuning\uff09\nB. \u9488\u5bf9\u7279\u5b9a\u9886\u57df\u7684\u9002\u5e94\uff08domain adaptation\uff09\nC. \u7279\u5b9a\u4efb\u52a1\u7684\u5fae\u8c03\uff08task-specific finetuning\uff09\n\n\u4e3a\u4e86\u7b80\u6d01\uff0c\u6211\u4eec\u53ea\u5173\u6ce8\u6307\u4ee4\u5f0f\u8c03\u6574\u8fd9\u4e00\u70b9\u3002\u5177\u4f53\u4f8b\u5b50\u5982\u4e0b\uff1a\n\n1) \u76ee\u6807\u662f\u5c06 Llama 2 70B Base \u6a21\u578b\u7684\u6027\u80fd\u63d0\u5347\u5230\u4e0e Llama 2 70B Chat \u76f8\u5f53\uff0c\u4f46\u4e0d\u901a\u8fc7\u4efb\u4f55\u4ece Base \u5230 Chat \u7684\u589e\u5f3a\u5b66\u4e60\u548c\u4eba\u7c7b\u53cd\u9988\uff08RLHF\uff09\u6765\u5b9e\u73b0\u3002\n\n2) \u4ed6\u4eec\u4f7f\u7528\u4e86\u4e00\u4e2a\u4f53\u79ef\u662f Llama 2 70B \u7684\u5341\u5206\u4e4b\u4e00\u7684 Llama 2 7B \u6a21\u578b\uff0c\u5e76\u5bf9\u5176\u8fdb\u884c\u4e86\u6307\u4ee4\u5f0f\u5fae\u8c03\u3002\n\n3) \u5fae\u8c03\u540e\uff0c\u4ed6\u4eec\u8ba1\u7b97\u4e86 7B Base \u548c 7B Finetuned \u4e4b\u95f4\u8f93\u51fa\u8bcd\u6c47\u8868\u4e0a\u7684 logits \u5dee\u5f02\u3002\n\n4) \u7136\u540e\uff0c\u4ed6\u4eec\u5c06\u8fd9\u79cd\u5dee\u5f02\u5e94\u7528\u5230 Llama 2 70B Base \u6a21\u578b\u4e0a\uff0c\u8fd9\u4f7f\u5f97 70B Base \u6a21\u578b\u7684\u6027\u80fd\u6781\u5927\u5730\u63a5\u8fd1\u4e86 70B Chat \u6a21\u578b\u3002\n\n\u8fd9\u79cd\u65b9\u6cd5\u7684\u552f\u4e00\u9650\u5236\u662f\uff0c\u8f83\u5c0f\u7684\u6a21\u578b\u5fc5\u987b\u4f7f\u7528\u4e0e\u8f83\u5927\u6a21\u578b\u76f8\u540c\u7684\u8bcd\u6c47\u8868\u8fdb\u884c\u8bad\u7ec3\u3002\u7406\u8bba\u4e0a\uff0c\u5982\u679c\u6709\u4eba\u77e5\u9053 GPT-4 \u7684\u8bcd\u6c47\u8868\u5e76\u4e14\u80fd\u591f\u8bbf\u95ee\u5176 logits \u8f93\u51fa\uff0c\u90a3\u4e48\u5c31\u53ef\u4ee5\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u6765\u521b\u5efa\u4e13\u95e8\u5b9a\u5236\u7684 GPT-4 \u6a21\u578b\u3002"}], "favorite_count": 134, "id_str": "1748036696774480292", "quoted_status_id_str": "1748021765790376385", "lang": "zh", "user": {"id_str": "3178231", "name": "\u5b9d\u7389", "screen_name": "dotey", "profile_image_url_https": "https://pbs.twimg.com/profile_images/561086911561736192/6_g58vEs_normal.jpeg", "description": "Prompt Engineer, dedicated to learning and disseminating knowledge about AI, software engineering, and engineering management.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "baoyu.io", "expanded_url": "https://baoyu.io", "indices": [0, 23], "url": "https://t.co/icobX4A3Ae"}]}}, "followers_count": 113173, "location": "Chicago, IL", "url": "https://x.com/dotey", "follow_url": "https://x.com/intent/follow?screen_name=dotey"}, "url": "https://x.com/dotey/status/1748036696774480292", "like_url": "https://x.com/intent/like?tweet_id=1748036696774480292", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748036696774480292", "replies": ["1748149704624664956", "1748149049759580413", "1748270820043235782"], "score": 0, "thread_score": 0, "reply_count": 4}, "1748038009365135669": {"created_at": "Thu Jan 18 17:41:53 +0000 2024", "entities": [{"indices": [19, 197], "type": "text", "text": "So they did stop giving them at some point.\nResearchers complained. And they brought it back.\nIf this goes against their TOS or business model, I\u2019m sure they will block it again."}], "favorite_count": 1, "id_str": "1748038009365135669", "in_reply_to_status_id_str": "1748032472871207177", "lang": "en", "user": {"id_str": "587612063", "name": "Saurabh Bhatnagar", "screen_name": "analyticsaurabh", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1298444761112686595/0_NlRxAT_normal.jpg", "description": "Founder @bohitaAi founded AI at Rent The Runway \ud83e\udd84, first fashion recommendation ML. Founded ML at Barnes & Nobles. Past, @Virevol, Unilever, HP, ...", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "sanealytics.com", "expanded_url": "http://sanealytics.com", "indices": [0, 23], "url": "https://t.co/soqfwJz228"}]}}, "followers_count": 1451, "location": "NoLIta, Manhattan", "url": "https://x.com/analyticsaurabh", "follow_url": "https://x.com/intent/follow?screen_name=analyticsaurabh"}, "url": "https://x.com/analyticsaurabh/status/1748038009365135669", "like_url": "https://x.com/intent/like?tweet_id=1748038009365135669", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748038009365135669", "replies": ["1748041659785363766"], "score": 0.3, "thread_score": 0, "reply_count": 3}, "1748039405489516757": {"created_at": "Thu Jan 18 17:47:25 +0000 2024", "entities": [{"indices": [7, 134], "type": "text", "text": "Could that be used for weak-to-strong generalization as a smaller model can make sure the large model behaves in a desired way?"}], "favorite_count": 1, "id_str": "1748039405489516757", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1742965649087844352", "name": "Foad Mobini Kesheh", "screen_name": "FKesheh84", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1749841246221135872/wB7pQyZ3_normal.jpg", "description": "AI-Powered Full-Stack Developer | Exploring the Intersection of AI & Software Engineering  | Sharing Insights & Latest Trends in AI", "entities": {"description": {"urls": []}}, "followers_count": 201, "location": "Curitiba/Brazil", "url": "https://x.com/FKesheh84", "follow_url": "https://x.com/intent/follow?screen_name=FKesheh84"}, "url": "https://x.com/FKesheh84/status/1748039405489516757", "like_url": "https://x.com/intent/like?tweet_id=1748039405489516757", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748039405489516757", "replies": [], "score": 0.5, "thread_score": 0.4, "reply_count": 0, "tweet_type": "Q&A", "location": "case study: proxy-tuning gpt-3.5 for the present", "is_branch": true}, "1748040174628409816": {"created_at": "Thu Jan 18 17:50:29 +0000 2024", "entities": [{"indices": [24, 64], "type": "text", "text": "I also could\u2019ve sworn I\u2019d seen it before"}], "favorite_count": 0, "id_str": "1748040174628409816", "in_reply_to_status_id_str": "1747526171196260390", "lang": "en", "user": {"id_str": "1529137439817842688", "name": "Ryan Teehan", "screen_name": "rteehas", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1619043324018532352/nW1rLJBG_normal.jpg", "description": "PhD Student @nyuniversity | prev. @carperai, @stabilityai | prev. @uchicago @TTIC_Connect", "entities": {"description": {"urls": []}}, "followers_count": 271, "location": "", "url": "https://x.com/rteehas", "follow_url": "https://x.com/intent/follow?screen_name=rteehas"}, "url": "https://x.com/rteehas/status/1748040174628409816", "like_url": "https://x.com/intent/like?tweet_id=1748040174628409816", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748040174628409816", "replies": [], "score": 0.1, "thread_score": 0, "reply_count": 0}, "1748041476880400848": {"created_at": "Thu Jan 18 17:55:39 +0000 2024", "entities": [{"indices": [7, 96], "type": "text", "text": "Wonder if proxy-tuning can replicate the performance gains of instruction tuned models. \ud83e\udd14"}], "favorite_count": 0, "id_str": "1748041476880400848", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1682415882864316417", "name": "Haz Sameen Shahgir", "screen_name": "sameen2080", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1743532605000282113/7iPj-WP2_normal.jpg", "description": "PhD Student @UCRiverside, incoming intern @Amazon, undergrad @BUET\nFromSoft enjoyer", "entities": {"description": {"urls": []}}, "followers_count": 31, "location": "", "url": "https://x.com/sameen2080", "follow_url": "https://x.com/intent/follow?screen_name=sameen2080"}, "url": "https://x.com/sameen2080/status/1748041476880400848", "like_url": "https://x.com/intent/like?tweet_id=1748041476880400848", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748041476880400848", "replies": [], "score": 0.5, "thread_score": 0.5, "reply_count": 0, "tweet_type": "Q&A", "location": "abstract", "is_branch": true}, "1748041659785363766": {"created_at": "Thu Jan 18 17:56:23 +0000 2024", "entities": [{"indices": [24, 270], "type": "text", "text": "That's an interesting extra piece of information. I wonder why none of the GPT-4 based datasets, like Ocra, include logprobs. They are not keeping it secret that the data was GPT-4 derived. Maybe they just thought it was more elegant to avoid it."}], "favorite_count": 1, "id_str": "1748041659785363766", "in_reply_to_status_id_str": "1748038009365135669", "lang": "en", "user": {"id_str": "185659268", "name": "Thomas Ahle", "screen_name": "thomasahle", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1837923668170887169/dCOwf_sy_normal.jpg", "description": "Head of AI @NormalComputing. Ex @Meta, @BARCdk, SupWiz, @OxfordQuantum. Tweets on Math, AI, #dspy, Probability, ML, Algorithms and Randomness. Recently tensors.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "thomasahle.com", "expanded_url": "https://thomasahle.com", "indices": [0, 23], "url": "https://t.co/EkMUe2lnQ9"}]}}, "followers_count": 7908, "location": "Copenhagen ", "url": "https://x.com/thomasahle", "follow_url": "https://x.com/intent/follow?screen_name=thomasahle"}, "url": "https://x.com/thomasahle/status/1748041659785363766", "like_url": "https://x.com/intent/like?tweet_id=1748041659785363766", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748041659785363766", "replies": ["1748046384740139475"], "score": 0.4, "thread_score": 0, "reply_count": 2}, "1748044697908793417": {"created_at": "Thu Jan 18 18:08:27 +0000 2024", "entities": [{"indices": [0, 11], "type": "text", "text": "Interesting"}], "favorite_count": 0, "id_str": "1748044697908793417", "quoted_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1250124257364824064", "name": "Mati", "screen_name": "KMatiDev1", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1588468478104588288/0xbNo6Zg_normal.jpg", "description": "Founder https://t.co/pqP6BZrqFS, Prev Co-founder & CTO https://t.co/NffEDTwfrj.", "entities": {"description": {"urls": [{"display_url": "Float16.cloud", "expanded_url": "http://Float16.cloud", "indices": [8, 31], "url": "https://t.co/pqP6BZrqFS"}, {"display_url": "easyrice.ai", "expanded_url": "https://easyrice.ai", "indices": [55, 78], "url": "https://t.co/NffEDTwfrj"}]}, "url": {"urls": [{"display_url": "matichon.me", "expanded_url": "https://matichon.me", "indices": [0, 23], "url": "https://t.co/wbcvD4Yn6e"}]}}, "followers_count": 827, "location": "Bangkok, Thailand", "url": "https://x.com/KMatiDev1", "follow_url": "https://x.com/intent/follow?screen_name=KMatiDev1"}, "url": "https://x.com/KMatiDev1/status/1748044697908793417", "like_url": "https://x.com/intent/like?tweet_id=1748044697908793417", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748044697908793417", "replies": ["1748161282476499388"], "score": 0, "thread_score": 0, "reply_count": 1, "is_branch": true}, "1748046384740139475": {"created_at": "Thu Jan 18 18:15:09 +0000 2024", "entities": [{"indices": [19, 181], "type": "text", "text": "Well, the GPT-4 paper documented that the post-RLHF logits are totally miscalibrated.\nSo I don\u2019t know how useful they are in datasets derived from unknown epochs."}], "favorite_count": 1, "id_str": "1748046384740139475", "in_reply_to_status_id_str": "1748041659785363766", "lang": "en", "user": {"id_str": "587612063", "name": "Saurabh Bhatnagar", "screen_name": "analyticsaurabh", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1298444761112686595/0_NlRxAT_normal.jpg", "description": "Founder @bohitaAi founded AI at Rent The Runway \ud83e\udd84, first fashion recommendation ML. Founded ML at Barnes & Nobles. Past, @Virevol, Unilever, HP, ...", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "sanealytics.com", "expanded_url": "http://sanealytics.com", "indices": [0, 23], "url": "https://t.co/soqfwJz228"}]}}, "followers_count": 1451, "location": "NoLIta, Manhattan", "url": "https://x.com/analyticsaurabh", "follow_url": "https://x.com/intent/follow?screen_name=analyticsaurabh"}, "url": "https://x.com/analyticsaurabh/status/1748046384740139475", "like_url": "https://x.com/intent/like?tweet_id=1748046384740139475", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748046384740139475", "replies": ["1748047058186178854"], "score": 0.4, "thread_score": 0, "reply_count": 1}, "1748046758855258545": {"created_at": "Thu Jan 18 18:16:39 +0000 2024", "entities": [{"indices": [7, 98], "type": "text", "text": "clever\nleaps in the field every day\nAGI achieved globaly soon\nthen we all get UBI\nand chill"}], "favorite_count": 0, "id_str": "1748046758855258545", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "439275107", "name": "kfant", "screen_name": "6___0", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1875977794515075072/G00m0IG5_normal.jpg", "description": "looking for a suggar mommy", "entities": {"description": {"urls": []}}, "followers_count": 254, "location": "Birthplace of bitcoin ", "url": "https://x.com/6___0", "follow_url": "https://x.com/intent/follow?screen_name=6___0"}, "url": "https://x.com/6___0/status/1748046758855258545", "like_url": "https://x.com/intent/like?tweet_id=1748046758855258545", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748046758855258545", "replies": [], "score": 0.1, "thread_score": 0.1, "reply_count": 0, "is_branch": true}, "1748047058186178854": {"created_at": "Thu Jan 18 18:17:50 +0000 2024", "entities": [{"indices": [19, 112], "type": "text", "text": "Also looks like they brought it back in December of last year. \nOcra seems to be from earlier"}], "favorite_count": 2, "id_str": "1748047058186178854", "in_reply_to_status_id_str": "1748046384740139475", "lang": "en", "user": {"id_str": "587612063", "name": "Saurabh Bhatnagar", "screen_name": "analyticsaurabh", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1298444761112686595/0_NlRxAT_normal.jpg", "description": "Founder @bohitaAi founded AI at Rent The Runway \ud83e\udd84, first fashion recommendation ML. Founded ML at Barnes & Nobles. Past, @Virevol, Unilever, HP, ...", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "sanealytics.com", "expanded_url": "http://sanealytics.com", "indices": [0, 23], "url": "https://t.co/soqfwJz228"}]}}, "followers_count": 1451, "location": "NoLIta, Manhattan", "url": "https://x.com/analyticsaurabh", "follow_url": "https://x.com/intent/follow?screen_name=analyticsaurabh"}, "url": "https://x.com/analyticsaurabh/status/1748047058186178854", "like_url": "https://x.com/intent/like?tweet_id=1748047058186178854", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748047058186178854", "replies": [], "score": 0.2, "thread_score": 0, "reply_count": 0}, "1748048115263787199": {"created_at": "Thu Jan 18 18:22:02 +0000 2024", "entities": [{"indices": [7, 17], "type": "text", "text": "@RgtShahar"}], "favorite_count": 0, "id_str": "1748048115263787199", "in_reply_to_status_id_str": "1748021765790376385", "lang": "qam", "user": {"id_str": "111050242", "name": "Memento Mori", "screen_name": "adambuildsweb3", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1628514606531444764/-sWs6FrR_normal.jpg", "description": "Build.", "entities": {"description": {"urls": []}}, "followers_count": 1953, "location": "", "url": "https://x.com/adambuildsweb3", "follow_url": "https://x.com/intent/follow?screen_name=adambuildsweb3"}, "url": "https://x.com/adambuildsweb3/status/1748048115263787199", "like_url": "https://x.com/intent/like?tweet_id=1748048115263787199", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748048115263787199", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748056347697123670": {"created_at": "Thu Jan 18 18:54:45 +0000 2024", "entities": [{"indices": [7, 43], "type": "text", "text": "Awesome! Needs to be commercialized!"}], "favorite_count": 0, "id_str": "1748056347697123670", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "77811731", "name": "Bharat Gera", "screen_name": "bharat_gera", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1707807987904200704/KZQBh935_normal.jpg", "description": "A dreamer in the true sense! UC Berkeley Haas School of Business.", "entities": {"description": {"urls": []}}, "followers_count": 744, "location": "Future Mars", "url": "https://x.com/bharat_gera", "follow_url": "https://x.com/intent/follow?screen_name=bharat_gera"}, "url": "https://x.com/bharat_gera/status/1748056347697123670", "like_url": "https://x.com/intent/like?tweet_id=1748056347697123670", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748056347697123670", "replies": [], "score": 0.1, "thread_score": 0.1, "reply_count": 0, "is_branch": true}, "1748056502152397109": {"created_at": "Thu Jan 18 18:55:22 +0000 2024", "entities": [{"indices": [0, 58], "type": "text", "text": "Lah ini kayak Dark Knowledge Distillation dari Hinton kan?"}], "favorite_count": 1, "id_str": "1748056502152397109", "quoted_status_id_str": "1748021765790376385", "lang": "in", "user": {"id_str": "268823196", "name": "Probably Approximately Correct", "screen_name": "PAClearning", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1573311930336686082/hKl6pp_S_normal.jpg", "description": "Arg Max stupidity, data scientist @pacmannai & @valianceai. \n\nSuka mengajar Stats & ML, boleh diskusi modeling di DM.\n\nRecSys, Causality, KG.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "instagram.com/capkeraterbang", "expanded_url": "http://instagram.com/capkeraterbang", "indices": [0, 23], "url": "https://t.co/N1KPWJ1wTX"}]}}, "followers_count": 11418, "location": "Semak-semak", "url": "https://x.com/PAClearning", "follow_url": "https://x.com/intent/follow?screen_name=PAClearning"}, "url": "https://x.com/PAClearning/status/1748056502152397109", "like_url": "https://x.com/intent/like?tweet_id=1748056502152397109", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748056502152397109", "replies": ["1748057380729061882", "1748063477586133191"], "score": 0, "thread_score": 0, "reply_count": 3}, "1748057380729061882": {"created_at": "Thu Jan 18 18:58:51 +0000 2024", "entities": [{"indices": [0, 112], "type": "text", "text": "Make sense banget cuma modeling logit difference dari student dan teacher, kayk yang dijelasin Hinton di sini:\n\n"}, {"display_url": "youtu.be/kfR6Jq-51x0?si\u2026", "expanded_url": "https://youtu.be/kfR6Jq-51x0?si=J8vFUtrrtMKIDei3", "indices": [112, 135], "url": "https://t.co/yjsgtX0ZSB", "type": "url", "href": "https://youtu.be/kfR6Jq-51x0?si=J8vFUtrrtMKIDei3", "text": "youtu.be/kfR6Jq-51x0?si\u2026"}], "favorite_count": 2, "id_str": "1748057380729061882", "in_reply_to_status_id_str": "1748056502152397109", "lang": "in", "user": {"id_str": "268823196", "name": "Probably Approximately Correct", "screen_name": "PAClearning", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1573311930336686082/hKl6pp_S_normal.jpg", "description": "Arg Max stupidity, data scientist @pacmannai & @valianceai. \n\nSuka mengajar Stats & ML, boleh diskusi modeling di DM.\n\nRecSys, Causality, KG.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "instagram.com/capkeraterbang", "expanded_url": "http://instagram.com/capkeraterbang", "indices": [0, 23], "url": "https://t.co/N1KPWJ1wTX"}]}}, "followers_count": 11418, "location": "Semak-semak", "url": "https://x.com/PAClearning", "follow_url": "https://x.com/intent/follow?screen_name=PAClearning"}, "url": "https://x.com/PAClearning/status/1748057380729061882", "like_url": "https://x.com/intent/like?tweet_id=1748057380729061882", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748057380729061882", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748060973053710362": {"created_at": "Thu Jan 18 19:13:08 +0000 2024", "entities": [{"indices": [0, 20], "type": "text", "text": "Math Engineers arise"}], "favorite_count": 0, "id_str": "1748060973053710362", "quoted_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1184197378233913344", "name": "Henry", "screen_name": "hienngn_99", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1654854025081225217/_Th5mfxY_normal.jpg", "description": "Mindful accelerationist \u2022 Banker by day, Builder by night \u2022 Sharing beautiful AI responses on discovering new topics", "entities": {"description": {"urls": []}}, "followers_count": 173, "location": "Boston, MA", "url": "https://x.com/hienngn_99", "follow_url": "https://x.com/intent/follow?screen_name=hienngn_99"}, "url": "https://x.com/hienngn_99/status/1748060973053710362", "like_url": "https://x.com/intent/like?tweet_id=1748060973053710362", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748060973053710362", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0, "is_branch": true}, "1748063046650757216": {"created_at": "Thu Jan 18 19:21:22 +0000 2024", "entities": [{"indices": [0, 45], "type": "text", "text": "This is a interesting approach to finetuning."}], "favorite_count": 1, "id_str": "1748063046650757216", "quoted_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1272104335439048705", "name": "Adithya S K", "screen_name": "adithya_s_k", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1888652795936706560/-pZRIId6_normal.jpg", "description": "Building OmniParse @cognitivelab_ai \u2022 FOSS Advocate \u2022 Prev \n@lossfunk AI Resident \u2022 Reseach Intern @iiscbangalore \u2022 Intern @TurboML  \u2022 21", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "github.com/adithya-s-k", "expanded_url": "http://github.com/adithya-s-k", "indices": [0, 23], "url": "https://t.co/wmvzo1oxJl"}]}}, "followers_count": 3504, "location": "Bangalore Urban", "url": "https://x.com/adithya_s_k", "follow_url": "https://x.com/intent/follow?screen_name=adithya_s_k"}, "url": "https://x.com/adithya_s_k/status/1748063046650757216", "like_url": "https://x.com/intent/like?tweet_id=1748063046650757216", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748063046650757216", "replies": [], "score": 0, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Teaser", "is_branch": true}, "1748063477586133191": {"created_at": "Thu Jan 18 19:23:05 +0000 2024", "entities": [{"indices": [13, 75], "type": "text", "text": "Tiap hari kayaknya keluar jurnal baru, model baru. Cape wkwkwk"}], "favorite_count": 0, "id_str": "1748063477586133191", "in_reply_to_status_id_str": "1748056502152397109", "lang": "in", "user": {"id_str": "1459597543260647426", "name": "Lol 123", "screen_name": "Lol12392781283", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1459597601620127745/m9hBlqiG_normal.png", "description": "Yoo", "entities": {"description": {"urls": []}}, "followers_count": 26, "location": "", "url": "https://x.com/Lol12392781283", "follow_url": "https://x.com/intent/follow?screen_name=Lol12392781283"}, "url": "https://x.com/Lol12392781283/status/1748063477586133191", "like_url": "https://x.com/intent/like?tweet_id=1748063477586133191", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748063477586133191", "replies": ["1748067378368516145"], "score": 0, "thread_score": 0, "reply_count": 1}, "1748063612009091538": {"created_at": "Thu Jan 18 19:23:37 +0000 2024", "entities": [{"indices": [0, 1], "type": "text", "text": "\ud83d\udc47"}], "favorite_count": 0, "id_str": "1748063612009091538", "quoted_status_id_str": "1748021765790376385", "lang": "art", "user": {"id_str": "14423278", "name": "Rub\u00e9n Aros", "screen_name": "rubenaros", "profile_image_url_https": "https://pbs.twimg.com/profile_images/989626692665823232/TsEZQCrN_normal.jpg", "description": "Hablo de Inteligencia Artificial. Me gusta emprender. Tambi\u00e9n hago jalot para la @adelaboltansky", "entities": {"description": {"urls": []}}, "followers_count": 908, "location": "Santiago, Chile", "url": "https://x.com/rubenaros", "follow_url": "https://x.com/intent/follow?screen_name=rubenaros"}, "url": "https://x.com/rubenaros/status/1748063612009091538", "like_url": "https://x.com/intent/like?tweet_id=1748063612009091538", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748063612009091538", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748063867505176787": {"created_at": "Thu Jan 18 19:24:38 +0000 2024", "entities": [{"indices": [7, 115], "type": "text", "text": "This fine-tuning term is it strict? I hear it is used as a way to enhance closed LLMs without changing them."}], "favorite_count": 0, "id_str": "1748063867505176787", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "33947080", "name": "Ark Szklar \ud83e\udd85", "screen_name": "ArkSzklar", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1722739301920763904/V72ff-GS_normal.jpg", "description": "Mental harmony. Purposeful life.\nSelf, Mind, Brain, Body as Laboratory.\nInsights grounded in Neuroscience, and Mind & Body arts.", "entities": {"description": {"urls": []}}, "followers_count": 83, "location": "", "url": "https://x.com/ArkSzklar", "follow_url": "https://x.com/intent/follow?screen_name=ArkSzklar"}, "url": "https://x.com/ArkSzklar/status/1748063867505176787", "like_url": "https://x.com/intent/like?tweet_id=1748063867505176787", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748063867505176787", "replies": [], "score": 0.2, "thread_score": 0.2, "reply_count": 0, "is_branch": true}, "1748067378368516145": {"created_at": "Thu Jan 18 19:38:35 +0000 2024", "entities": [{"indices": [16, 255], "type": "text", "text": "Jangan dibaca semua, fokus ke paper-paper yang dibahas di kelas ML aja dulu. Kebanyakan paper enggak perlu dibaca kalau enggak mau selesaikan problem yang sama atau bahkan kebanyakan metode cuma hypr sementara. Fokus ke fundamental aja mas"}], "favorite_count": 2, "id_str": "1748067378368516145", "in_reply_to_status_id_str": "1748063477586133191", "lang": "in", "user": {"id_str": "268823196", "name": "Probably Approximately Correct", "screen_name": "PAClearning", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1573311930336686082/hKl6pp_S_normal.jpg", "description": "Arg Max stupidity, data scientist @pacmannai & @valianceai. \n\nSuka mengajar Stats & ML, boleh diskusi modeling di DM.\n\nRecSys, Causality, KG.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "instagram.com/capkeraterbang", "expanded_url": "http://instagram.com/capkeraterbang", "indices": [0, 23], "url": "https://t.co/N1KPWJ1wTX"}]}}, "followers_count": 11418, "location": "Semak-semak", "url": "https://x.com/PAClearning", "follow_url": "https://x.com/intent/follow?screen_name=PAClearning"}, "url": "https://x.com/PAClearning/status/1748067378368516145", "like_url": "https://x.com/intent/like?tweet_id=1748067378368516145", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748067378368516145", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748067983350755401": {"created_at": "Thu Jan 18 19:40:59 +0000 2024", "entities": [{"indices": [7, 121], "type": "text", "text": "On some level, it makes logical sense but on another level, it absolutely makes no sense that this actually works."}], "favorite_count": 2, "id_str": "1748067983350755401", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1518559353225334785", "name": "Vanna", "screen_name": "Vannaweh", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1579842534624628737/I6_Mz9qv_normal.jpg", "description": "", "entities": {"description": {"urls": []}}, "followers_count": 4688, "location": "", "url": "https://x.com/Vannaweh", "follow_url": "https://x.com/intent/follow?screen_name=Vannaweh"}, "url": "https://x.com/Vannaweh/status/1748067983350755401", "like_url": "https://x.com/intent/like?tweet_id=1748067983350755401", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748067983350755401", "replies": ["1748073610600735007"], "score": 0.1, "thread_score": 0.1, "reply_count": 1, "is_branch": true}, "1748068042615976291": {"created_at": "Thu Jan 18 19:41:13 +0000 2024", "entities": [{"indices": [7, 78], "type": "text", "text": "Can this be applied to other ML models that have decoders e.g. Whisper?"}], "favorite_count": 0, "id_str": "1748068042615976291", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "954123758", "name": "Amgad Hasan", "screen_name": "AmgadGamalHasan", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1719448114816225280/QNIg0Knr_normal.jpg", "description": "A machine learning engineer specializing in LLMs and ASR models", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "substack.com/@amgadhasan", "expanded_url": "https://substack.com/@amgadhasan", "indices": [0, 23], "url": "https://t.co/WcmgSn7xni"}]}}, "followers_count": 256, "location": "", "url": "https://x.com/AmgadGamalHasan", "follow_url": "https://x.com/intent/follow?screen_name=AmgadGamalHasan"}, "url": "https://x.com/AmgadGamalHasan/status/1748068042615976291", "like_url": "https://x.com/intent/like?tweet_id=1748068042615976291", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748068042615976291", "replies": [], "score": 0.4, "thread_score": 0.4, "reply_count": 0, "tweet_type": "Q&A", "location": "conclusion", "is_branch": true}, "1748068797163151410": {"created_at": "Thu Jan 18 19:44:13 +0000 2024", "entities": [{"indices": [7, 36], "type": "text", "text": "This makes so much more sense"}], "favorite_count": 1, "id_str": "1748068797163151410", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1188159594318594048", "name": "Tejesh Bhalla", "screen_name": "OG_tejeshbhalla", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1846225014519222272/duvFqG81_normal.jpg", "description": "@theagentic", "entities": {"description": {"urls": []}}, "followers_count": 40, "location": "New Delhi, India", "url": "https://x.com/OG_tejeshbhalla", "follow_url": "https://x.com/intent/follow?screen_name=OG_tejeshbhalla"}, "url": "https://x.com/OG_tejeshbhalla/status/1748068797163151410", "like_url": "https://x.com/intent/like?tweet_id=1748068797163151410", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748068797163151410", "replies": [], "score": 0.1, "thread_score": 0.1, "reply_count": 0, "is_branch": true}, "1748073610600735007": {"created_at": "Thu Jan 18 20:03:21 +0000 2024", "entities": [{"indices": [10, 122], "type": "text", "text": "lol yeah, that was also kind of my first thought. It\u2019s wild and quite cool that this actually works in practice."}], "favorite_count": 2, "id_str": "1748073610600735007", "in_reply_to_status_id_str": "1748067983350755401", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748073610600735007", "like_url": "https://x.com/intent/like?tweet_id=1748073610600735007", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748073610600735007", "replies": [], "score": 0.1, "thread_score": 0, "reply_count": 0}, "1748074367114793308": {"created_at": "Thu Jan 18 20:06:21 +0000 2024", "entities": [{"indices": [10, 173], "type": "text", "text": "Good question actually. Theoretically, this should not work super well because you are probably overcompensating, but it would be an interesting data point to add."}], "favorite_count": 0, "id_str": "1748074367114793308", "in_reply_to_status_id_str": "1748031547536544076", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748074367114793308", "like_url": "https://x.com/intent/like?tweet_id=1748074367114793308", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748074367114793308", "replies": [], "score": 0.7, "thread_score": 0, "reply_count": 0}, "1748075477703479741": {"created_at": "Thu Jan 18 20:10:46 +0000 2024", "entities": [{"indices": [0, 529], "type": "text", "text": "Whoa, thanks for sharing, this indeed looks like the same thing: \"we can emulate the result of pre-training at 70B scale and fine-tuning at 7B scale by performing the log probability algebra Llama-2-base 70B + (Llama-2-chat 7B - Llama-2-base 7B), where the first term is the base log probabilities and the term in parentheses is the behavioral delta\"\n\nThe only very tiny difference is that proxy-tuning applies this to the logits and then computes the probas whereas this method applies it to the probas (or log probas) directly."}], "favorite_count": 30, "id_str": "1748075477703479741", "in_reply_to_status_id_str": "1748030792624935034", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748075477703479741", "like_url": "https://x.com/intent/like?tweet_id=1748075477703479741", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748075477703479741", "replies": ["1748076542217879922", "1748111814884462747", "1748668111274832002"], "score": 0.7, "thread_score": 0.6, "reply_count": 15, "tweet_type": "Perspective"}, "1748076542217879922": {"created_at": "Thu Jan 18 20:15:00 +0000 2024", "entities": [{"indices": [23, 173], "type": "text", "text": "From a scientific pov, two teams doing the same thing and coming to the same results is awesome! Guess it was done at the same time, the first is ICLR"}], "favorite_count": 12, "id_str": "1748076542217879922", "in_reply_to_status_id_str": "1748075477703479741", "lang": "en", "user": {"id_str": "3382720905", "name": "Xeophon", "screen_name": "TheXeophon", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1708143515824168960/JeSwb2wy_normal.jpg", "description": "AI, LLMs", "entities": {"description": {"urls": []}}, "followers_count": 5184, "location": "", "url": "https://x.com/TheXeophon", "follow_url": "https://x.com/intent/follow?screen_name=TheXeophon"}, "url": "https://x.com/TheXeophon/status/1748076542217879922", "like_url": "https://x.com/intent/like?tweet_id=1748076542217879922", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748076542217879922", "replies": ["1748077043827318913"], "score": 0.2, "thread_score": 0, "reply_count": 11}, "1748077021949726986": {"created_at": "Thu Jan 18 20:16:54 +0000 2024", "entities": [{"indices": [19, 297], "type": "text", "text": "There was someone I saw writing about a method of extracting all the logits from the OAI API. But it was request intensive so not viable to do in real time for all queries. But they did it for a set of queries they predefined and used the outputted logits to do further research"}], "favorite_count": 0, "id_str": "1748077021949726986", "in_reply_to_status_id_str": "1748025996933050865", "lang": "en", "user": {"id_str": "1343917419702714369", "name": "0xScotch \ud83e\udd43", "screen_name": "0xScotch", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1485376265259470848/t_iWE7C7_normal.jpg", "description": "Defi lover. Building @MaltProtocol \ud83e\udd43 52C0 7058 693C 3A6D 7BAB 9993 0766 5A15 0B5D AB67", "entities": {"description": {"urls": []}}, "followers_count": 628, "location": "", "url": "https://x.com/0xScotch", "follow_url": "https://x.com/intent/follow?screen_name=0xScotch"}, "url": "https://x.com/0xScotch/status/1748077021949726986", "like_url": "https://x.com/intent/like?tweet_id=1748077021949726986", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748077021949726986", "replies": ["1748084435747057872"], "score": 0.3, "thread_score": 0, "reply_count": 1}, "1748077043827318913": {"created_at": "Thu Jan 18 20:16:59 +0000 2024", "entities": [{"indices": [28, 74], "type": "text", "text": "Yup, it's nice evidence for reproducibility :)"}], "favorite_count": 9, "id_str": "1748077043827318913", "in_reply_to_status_id_str": "1748076542217879922", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748077043827318913", "like_url": "https://x.com/intent/like?tweet_id=1748077043827318913", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748077043827318913", "replies": ["1748169662196551883"], "score": 0.1, "thread_score": 0, "reply_count": 10}, "1748084435747057872": {"created_at": "Thu Jan 18 20:46:21 +0000 2024", "entities": [{"indices": [17, 119], "type": "text", "text": "Maybe using the logit_bias? That you can mask out things you've already seen and run the prompt again."}], "favorite_count": 0, "id_str": "1748084435747057872", "in_reply_to_status_id_str": "1748077021949726986", "lang": "en", "user": {"id_str": "185659268", "name": "Thomas Ahle", "screen_name": "thomasahle", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1837923668170887169/dCOwf_sy_normal.jpg", "description": "Head of AI @NormalComputing. Ex @Meta, @BARCdk, SupWiz, @OxfordQuantum. Tweets on Math, AI, #dspy, Probability, ML, Algorithms and Randomness. Recently tensors.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "thomasahle.com", "expanded_url": "https://thomasahle.com", "indices": [0, 23], "url": "https://t.co/EkMUe2lnQ9"}]}}, "followers_count": 7908, "location": "Copenhagen ", "url": "https://x.com/thomasahle", "follow_url": "https://x.com/intent/follow?screen_name=thomasahle"}, "url": "https://x.com/thomasahle/status/1748084435747057872", "like_url": "https://x.com/intent/like?tweet_id=1748084435747057872", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748084435747057872", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748085650664910906": {"created_at": "Thu Jan 18 20:51:11 +0000 2024", "entities": [{"indices": [7, 203], "type": "text", "text": "I would wonder if the same works inversely. Taking the difference between 70b chat and 70b base, then applying it to a 7b model. \n\nCould be a cheap and dirty way to improve tons of smaller models."}], "favorite_count": 0, "id_str": "1748085650664910906", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1681469681956270088", "name": "Nathan", "screen_name": "unaidedelf8777", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1681469724226465795/QPopl5gq_normal.png", "description": "", "entities": {"description": {"urls": []}}, "followers_count": 17, "location": "", "url": "https://x.com/unaidedelf8777", "follow_url": "https://x.com/intent/follow?screen_name=unaidedelf8777"}, "url": "https://x.com/unaidedelf8777/status/1748085650664910906", "like_url": "https://x.com/intent/like?tweet_id=1748085650664910906", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748085650664910906", "replies": [], "score": 0.5, "thread_score": 0.4, "reply_count": 0, "tweet_type": "Q&A", "location": "introduction", "is_branch": true}, "1748108737305280708": {"created_at": "Thu Jan 18 22:22:55 +0000 2024", "entities": [{"indices": [7, 210], "type": "text", "text": "I noticed this trend: constrained decoding is old technique to NLP ppl but new to ML ppl. Thus, with new wave of MLers doing LLM research, many old tricks were treated as new (for ignorance of the field)"}], "favorite_count": 1, "id_str": "1748108737305280708", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1543864209322156032", "name": "Ryan Sun", "screen_name": "sun_hanchi", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1885747695186292736/A0b7PVwi_normal.jpg", "description": "Large Language Mystificator\ud83e\uddd0 | Member of Non-Technical Staff @ Lehigh | Converting to JEPAism\ud83d\ude4f", "entities": {"description": {"urls": []}}, "followers_count": 222, "location": "", "url": "https://x.com/sun_hanchi", "follow_url": "https://x.com/intent/follow?screen_name=sun_hanchi"}, "url": "https://x.com/sun_hanchi/status/1748108737305280708", "like_url": "https://x.com/intent/like?tweet_id=1748108737305280708", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748108737305280708", "replies": [], "score": 0.7, "thread_score": 0.6, "reply_count": 0, "is_branch": true}, "1748111814884462747": {"created_at": "Thu Jan 18 22:35:09 +0000 2024", "entities": [{"indices": [23, 293], "type": "text", "text": "FWIW, giving credit where it's due, it does look like the former (Liu et al. 2024) cite the latter (Mitchell et al. 2023) and discuss distinctions b/w the papers in the related work, while acknowledging the equation is largely the same (Sec 7, second para of Liu et al.)"}], "favorite_count": 4, "id_str": "1748111814884462747", "in_reply_to_status_id_str": "1748075477703479741", "lang": "en", "user": {"id_str": "360876248", "name": "Michael Oberst", "screen_name": "MichaelOberst", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1549032665407537154/utuMlWcF_normal.jpg", "description": "Assistant Professor of CS at @JohnsHopkins, Part-time Visiting Scientist @AbridgeHQ.  Previously: Postdoc at @CarnegieMellon. PhD from @MIT_CSAIL.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "michaelkoberst.com", "expanded_url": "https://www.michaelkoberst.com", "indices": [0, 23], "url": "https://t.co/L0AbbVRDPr"}]}}, "followers_count": 2011, "location": "Cambridge, MA", "url": "https://x.com/MichaelOberst", "follow_url": "https://x.com/intent/follow?screen_name=MichaelOberst"}, "url": "https://x.com/MichaelOberst/status/1748111814884462747", "like_url": "https://x.com/intent/like?tweet_id=1748111814884462747", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748111814884462747", "replies": [], "score": 0.6, "thread_score": 0, "reply_count": 0}, "1748141214699077866": {"created_at": "Fri Jan 19 00:31:59 +0000 2024", "entities": [{"indices": [0, 23], "type": "text", "text": "\u8fd9\u4ed6\u5988\u4e0d\u662f\u526a\u8f91\u89c6\u9891\u65f6\u7528\u4f4e\u5206\u8fa8\u4ee3\u7406\u7d20\u6750\u7684\u601d\u8def\u5417\uff1f"}], "favorite_count": 1, "id_str": "1748141214699077866", "quoted_status_id_str": "1748021765790376385", "lang": "zh", "user": {"id_str": "755149", "name": "Datou", "screen_name": "Datou", "profile_image_url_https": "https://pbs.twimg.com/profile_images/649477316461006848/K2eKkOPs_normal.jpg", "description": "", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "jiewang.gitbook.io/chan-pin-jing-\u2026", "expanded_url": "https://jiewang.gitbook.io/chan-pin-jing-li-de-wu-xian-you-xi/", "indices": [0, 23], "url": "https://t.co/44eSXttD97"}]}}, "followers_count": 18272, "location": "shenzhen", "url": "https://x.com/Datou", "follow_url": "https://x.com/intent/follow?screen_name=Datou"}, "url": "https://x.com/Datou/status/1748141214699077866", "like_url": "https://x.com/intent/like?tweet_id=1748141214699077866", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748141214699077866", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748146929476006189": {"created_at": "Fri Jan 19 00:54:41 +0000 2024", "entities": [{"indices": [0, 98], "type": "text", "text": "LLM\u3092\u7279\u5b9a\u76ee\u7684\u306bFine-tuning\u305b\u305a\u3068\u3082\u3001\u3088\u308a\u5c0f\u3055\u306aLLM\u3068\u305d\u306eFine\u2212tuning\u7248\u306e\u51fa\u529b\u306e\u5dee\u5206\u3092\u3001\u5143\u306eLLM\u306e\u51fa\u529b\uff08logits\uff09\u306b\u52a0\u3048\u308b\u3053\u3068\u3067\u540c\u7b49\u306e\u52b9\u679c\u3092\u5f97\u3089\u308c\u308b\u3068\u3044\u3046\u8a71\u3002\u304a\u3082\u308d\u301c"}], "favorite_count": 253, "id_str": "1748146929476006189", "quoted_status_id_str": "1748021765790376385", "lang": "ja", "user": {"id_str": "5904392", "name": "\u6bd4\u6238\u5c06\u5e73 Shohei Hido", "screen_name": "sla", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1663429192581775362/kiMkIsAr_normal.jpg", "description": "\u30c0\u30a4\u30ad\u30f3\u5de5\u696d\uff08\u682a\uff09\u30c6\u30af\u30ce\u30ed\u30b8\u30fc\u30fb\u30a4\u30ce\u30d9\u30fc\u30b7\u30e7\u30f3\u30bb\u30f3\u30bf\u30fc\u6280\u5e2b\u9577 / \u5143LeapMind\u793e\u5916\u53d6\u7de0\u5f79 / \u5143Preferred Networks / \u5143IBM\u6771\u4eac\u57fa\u790e\u7814 / Tweets are my own.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "daikin.co.jp/tic", "expanded_url": "https://www.daikin.co.jp/tic", "indices": [0, 23], "url": "https://t.co/ljpuUM1Lqc"}]}}, "followers_count": 11368, "location": "Tokyo\u21c4Osaka", "url": "https://x.com/sla", "follow_url": "https://x.com/intent/follow?screen_name=sla"}, "url": "https://x.com/sla/status/1748146929476006189", "like_url": "https://x.com/intent/like?tweet_id=1748146929476006189", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748146929476006189", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748148298903691300": {"created_at": "Fri Jan 19 01:00:08 +0000 2024", "entities": [{"indices": [0, 18], "type": "text", "text": "Big day in AI: \n- "}, {"indices": [18, 28], "text": "#Microsoft", "type": "hashtag", "href": "https://x.com/hashtag/Microsoft"}, {"indices": [28, 73], "type": "text", "text": "'s LLMLingua compresses prompts up to 20X \n- "}, {"indices": [73, 78], "text": "#Meta", "type": "hashtag", "href": "https://x.com/hashtag/Meta"}, {"indices": [78, 147], "type": "text", "text": " announces major AI research expansion &amp; ambitious GPU goals. \n- "}, {"indices": [147, 154], "text": "#Codium", "type": "hashtag", "href": "https://x.com/hashtag/Codium"}, {"indices": [154, 190], "type": "text", "text": " elevates GPT-4 with \"reflection\"\n- "}, {"indices": [190, 197], "text": "#Runway", "type": "hashtag", "href": "https://x.com/hashtag/Runway"}, {"indices": [197, 272], "type": "text", "text": "'s Multi Motion Brush redefines video editing\n\nAnd more! Here's a thread..."}], "favorite_count": 0, "id_str": "1748148298903691300", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/ggvoho6BKC", "expanded_url": "https://x.com/AITimetoImpact/status/1748148298903691300/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": [{"h": 844, "w": 844, "x": 158, "y": 95}]}, "medium": {"faces": [{"h": 844, "w": 844, "x": 158, "y": 95}]}, "orig": {"faces": [{"h": 844, "w": 844, "x": 158, "y": 95}]}, "small": {"faces": [{"h": 521, "w": 521, "x": 97, "y": 58}]}}, "id_str": "1748147085516718080", "indices": [273, 296], "media_key": "3_1748147085516718080", "media_results": {"result": {"media_key": "3_1748147085516718080"}}, "media_url_https": "https://pbs.twimg.com/media/GEKqgx9bwAANVjy.jpg", "original_info": {"focus_rects": [{"h": 616, "w": 1100, "x": 0, "y": 0}, {"h": 1100, "w": 1100, "x": 0, "y": 0}, {"h": 1100, "w": 965, "x": 40, "y": 0}, {"h": 1100, "w": 550, "x": 247, "y": 0}, {"h": 1100, "w": 1100, "x": 0, "y": 0}], "height": 1100, "width": 1100}, "sizes": {"large": {"h": 1100, "resize": "fit", "w": 1100}, "medium": {"h": 1100, "resize": "fit", "w": 1100}, "small": {"h": 680, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/ggvoho6BKC"}], "user": {"id_str": "1671571554050899969", "name": "AI Time to Impact", "screen_name": "AITimetoImpact", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1720236647621795840/6PJqGbHT_normal.jpg", "description": "The best short, but not too short, daily summaries of the top stories in AI, according to our weighted analysis of AI community engagement.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "aitimetoimpact.com", "expanded_url": "https://aitimetoimpact.com/", "indices": [0, 23], "url": "https://t.co/N2aiASYPTW"}]}}, "followers_count": 317, "location": "", "url": "https://x.com/AITimetoImpact", "follow_url": "https://x.com/intent/follow?screen_name=AITimetoImpact"}, "url": "https://x.com/AITimetoImpact/status/1748148298903691300", "like_url": "https://x.com/intent/like?tweet_id=1748148298903691300", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748148298903691300", "replies": ["1748148301730631974"], "score": 0, "thread_score": 0, "reply_count": 0, "is_branch": true}, "1748149049759580413": {"created_at": "Fri Jan 19 01:03:07 +0000 2024", "entities": [{"id_str": "920321515077414912", "indices": [7, 16], "name": "Readwise", "screen_name": "readwise", "type": "mention", "href": "https://x.com/readwise", "text": "@readwise"}, {"indices": [16, 28], "type": "text", "text": " save thread"}], "favorite_count": 0, "id_str": "1748149049759580413", "in_reply_to_status_id_str": "1748036696774480292", "lang": "en", "user": {"id_str": "89958280", "name": "zzzzzzoo00oo", "screen_name": "zzzzzzoo00oo", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1508283070046113793/WR3gVZfN_normal.jpg", "description": "", "entities": {"description": {"urls": []}}, "followers_count": 241, "location": "", "url": "https://x.com/zzzzzzoo00oo", "follow_url": "https://x.com/intent/follow?screen_name=zzzzzzoo00oo"}, "url": "https://x.com/zzzzzzoo00oo/status/1748149049759580413", "like_url": "https://x.com/intent/like?tweet_id=1748149049759580413", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748149049759580413", "replies": ["1748149343633203242"], "score": 0, "thread_score": 0, "reply_count": 1}, "1748149343633203242": {"created_at": "Fri Jan 19 01:04:17 +0000 2024", "entities": [{"id_str": "89958280", "indices": [21, 34], "name": "zzzzzzoo00oo", "screen_name": "zzzzzzoo00oo", "type": "mention", "href": "https://x.com/zzzzzzoo00oo", "text": "@zzzzzzoo00oo"}, {"indices": [34, 129], "type": "text", "text": " First public save of this thread! \ud83c\udfc6\n\nStats:\n\u2022 2497 total saves of dotey's threads (ranked #47)"}], "favorite_count": 0, "id_str": "1748149343633203242", "in_reply_to_status_id_str": "1748149049759580413", "lang": "en", "user": {"id_str": "920321515077414912", "name": "Readwise", "screen_name": "readwise", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1333582244817100801/W9vXWh4U_normal.jpg", "description": "Save your best highlights from Kindle, Twitter, Pocket, Instapaper, iBooks, and 30+ others.\n\nThen revisit, search, organize, and export them seamlessly.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "readwise.io", "expanded_url": "https://readwise.io", "indices": [0, 23], "url": "https://t.co/nrgToNhKqN"}]}}, "followers_count": 210159, "location": "", "url": "https://x.com/readwise", "follow_url": "https://x.com/intent/follow?screen_name=readwise"}, "url": "https://x.com/readwise/status/1748149343633203242", "like_url": "https://x.com/intent/like?tweet_id=1748149343633203242", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748149343633203242", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748149704624664956": {"created_at": "Fri Jan 19 01:05:43 +0000 2024", "entities": [{"indices": [7, 31], "type": "text", "text": "\u9ad8\u7eac\u5411\u91cf\u7a7a\u95f4\u4e2d\u7684\u52a0\u51cf\u5f88\u6709\u610f\u601d\uff0c\u7406\u8bba\u4e0a\u77e5\u8bc6\u53ef\u7f16\u8f91\u4e86"}], "favorite_count": 1, "id_str": "1748149704624664956", "in_reply_to_status_id_str": "1748036696774480292", "lang": "zh", "user": {"id_str": "1591396522599469056", "name": "BruceDai", "screen_name": "BruceDai11", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1591402486207721473/w1xyiqSF_normal.jpg", "description": "NLPer,  AI,  Web3 \n$KNDX Web3 design lab @kondux_kndx", "entities": {"description": {"urls": []}}, "followers_count": 150, "location": "", "url": "https://x.com/BruceDai11", "follow_url": "https://x.com/intent/follow?screen_name=BruceDai11"}, "url": "https://x.com/BruceDai11/status/1748149704624664956", "like_url": "https://x.com/intent/like?tweet_id=1748149704624664956", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748149704624664956", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748156730234823032": {"created_at": "Fri Jan 19 01:33:38 +0000 2024", "entities": [{"indices": [0, 113], "type": "text", "text": "\u5c0f\u3055\u3044\u30e2\u30c7\u30eb\u3067\u30a2\u30e9\u30a4\u30e1\u30f3\u30c8\u6709\u7121\u306e\u30ed\u30b8\u30c3\u30c8\u5dee\u3092\u5927\u304d\u3044\u30e2\u30c7\u30eb\u306b\u9069\u7528\u3059\u308b\u3053\u3068\u3067\u518d\u5b66\u7fd2\u3057\u306a\u304f\u3066\u3082finetune\u3068\u540c\u7b49\u306e\u7d50\u679c\u304c\u5f97\u3089\u308c\u308b\u624b\u6cd5\n\u3053\u308c\u9762\u767d\u3044\nAdapter\u578b\u306efintune\u306b\u4f3c\u3066\u3044\u308b\n\u540c\u3058\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3058\u3083\u306a\u3044\u3068\u30c0\u30e1\u306a\u306e\u304b\uff1f"}], "favorite_count": 0, "id_str": "1748156730234823032", "quoted_status_id_str": "1748021765790376385", "lang": "ja", "user": {"id_str": "111804153", "name": "Ryousuke_Wayama", "screen_name": "wayama_ryousuke", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1837335142/webclip_129px_template________normal.jpg", "description": "Working in the R&D Department of Northern System Services, Inc. It takes all the running you can do, to keep in the same place.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "nssv.co.jp", "expanded_url": "http://www.nssv.co.jp", "indices": [0, 23], "url": "https://t.co/j5UTcsNTul"}]}}, "followers_count": 513, "location": "\u5ca9\u624b\u770c\u76db\u5ca1\u5e02", "url": "https://x.com/wayama_ryousuke", "follow_url": "https://x.com/intent/follow?screen_name=wayama_ryousuke"}, "url": "https://x.com/wayama_ryousuke/status/1748156730234823032", "like_url": "https://x.com/intent/like?tweet_id=1748156730234823032", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748156730234823032", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748161282476499388": {"created_at": "Fri Jan 19 01:51:43 +0000 2024", "entities": [{"indices": [11, 40], "type": "text", "text": "How dare you call 7B small! \ud83e\udd79"}], "favorite_count": 1, "id_str": "1748161282476499388", "in_reply_to_status_id_str": "1748044697908793417", "lang": "en", "user": {"id_str": "1385880992984956932", "name": "chompk.eth", "screen_name": "cpkcpk3", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1797823978930941952/jtZcuDSt_normal.jpg", "description": "\ud83e\uddd1\u200d\ud83d\udcbb AI lead at @visaiAI \ud83c\udfc3\u200d\u2642\ufe0fcontributor @contributedao @everclearorg 5k - 19:12 10k - 39:36 21k - 1:28:45 42k - 3:28:34", "entities": {"description": {"urls": []}}, "followers_count": 2365, "location": "BKK, th", "url": "https://x.com/cpkcpk3", "follow_url": "https://x.com/intent/follow?screen_name=cpkcpk3"}, "url": "https://x.com/cpkcpk3/status/1748161282476499388", "like_url": "https://x.com/intent/like?tweet_id=1748161282476499388", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748161282476499388", "replies": [], "score": 0.0, "thread_score": 0.0, "reply_count": 0, "is_branch": true}, "1748169662196551883": {"created_at": "Fri Jan 19 02:25:01 +0000 2024", "entities": [{"display_url": "arxiv.org/pdf/2305.16876\u2026", "expanded_url": "https://arxiv.org/pdf/2305.16876.pdf", "indices": [35, 58], "url": "https://t.co/6hi53RSPfB", "type": "url", "href": "https://arxiv.org/pdf/2305.16876.pdf", "text": "arxiv.org/pdf/2305.16876\u2026"}, {"indices": [58, 284], "type": "text", "text": "\u2026 Sad how the authors cite this given that most of their novelty is contained in this work (EMNLP '13). We worked on the same idea: substracting the base model didn't help, maybe the authors can put this ablation in the paper."}], "favorite_count": 3, "id_str": "1748169662196551883", "in_reply_to_status_id_str": "1748077043827318913", "lang": "en", "user": {"id_str": "124319949", "name": "Alessandro Sordoni", "screen_name": "murefil", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1488508324580667392/u4aTr2Qv_normal.jpg", "description": "Research Scientist / Manager, ML Team @MSFTResearch Montr\u00e9al. Adjunct Professor at UdeM, @Mila_Quebec.", "entities": {"description": {"urls": []}}, "followers_count": 1020, "location": "Montr\u00e9al", "url": "https://x.com/murefil", "follow_url": "https://x.com/intent/follow?screen_name=murefil"}, "url": "https://x.com/murefil/status/1748169662196551883", "like_url": "https://x.com/intent/like?tweet_id=1748169662196551883", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748169662196551883", "replies": ["1748307022565499298", "1748202358595817950"], "score": 0.7, "thread_score": 0.7, "reply_count": 9, "tweet_type": "Critique", "location": "related work", "is_branch": true}, "1748176312865575032": {"created_at": "Fri Jan 19 02:51:27 +0000 2024", "entities": [{"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [0, 23], "url": "https://t.co/bvTdbai82P", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}], "favorite_count": 0, "id_str": "1748176312865575032", "lang": "zxx", "user": {"id_str": "1518682605323177984", "name": "Pv", "screen_name": "DaiSwap", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1776242075060895745/8pWisIlP_normal.jpg", "description": "grug no dev.\ngrug no brain.\ngrug da best.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "daiswap.is-a.dev", "expanded_url": "https://daiswap.is-a.dev/", "indices": [0, 23], "url": "https://t.co/0txrJo1Sqz"}]}}, "followers_count": 20, "location": "Bengaluru, India", "url": "https://x.com/DaiSwap", "follow_url": "https://x.com/intent/follow?screen_name=DaiSwap"}, "url": "https://x.com/DaiSwap/status/1748176312865575032", "like_url": "https://x.com/intent/like?tweet_id=1748176312865575032", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748176312865575032", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748177033098907802": {"created_at": "Fri Jan 19 02:54:18 +0000 2024", "entities": [{"indices": [22, 109], "type": "text", "text": "Seems many people think it's the same! I haven't read either actually lol, not my area "}, {"display_url": "x.com/andersonbcdefg\u2026", "expanded_url": "https://x.com/andersonbcdefg/status/1748030792624935034?t=iOPeQf3OwYrkMgNuGJFYBQ&s=19", "indices": [109, 132], "url": "https://t.co/CeSezSdqyU", "type": "url", "href": "https://x.com/andersonbcdefg/status/1748030792624935034?t=iOPeQf3OwYrkMgNuGJFYBQ&s=19", "text": "x.com/andersonbcdefg\u2026"}], "favorite_count": 1, "id_str": "1748177033098907802", "quoted_status_id_str": "1748030792624935034", "in_reply_to_status_id_str": "1747859740242464773", "lang": "en", "user": {"id_str": "1070455434304200705", "name": "Aryaman Arora", "screen_name": "aryaman2020", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1873580950459723776/Ak4eR8pL_normal.jpg", "description": "member of technical staff @stanfordnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "aryaman.io", "expanded_url": "http://aryaman.io/", "indices": [0, 23], "url": "https://t.co/QWlHp6nsvW"}]}}, "followers_count": 6061, "location": "\ud83c\udf32", "url": "https://x.com/aryaman2020", "follow_url": "https://x.com/intent/follow?screen_name=aryaman2020"}, "url": "https://x.com/aryaman2020/status/1748177033098907802", "like_url": "https://x.com/intent/like?tweet_id=1748177033098907802", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748177033098907802", "replies": [], "score": 0.1, "thread_score": 0, "reply_count": 0}, "1748202358595817950": {"created_at": "Fri Jan 19 04:34:56 +0000 2024", "entities": [{"indices": [44, 122], "type": "text", "text": "Yes, this does seem basically identical to our Emulator for Fine-Tuning LLMs ("}, {"display_url": "arxiv.org/abs/2310.12962", "expanded_url": "https://arxiv.org/abs/2310.12962", "indices": [122, 145], "url": "https://t.co/y3M5tgmxZk", "type": "url", "href": "https://arxiv.org/abs/2310.12962", "text": "arxiv.org/abs/2310.12962"}, {"indices": [145, 169], "type": "text", "text": "). Thanks for noticing, "}, {"id_str": "1299856802268377090", "indices": [169, 184], "name": "Ben (e/treats)", "screen_name": "andersonbcdefg", "type": "mention", "href": "https://x.com/andersonbcdefg", "text": "@andersonbcdefg"}, {"indices": [184, 194], "type": "text", "text": "! But, as "}, {"id_str": "14968475", "indices": [194, 203], "name": "Dan Jurafsky", "screen_name": "jurafsky", "type": "mention", "href": "https://x.com/jurafsky", "text": "@jurafsky"}, {"indices": [203, 240], "type": "text", "text": " &amp; Martin note (2nd ed., \u00a71.6.7, "}, {"display_url": "home.cs.colorado.edu/%7Emartin/SLP/\u2026", "expanded_url": "https://home.cs.colorado.edu/%7Emartin/SLP/Updates/1.pdf", "indices": [240, 263], "url": "https://t.co/Z0MciT34KZ", "type": "url", "href": "https://home.cs.colorado.edu/%7Emartin/SLP/Updates/1.pdf", "text": "home.cs.colorado.edu/%7Emartin/SLP/\u2026"}, {"indices": [263, 326], "type": "text", "text": "), following Merton, science has a lot of multiple discoveries."}], "favorite_count": 9, "id_str": "1748202358595817950", "in_reply_to_status_id_str": "1748169662196551883", "lang": "en", "user": {"id_str": "2815077014", "name": "Christopher Manning", "screen_name": "chrmanning", "profile_image_url_https": "https://pbs.twimg.com/profile_images/512256295542333440/8Jo4w8kV_normal.jpeg", "description": "Director, @StanfordAILab. Assoc. Director, @StanfordHAI. Founder, @stanfordnlp. Prof. CS & Linguistics, @Stanford. IP @aixventureshq. \ud83c\udde6\ud83c\uddfa Do #NLProc & #AI. \ud83d\udc4b", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "nlp.stanford.edu/~manning/", "expanded_url": "https://nlp.stanford.edu/~manning/", "indices": [0, 23], "url": "https://t.co/mkzg9826Hu"}]}}, "followers_count": 142338, "location": "Palo Alto", "url": "https://x.com/chrmanning", "follow_url": "https://x.com/intent/follow?screen_name=chrmanning"}, "url": "https://x.com/chrmanning/status/1748202358595817950", "like_url": "https://x.com/intent/like?tweet_id=1748202358595817950", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748202358595817950", "replies": ["1748203123884409185", "1748209560215752786"], "score": 0.8, "thread_score": 0.8, "reply_count": 6, "tweet_type": "Critique"}, "1748203123884409185": {"created_at": "Fri Jan 19 04:37:59 +0000 2024", "entities": [{"indices": [54, 226], "type": "text", "text": "In this case, I think one definitely has to regard it as parallel play, given how (most of) the Proxy Tuning team had earlier used exactly the same technique for DExperts ("}, {"display_url": "arxiv.org/abs/2105.03023", "expanded_url": "https://arxiv.org/abs/2105.03023", "indices": [226, 249], "url": "https://t.co/ksWpmX4jfJ", "type": "url", "href": "https://arxiv.org/abs/2105.03023", "text": "arxiv.org/abs/2105.03023"}, {"indices": [249, 271], "type": "text", "text": ") \u2013 which we\u2019d missed."}], "favorite_count": 16, "id_str": "1748203123884409185", "in_reply_to_status_id_str": "1748202358595817950", "lang": "en", "user": {"id_str": "2815077014", "name": "Christopher Manning", "screen_name": "chrmanning", "profile_image_url_https": "https://pbs.twimg.com/profile_images/512256295542333440/8Jo4w8kV_normal.jpeg", "description": "Director, @StanfordAILab. Assoc. Director, @StanfordHAI. Founder, @stanfordnlp. Prof. CS & Linguistics, @Stanford. IP @aixventureshq. \ud83c\udde6\ud83c\uddfa Do #NLProc & #AI. \ud83d\udc4b", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "nlp.stanford.edu/~manning/", "expanded_url": "https://nlp.stanford.edu/~manning/", "indices": [0, 23], "url": "https://t.co/mkzg9826Hu"}]}}, "followers_count": 142338, "location": "Palo Alto", "url": "https://x.com/chrmanning", "follow_url": "https://x.com/intent/follow?screen_name=chrmanning"}, "url": "https://x.com/chrmanning/status/1748203123884409185", "like_url": "https://x.com/intent/like?tweet_id=1748203123884409185", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748203123884409185", "replies": ["1748206049054933103"], "score": 0.8, "thread_score": 0, "reply_count": 4}, "1748206049054933103": {"created_at": "Fri Jan 19 04:49:36 +0000 2024", "entities": [{"indices": [54, 62], "type": "text", "text": "CombLM ("}, {"display_url": "arxiv.org/abs/2305.16876", "expanded_url": "https://arxiv.org/abs/2305.16876", "indices": [62, 85], "url": "https://t.co/ly4H1V14J3", "type": "url", "href": "https://arxiv.org/abs/2305.16876", "text": "arxiv.org/abs/2305.16876"}, {"indices": [85, 87], "type": "text", "text": ", "}, {"id_str": "1138704090106646528", "indices": [87, 99], "name": "Aitor Ormazabal", "screen_name": "aormazabalo", "type": "mention", "href": "https://x.com/aormazabalo", "text": "@aormazabalo"}, {"indices": [99, 101], "type": "text", "text": ", "}, {"id_str": "892059194240532480", "indices": [101, 110], "name": "Mikel Artetxe", "screen_name": "artetxem", "type": "mention", "href": "https://x.com/artetxem", "text": "@artetxem"}, {"indices": [110, 112], "type": "text", "text": ", "}, {"id_str": "24603962", "indices": [112, 120], "name": "Eneko Agirre @eagirre.bsky.social", "screen_name": "eagirre", "type": "mention", "href": "https://x.com/eagirre", "text": "@eagirre"}, {"indices": [120, 331], "type": "text", "text": ") pioneers the same goal of adjusting a big LLM via a small tuned proxy, but doesn\u2019t introduce adding the difference in logits between a base and fine-tuned model, which I think is just the right way to do this."}], "favorite_count": 15, "id_str": "1748206049054933103", "in_reply_to_status_id_str": "1748203123884409185", "lang": "en", "user": {"id_str": "2815077014", "name": "Christopher Manning", "screen_name": "chrmanning", "profile_image_url_https": "https://pbs.twimg.com/profile_images/512256295542333440/8Jo4w8kV_normal.jpeg", "description": "Director, @StanfordAILab. Assoc. Director, @StanfordHAI. Founder, @stanfordnlp. Prof. CS & Linguistics, @Stanford. IP @aixventureshq. \ud83c\udde6\ud83c\uddfa Do #NLProc & #AI. \ud83d\udc4b", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "nlp.stanford.edu/~manning/", "expanded_url": "https://nlp.stanford.edu/~manning/", "indices": [0, 23], "url": "https://t.co/mkzg9826Hu"}]}}, "followers_count": 142338, "location": "Palo Alto", "url": "https://x.com/chrmanning", "follow_url": "https://x.com/intent/follow?screen_name=chrmanning"}, "url": "https://x.com/chrmanning/status/1748206049054933103", "like_url": "https://x.com/intent/like?tweet_id=1748206049054933103", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748206049054933103", "replies": ["1748207242984276281"], "score": 0.9, "thread_score": 0, "reply_count": 3}, "1748207242984276281": {"created_at": "Fri Jan 19 04:54:21 +0000 2024", "entities": [{"indices": [89, 366], "type": "text", "text": "it seems indeed the right way, but in practice it doesn't help according to our experiments (that we decided to abandon given high similarity to CombLM, which I think deserve a bit more credit in the related works of Proxy Tuning). Maybe I missed this ablation in Proxy Tuning?"}], "favorite_count": 7, "id_str": "1748207242984276281", "in_reply_to_status_id_str": "1748206049054933103", "lang": "en", "user": {"id_str": "124319949", "name": "Alessandro Sordoni", "screen_name": "murefil", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1488508324580667392/u4aTr2Qv_normal.jpg", "description": "Research Scientist / Manager, ML Team @MSFTResearch Montr\u00e9al. Adjunct Professor at UdeM, @Mila_Quebec.", "entities": {"description": {"urls": []}}, "followers_count": 1020, "location": "Montr\u00e9al", "url": "https://x.com/murefil", "follow_url": "https://x.com/intent/follow?screen_name=murefil"}, "url": "https://x.com/murefil/status/1748207242984276281", "like_url": "https://x.com/intent/like?tweet_id=1748207242984276281", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748207242984276281", "replies": ["1748485259224887353"], "score": 0.7, "thread_score": 0, "reply_count": 2}, "1748209560215752786": {"created_at": "Fri Jan 19 05:03:33 +0000 2024", "entities": [{"indices": [50, 85], "type": "text", "text": "great minds think alike i suppose \ud83d\ude00"}], "favorite_count": 0, "id_str": "1748209560215752786", "in_reply_to_status_id_str": "1748202358595817950", "lang": "en", "user": {"id_str": "1299856802268377090", "name": "Ben (e/treats)", "screen_name": "andersonbcdefg", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1299864018081865729/CMlOyn1u_normal.jpg", "description": "\ud83e\udd16 Computer scientist, next-word-prediction enjoyer\n\ud83d\udcca Prev. research fellow @ Stanford RegLab\n\ud83d\udee0\ufe0f bUiLdiNg sOmeThiNg nEw (https://t.co/mdYPZmjSzN - YC S23)\n\ud83c\udff3\ufe0f\u200d\ud83c\udf08", "entities": {"description": {"urls": [{"display_url": "trytaylor.ai", "expanded_url": "http://trytaylor.ai", "indices": [120, 143], "url": "https://t.co/mdYPZmjSzN"}]}, "url": {"urls": [{"display_url": "trytaylor.ai", "expanded_url": "https://trytaylor.ai", "indices": [0, 23], "url": "https://t.co/8ndhXQEa9x"}]}}, "followers_count": 5269, "location": "San Francisco, CA", "url": "https://x.com/andersonbcdefg", "follow_url": "https://x.com/intent/follow?screen_name=andersonbcdefg"}, "url": "https://x.com/andersonbcdefg/status/1748209560215752786", "like_url": "https://x.com/intent/like?tweet_id=1748209560215752786", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748209560215752786", "replies": [], "score": 0.1, "thread_score": 0, "reply_count": 0}, "1748224216871444607": {"created_at": "Fri Jan 19 06:01:48 +0000 2024", "entities": [{"indices": [0, 244], "type": "text", "text": "Fascinating method to fine-tune a model with no training: \n- run inference on a large model\n- run it on the base and RLHF's version of a small model\n- compute the diff vector &lt;small-RLHF'd - small-base&gt;\n- add to base, then softmax\n\nVoil\u00e0!"}], "favorite_count": 0, "id_str": "1748224216871444607", "quoted_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "138999682", "name": "Romain Lacombe", "screen_name": "rlacombe", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1628925690237095937/p8MjHgFg_normal.jpg", "description": "Researching AI/ML  & ChemE @Stanford \u26a1\ufe0f\ud83e\uddea | Past: CEO @Plume_Labs (acquired by @AccuWeather) \ud83c\udf26\ufe0f", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "romainlacombe.com", "expanded_url": "http://romainlacombe.com", "indices": [0, 23], "url": "https://t.co/5y4RZ8mjrG"}]}}, "followers_count": 6389, "location": "\ud83c\udfd4\ufe0f\ud83c\udf32\ud83c\udf0a", "url": "https://x.com/rlacombe", "follow_url": "https://x.com/intent/follow?screen_name=rlacombe"}, "url": "https://x.com/rlacombe/status/1748224216871444607", "like_url": "https://x.com/intent/like?tweet_id=1748224216871444607", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748224216871444607", "replies": [], "score": 0, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Teaser", "is_branch": true}, "1748228079661600788": {"created_at": "Fri Jan 19 06:17:09 +0000 2024", "entities": [{"indices": [0, 112], "type": "text", "text": "Otro sorprendente caso de lo bien que funciona el \u00e1lgebra simple sobre predicci\u00f3nes/pesos de diferentes modelos."}], "favorite_count": 2, "id_str": "1748228079661600788", "quoted_status_id_str": "1748021765790376385", "lang": "es", "user": {"id_str": "13623842", "name": "Iv\u00e1n de Prado", "screen_name": "ivanprado", "profile_image_url_https": "https://pbs.twimg.com/profile_images/983809548636098560/VuOEkgOt_normal.jpg", "description": "Head of AI at @freepik", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "ivanprado.es", "expanded_url": "http://www.ivanprado.es", "indices": [0, 23], "url": "https://t.co/7pPKa9DEtS"}]}}, "followers_count": 1668, "location": "Segovia, Spain", "url": "https://x.com/ivanprado", "follow_url": "https://x.com/intent/follow?screen_name=ivanprado"}, "url": "https://x.com/ivanprado/status/1748228079661600788", "like_url": "https://x.com/intent/like?tweet_id=1748228079661600788", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748228079661600788", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748242916953276920": {"created_at": "Fri Jan 19 07:16:06 +0000 2024", "entities": [{"indices": [0, 210], "type": "text", "text": "\ud83e\uddf5king = queen - woman + man\nAnother explanation as to why something like this can work well. Does any one remember oldschool cold-fusion of LMs? When you combine one or more LMs where one LM is domain specific?"}], "favorite_count": 8, "id_str": "1748242916953276920", "quoted_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "87473622", "name": "Leo Boytsov", "screen_name": "srchvrs", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1570605341137637377/jQkvsU1y_normal.jpg", "description": "Sr. Research Scientist @AWS Labs (ph-D @LTIatCMU) working on (un)natural language processing, speaking \u03c0torch & C++. Opinions sampled from MY OWN 100T param LM.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "searchivarius.org/about", "expanded_url": "http://searchivarius.org/about", "indices": [0, 23], "url": "https://t.co/Do0zhhL3OQ"}]}}, "followers_count": 8253, "location": "Pittsburgh, PA", "url": "https://x.com/srchvrs", "follow_url": "https://x.com/intent/follow?screen_name=srchvrs"}, "url": "https://x.com/srchvrs/status/1748242916953276920", "like_url": "https://x.com/intent/like?tweet_id=1748242916953276920", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748242916953276920", "replies": ["1748242919142633852", "1748243231161106664"], "score": 0, "thread_score": 0.4, "reply_count": 11, "tweet_type": "Related Work", "location": "related work", "is_branch": true}, "1748242919142633852": {"created_at": "Fri Jan 19 07:16:07 +0000 2024", "entities": [{"indices": [0, 247], "type": "text", "text": "Or you train a generic acoustic model in a hybrid speech system and use a domain specific LM to decode? This is basically what is happening here IMHO with a twist that a DIFFERENCE between two models may work better than a traditional cold fusion."}], "favorite_count": 2, "id_str": "1748242919142633852", "in_reply_to_status_id_str": "1748242916953276920", "lang": "en", "user": {"id_str": "87473622", "name": "Leo Boytsov", "screen_name": "srchvrs", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1570605341137637377/jQkvsU1y_normal.jpg", "description": "Sr. Research Scientist @AWS Labs (ph-D @LTIatCMU) working on (un)natural language processing, speaking \u03c0torch & C++. Opinions sampled from MY OWN 100T param LM.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "searchivarius.org/about", "expanded_url": "http://searchivarius.org/about", "indices": [0, 23], "url": "https://t.co/Do0zhhL3OQ"}]}}, "followers_count": 8253, "location": "Pittsburgh, PA", "url": "https://x.com/srchvrs", "follow_url": "https://x.com/intent/follow?screen_name=srchvrs"}, "url": "https://x.com/srchvrs/status/1748242919142633852", "like_url": "https://x.com/intent/like?tweet_id=1748242919142633852", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748242919142633852", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748243231161106664": {"created_at": "Fri Jan 19 07:17:21 +0000 2024", "entities": [{"indices": [9, 19], "type": "text", "text": "Old = 2022"}], "favorite_count": 0, "id_str": "1748243231161106664", "in_reply_to_status_id_str": "1748242916953276920", "lang": "und", "user": {"id_str": "2157203573", "name": "Raphael cohen", "screen_name": "cohenrap", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1566368253416558594/Hhya-D9T_normal.jpg", "description": "Helping AI understand people, so AI could help people understand people\n@cohenrap@sigmoid.social", "entities": {"description": {"urls": []}}, "followers_count": 903, "location": "", "url": "https://x.com/cohenrap", "follow_url": "https://x.com/intent/follow?screen_name=cohenrap"}, "url": "https://x.com/cohenrap/status/1748243231161106664", "like_url": "https://x.com/intent/like?tweet_id=1748243231161106664", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748243231161106664", "replies": ["1748244894827590080"], "score": 0, "thread_score": 0, "reply_count": 9}, "1748244894827590080": {"created_at": "Fri Jan 19 07:23:58 +0000 2024", "entities": [{"indices": [10, 36], "type": "text", "text": "No from the day of Jelinek"}], "favorite_count": 1, "id_str": "1748244894827590080", "in_reply_to_status_id_str": "1748243231161106664", "lang": "en", "user": {"id_str": "87473622", "name": "Leo Boytsov", "screen_name": "srchvrs", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1570605341137637377/jQkvsU1y_normal.jpg", "description": "Sr. Research Scientist @AWS Labs (ph-D @LTIatCMU) working on (un)natural language processing, speaking \u03c0torch & C++. Opinions sampled from MY OWN 100T param LM.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "searchivarius.org/about", "expanded_url": "http://searchivarius.org/about", "indices": [0, 23], "url": "https://t.co/Do0zhhL3OQ"}]}}, "followers_count": 8253, "location": "Pittsburgh, PA", "url": "https://x.com/srchvrs", "follow_url": "https://x.com/intent/follow?screen_name=srchvrs"}, "url": "https://x.com/srchvrs/status/1748244894827590080", "like_url": "https://x.com/intent/like?tweet_id=1748244894827590080", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748244894827590080", "replies": ["1748255124898664878"], "score": 0, "thread_score": 0, "reply_count": 8}, "1748255124898664878": {"created_at": "Fri Jan 19 08:04:37 +0000 2024", "entities": [{"indices": [9, 88], "type": "text", "text": "Oh, I didn't know that was a classic reference in the Roberta cold fusion paper"}], "favorite_count": 0, "id_str": "1748255124898664878", "in_reply_to_status_id_str": "1748244894827590080", "lang": "en", "user": {"id_str": "2157203573", "name": "Raphael cohen", "screen_name": "cohenrap", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1566368253416558594/Hhya-D9T_normal.jpg", "description": "Helping AI understand people, so AI could help people understand people\n@cohenrap@sigmoid.social", "entities": {"description": {"urls": []}}, "followers_count": 903, "location": "", "url": "https://x.com/cohenrap", "follow_url": "https://x.com/intent/follow?screen_name=cohenrap"}, "url": "https://x.com/cohenrap/status/1748255124898664878", "like_url": "https://x.com/intent/like?tweet_id=1748255124898664878", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748255124898664878", "replies": ["1748342026100199562"], "score": 0, "thread_score": 0, "reply_count": 7}, "1748257530646778344": {"created_at": "Fri Jan 19 08:14:11 +0000 2024", "entities": [{"id_str": "1131528376538337280", "indices": [7, 16], "name": "Rattibha \u0631\u062a\u0628\u0647\u0627", "screen_name": "rattibha", "type": "mention", "href": "https://x.com/rattibha", "text": "@rattibha"}], "favorite_count": 0, "id_str": "1748257530646778344", "in_reply_to_status_id_str": "1748021765790376385", "lang": "qam", "user": {"id_str": "2276642201", "name": "Auwal Shehu Ali", "screen_name": "Asali_cs", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1726880191384047616/lxNiV3rp_normal.jpg", "description": "PhD Researcher University Sains Malaysia, | CS Lecturer Bayero University, Kano| Aspiring Cyber Physical System, Usable Security and Privacy, Data Science, ML,", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "buk.edu.ng", "expanded_url": "http://www.buk.edu.ng", "indices": [0, 23], "url": "https://t.co/hCmNZOMeiU"}]}}, "followers_count": 1175, "location": "George Town, Penang Ireland", "url": "https://x.com/Asali_cs", "follow_url": "https://x.com/intent/follow?screen_name=Asali_cs"}, "url": "https://x.com/Asali_cs/status/1748257530646778344", "like_url": "https://x.com/intent/like?tweet_id=1748257530646778344", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748257530646778344", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748267273276559398": {"created_at": "Fri Jan 19 08:52:53 +0000 2024", "entities": [{"indices": [0, 249], "type": "text", "text": "Proxy-tuning is a promising method of \u201ctuning\u201d LLMs at decoding-time by\rmodifying output logits. It is an efficient alternative to finetuning, increasing the accessibility\nof LLMs for those who lack the extensive resources required to train them.\n\ud83d\udcdc "}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [249, 272], "url": "https://t.co/SoDhjdIJyD", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}, {"indices": [272, 355], "type": "text", "text": "\n\nCoincidentally, this result was also produced by Mitchell et al. a while back.\n\ud83d\udcdc "}, {"display_url": "arxiv.org/abs/2310.12962", "expanded_url": "https://arxiv.org/abs/2310.12962", "indices": [355, 378], "url": "https://t.co/tVj9F5qi89", "type": "url", "href": "https://arxiv.org/abs/2310.12962", "text": "arxiv.org/abs/2310.12962"}, {"indices": [378, 561], "type": "text", "text": "\n\nThe only very tiny difference is that proxy-tuning applies this to the logits and then computes the probas whereas this method applies it to the probas (or log probas) directly \ud83d\ude80"}], "favorite_count": 2, "id_str": "1748267273276559398", "quoted_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1481857459", "name": "Mayank Bhaskar", "screen_name": "cataluna84", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1372809854939623424/OKqjJLdV_normal.jpg", "description": "Machine Learning Consultant \ud83e\uddd1\ud83c\udffd\u200d\ud83d\udcbb | @twimlai & @CohereForAI Community Lead \ud83d\udc65 | #programmer \u2328 | #engineer \ud83d\udee0 \ud83e\uddee | #datavisualization \ud83d\udcca | #sports \u26bd \ud83c\udfd3 \ud83c\udfcb\ud83c\udffd \ud83c\udfae", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "linkedin.com/in/cataluna84", "expanded_url": "http://www.linkedin.com/in/cataluna84", "indices": [0, 23], "url": "https://t.co/RJFNPQSWKn"}]}}, "followers_count": 857, "location": "Lucknow, India", "url": "https://x.com/cataluna84", "follow_url": "https://x.com/intent/follow?screen_name=cataluna84"}, "url": "https://x.com/cataluna84/status/1748267273276559398", "like_url": "https://x.com/intent/like?tweet_id=1748267273276559398", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748267273276559398", "replies": [], "score": 0, "thread_score": 0.4, "reply_count": 0, "tweet_type": "Related Work", "location": "related work", "is_branch": true}, "1748270820043235782": {"created_at": "Fri Jan 19 09:06:59 +0000 2024", "entities": [{"indices": [7, 20], "type": "text", "text": "\u5c31\u662f\u4e00\u4e2a\u5c0f\u6a21\u578b\u52a0\u4e00\u4e2a\u5927\u6a21\u578b"}], "favorite_count": 0, "id_str": "1748270820043235782", "in_reply_to_status_id_str": "1748036696774480292", "lang": "zh", "user": {"id_str": "41510545", "name": "LiUgOd", "screen_name": "LiuGods", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1542329569868644352/fsBacpal_normal.jpg", "description": "\u6bcf\u5929\u5206\u4eab\u4e00\u6761\u539f\u521b\u63d0\u793a\u8bcd\nAI\u5e26\u8def\u515a\u603b\u4e66\u8bb0\nMindQueryLanguage (MQL) \u8ba4\u77e5\u67e5\u8be2\u8bed\u8a00\u5f00\u53d1\u8005\n\u4eba\u5de5\u667a\u80fd\u5fc3\u7406\u5b66\u521b\u59cb\u4eba\n\u4eba\u5de5\u667a\u80fdPUA\u8bad\u7ec3\u8425\u8425\u957f\n\u9ea6\u5f53\u52b3\u9ea6\u91d1\u4f1a\u5458", "entities": {"description": {"urls": []}}, "followers_count": 2169, "location": "", "url": "https://x.com/LiuGods", "follow_url": "https://x.com/intent/follow?screen_name=LiuGods"}, "url": "https://x.com/LiuGods/status/1748270820043235782", "like_url": "https://x.com/intent/like?tweet_id=1748270820043235782", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748270820043235782", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748279412074897715": {"created_at": "Fri Jan 19 09:41:07 +0000 2024", "entities": [{"indices": [0, 70], "type": "text", "text": "really like this one\uff01showing an efficient way to align LLM in decoding"}], "favorite_count": 1, "id_str": "1748279412074897715", "quoted_status_id_str": "1747476115852316838", "lang": "en", "user": {"id_str": "1734931592097710080", "name": "Keming (Luke) Lu", "screen_name": "KemingLu612", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1734932355259756544/Z9_6izHU_normal.jpg", "description": "LLM Post-training, RLHF, Pre-Qwen #THU, #USC", "entities": {"description": {"urls": []}}, "followers_count": 253, "location": "Los Angeles, CA", "url": "https://x.com/KemingLu612", "follow_url": "https://x.com/intent/follow?screen_name=KemingLu612"}, "url": "https://x.com/KemingLu612/status/1748279412074897715", "like_url": "https://x.com/intent/like?tweet_id=1748279412074897715", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748279412074897715", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0, "is_branch": true}, "1748280216894550193": {"created_at": "Fri Jan 19 09:44:19 +0000 2024", "entities": [{"indices": [7, 295], "type": "text", "text": "Always like these scale-difference based approaches - seems to work &amp; be good for efficiency &amp; to avoid catastrophic forgetting. Right that vocab is an issue at logit level - would byte-level encodings help? But how to retrofit to fixed vocab models (extra transformation layers?)"}], "favorite_count": 0, "id_str": "1748280216894550193", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "76333742", "name": "Ben Hoyle", "screen_name": "bjh_ip", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1147087026644279296/3UOAi83__normal.png", "description": "UK & European Patent Attorney | Information Engineer | Parent | Dilettante / polymath | Likely ASD | Approximately true; practically adequate.", "entities": {"description": {"urls": []}}, "followers_count": 1767, "location": "Bath, UK", "url": "https://x.com/bjh_ip", "follow_url": "https://x.com/intent/follow?screen_name=bjh_ip"}, "url": "https://x.com/bjh_ip/status/1748280216894550193", "like_url": "https://x.com/intent/like?tweet_id=1748280216894550193", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748280216894550193", "replies": [], "score": 0.6, "thread_score": 0.4, "reply_count": 0, "tweet_type": "Q&A", "location": "method", "is_branch": true}, "1748307022565499298": {"created_at": "Fri Jan 19 11:30:50 +0000 2024", "entities": [{"indices": [44, 160], "type": "text", "text": "11 years ago? Please cite precise reference. There was a surprisingly similar paper from 1 year ago indeed, but 11??"}], "favorite_count": 0, "id_str": "1748307022565499298", "in_reply_to_status_id_str": "1748169662196551883", "lang": "en", "user": {"id_str": "259957434", "name": "floating point", "screen_name": "yar_vol", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1597722982180429824/MeH0cQlf_normal.jpg", "description": "", "entities": {"description": {"urls": []}}, "followers_count": 913, "location": "", "url": "https://x.com/yar_vol", "follow_url": "https://x.com/intent/follow?screen_name=yar_vol"}, "url": "https://x.com/yar_vol/status/1748307022565499298", "like_url": "https://x.com/intent/like?tweet_id=1748307022565499298", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748307022565499298", "replies": ["1748332530208534615"], "score": 0.3, "thread_score": 0, "reply_count": 1}, "1748332530208534615": {"created_at": "Fri Jan 19 13:12:12 +0000 2024", "entities": [{"indices": [44, 109], "type": "text", "text": "Sorry for the typo, I meant EMNLP '23 as the arxiv link suggests."}], "favorite_count": 2, "id_str": "1748332530208534615", "in_reply_to_status_id_str": "1748307022565499298", "lang": "en", "user": {"id_str": "124319949", "name": "Alessandro Sordoni", "screen_name": "murefil", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1488508324580667392/u4aTr2Qv_normal.jpg", "description": "Research Scientist / Manager, ML Team @MSFTResearch Montr\u00e9al. Adjunct Professor at UdeM, @Mila_Quebec.", "entities": {"description": {"urls": []}}, "followers_count": 1020, "location": "Montr\u00e9al", "url": "https://x.com/murefil", "follow_url": "https://x.com/intent/follow?screen_name=murefil"}, "url": "https://x.com/murefil/status/1748332530208534615", "like_url": "https://x.com/intent/like?tweet_id=1748332530208534615", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748332530208534615", "replies": [], "score": 0.2, "thread_score": 0, "reply_count": 0}, "1748342026100199562": {"created_at": "Fri Jan 19 13:49:56 +0000 2024", "entities": [{"indices": [10, 73], "type": "text", "text": "Actually I should have probably said a shallow fusion instead: "}, {"display_url": "research.baidu.com/Blog/index-vie\u2026", "expanded_url": "http://research.baidu.com/Blog/index-view?id=90", "indices": [73, 96], "url": "https://t.co/auXMXcrXed", "type": "url", "href": "http://research.baidu.com/Blog/index-view?id=90", "text": "research.baidu.com/Blog/index-vie\u2026"}], "favorite_count": 1, "id_str": "1748342026100199562", "in_reply_to_status_id_str": "1748255124898664878", "lang": "en", "user": {"id_str": "87473622", "name": "Leo Boytsov", "screen_name": "srchvrs", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1570605341137637377/jQkvsU1y_normal.jpg", "description": "Sr. Research Scientist @AWS Labs (ph-D @LTIatCMU) working on (un)natural language processing, speaking \u03c0torch & C++. Opinions sampled from MY OWN 100T param LM.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "searchivarius.org/about", "expanded_url": "http://searchivarius.org/about", "indices": [0, 23], "url": "https://t.co/Do0zhhL3OQ"}]}}, "followers_count": 8253, "location": "Pittsburgh, PA", "url": "https://x.com/srchvrs", "follow_url": "https://x.com/intent/follow?screen_name=srchvrs"}, "url": "https://x.com/srchvrs/status/1748342026100199562", "like_url": "https://x.com/intent/like?tweet_id=1748342026100199562", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748342026100199562", "replies": ["1748363473166241820"], "score": 0, "thread_score": 0, "reply_count": 6}, "1748363473166241820": {"created_at": "Fri Jan 19 15:15:09 +0000 2024", "entities": [{"indices": [9, 17], "type": "text", "text": "I meant "}, {"display_url": "huggingface.co/ibm/ColD-Fusion", "expanded_url": "https://huggingface.co/ibm/ColD-Fusion", "indices": [17, 40], "url": "https://t.co/PGeBhMKUwT", "type": "url", "href": "https://huggingface.co/ibm/ColD-Fusion", "text": "huggingface.co/ibm/ColD-Fusion"}], "favorite_count": 0, "id_str": "1748363473166241820", "in_reply_to_status_id_str": "1748342026100199562", "lang": "en", "user": {"id_str": "2157203573", "name": "Raphael cohen", "screen_name": "cohenrap", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1566368253416558594/Hhya-D9T_normal.jpg", "description": "Helping AI understand people, so AI could help people understand people\n@cohenrap@sigmoid.social", "entities": {"description": {"urls": []}}, "followers_count": 903, "location": "", "url": "https://x.com/cohenrap", "follow_url": "https://x.com/intent/follow?screen_name=cohenrap"}, "url": "https://x.com/cohenrap/status/1748363473166241820", "like_url": "https://x.com/intent/like?tweet_id=1748363473166241820", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748363473166241820", "replies": ["1748365826074317131", "1748363978902745547"], "score": 0, "thread_score": 0, "reply_count": 5}, "1748363978902745547": {"created_at": "Fri Jan 19 15:17:10 +0000 2024", "entities": [{"indices": [9, 120], "type": "text", "text": "I didn't know those Baidu tricks, it's in my speech years but rnns weren't beating kaldi in 2017 on small data."}], "favorite_count": 0, "id_str": "1748363978902745547", "in_reply_to_status_id_str": "1748363473166241820", "lang": "en", "user": {"id_str": "2157203573", "name": "Raphael cohen", "screen_name": "cohenrap", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1566368253416558594/Hhya-D9T_normal.jpg", "description": "Helping AI understand people, so AI could help people understand people\n@cohenrap@sigmoid.social", "entities": {"description": {"urls": []}}, "followers_count": 903, "location": "", "url": "https://x.com/cohenrap", "follow_url": "https://x.com/intent/follow?screen_name=cohenrap"}, "url": "https://x.com/cohenrap/status/1748363978902745547", "like_url": "https://x.com/intent/like?tweet_id=1748363978902745547", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748363978902745547", "replies": ["1748364993425236335"], "score": 0, "thread_score": 0, "reply_count": 3}, "1748364993425236335": {"created_at": "Fri Jan 19 15:21:12 +0000 2024", "entities": [{"indices": [10, 236], "type": "text", "text": "I think this might be more fair to say: end-to-end didn't beat a highly optimized Kaldi recipe with a multi-stage training pipeline and MBR finetuning. BTW, didn't Kaldi use RNN for language modeling? I think they should have."}], "favorite_count": 0, "id_str": "1748364993425236335", "in_reply_to_status_id_str": "1748363978902745547", "lang": "en", "user": {"id_str": "87473622", "name": "Leo Boytsov", "screen_name": "srchvrs", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1570605341137637377/jQkvsU1y_normal.jpg", "description": "Sr. Research Scientist @AWS Labs (ph-D @LTIatCMU) working on (un)natural language processing, speaking \u03c0torch & C++. Opinions sampled from MY OWN 100T param LM.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "searchivarius.org/about", "expanded_url": "http://searchivarius.org/about", "indices": [0, 23], "url": "https://t.co/Do0zhhL3OQ"}]}}, "followers_count": 8253, "location": "Pittsburgh, PA", "url": "https://x.com/srchvrs", "follow_url": "https://x.com/intent/follow?screen_name=srchvrs"}, "url": "https://x.com/srchvrs/status/1748364993425236335", "like_url": "https://x.com/intent/like?tweet_id=1748364993425236335", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748364993425236335", "replies": ["1748366324600848751"], "score": 0, "thread_score": 0, "reply_count": 2}, "1748365826074317131": {"created_at": "Fri Jan 19 15:24:30 +0000 2024", "entities": [{"indices": [10, 237], "type": "text", "text": "Ahhh, I saw this paper. In fact, I used similar ideas on the leaderboard to slightly improve results but I didn't publish anything. In the fast moving field, a lot of people come up with similar ideas, you have to publish fast."}], "favorite_count": 1, "id_str": "1748365826074317131", "in_reply_to_status_id_str": "1748363473166241820", "lang": "en", "user": {"id_str": "87473622", "name": "Leo Boytsov", "screen_name": "srchvrs", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1570605341137637377/jQkvsU1y_normal.jpg", "description": "Sr. Research Scientist @AWS Labs (ph-D @LTIatCMU) working on (un)natural language processing, speaking \u03c0torch & C++. Opinions sampled from MY OWN 100T param LM.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "searchivarius.org/about", "expanded_url": "http://searchivarius.org/about", "indices": [0, 23], "url": "https://t.co/Do0zhhL3OQ"}]}}, "followers_count": 8253, "location": "Pittsburgh, PA", "url": "https://x.com/srchvrs", "follow_url": "https://x.com/intent/follow?screen_name=srchvrs"}, "url": "https://x.com/srchvrs/status/1748365826074317131", "like_url": "https://x.com/intent/like?tweet_id=1748365826074317131", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748365826074317131", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748365911088591279": {"created_at": "Fri Jan 19 15:24:50 +0000 2024", "entities": [{"indices": [0, 67], "type": "text", "text": "This is cool. There's only about 100k vocabulary in English, right?"}], "favorite_count": 3, "id_str": "1748365911088591279", "quoted_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "417605061", "name": "Mickey \ud83c\uddfa\ud83c\uddf8", "screen_name": "MickeyShaughnes", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1899831780489781248/y_VaV699_normal.jpg", "description": "Husband & father of 4. Homeschool coding coach. Robot real estate development. Accelerant research \ud83c\udf08", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "open.substack.com/pub/michaelcsh\u2026", "expanded_url": "https://open.substack.com/pub/michaelcshaughnessy/", "indices": [0, 23], "url": "https://t.co/44y7neTksr"}]}}, "followers_count": 2223, "location": "Western United States \ud83d\udc3a", "url": "https://x.com/MickeyShaughnes", "follow_url": "https://x.com/intent/follow?screen_name=MickeyShaughnes"}, "url": "https://x.com/MickeyShaughnes/status/1748365911088591279", "like_url": "https://x.com/intent/like?tweet_id=1748365911088591279", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748365911088591279", "replies": ["1748366246150582755"], "score": 0, "thread_score": 0, "reply_count": 1, "is_branch": true}, "1748366246150582755": {"created_at": "Fri Jan 19 15:26:10 +0000 2024", "entities": [{"indices": [17, 54], "type": "text", "text": "I think Llama 2 uses a 32K vocabulary"}], "favorite_count": 1, "id_str": "1748366246150582755", "in_reply_to_status_id_str": "1748365911088591279", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1748366246150582755", "like_url": "https://x.com/intent/like?tweet_id=1748366246150582755", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748366246150582755", "replies": [], "score": 0.2, "thread_score": 0.2, "reply_count": 0, "is_branch": true}, "1748366324600848751": {"created_at": "Fri Jan 19 15:26:29 +0000 2024", "entities": [{"indices": [9, 110], "type": "text", "text": "We did have RNNLMs in 2017, but it wasn't seq2seq just the final bit. With voting against a 3gram lm."}], "favorite_count": 0, "id_str": "1748366324600848751", "in_reply_to_status_id_str": "1748364993425236335", "lang": "en", "user": {"id_str": "2157203573", "name": "Raphael cohen", "screen_name": "cohenrap", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1566368253416558594/Hhya-D9T_normal.jpg", "description": "Helping AI understand people, so AI could help people understand people\n@cohenrap@sigmoid.social", "entities": {"description": {"urls": []}}, "followers_count": 903, "location": "", "url": "https://x.com/cohenrap", "follow_url": "https://x.com/intent/follow?screen_name=cohenrap"}, "url": "https://x.com/cohenrap/status/1748366324600848751", "like_url": "https://x.com/intent/like?tweet_id=1748366324600848751", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748366324600848751", "replies": ["1748368421719310731"], "score": 0, "thread_score": 0, "reply_count": 1}, "1748368421719310731": {"created_at": "Fri Jan 19 15:34:49 +0000 2024", "entities": [{"indices": [10, 286], "type": "text", "text": "Yeah, just nitpicking on your claim that \"RNNs were not beating Kaldi\" while RNNs were a part of Kaldi. Another fun tidbit that you hinted at: until very recently neural LMs didn't consistently outperform n-gram LMs, but their combination did. Transformer HLM did change this."}], "favorite_count": 1, "id_str": "1748368421719310731", "in_reply_to_status_id_str": "1748366324600848751", "lang": "en", "user": {"id_str": "87473622", "name": "Leo Boytsov", "screen_name": "srchvrs", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1570605341137637377/jQkvsU1y_normal.jpg", "description": "Sr. Research Scientist @AWS Labs (ph-D @LTIatCMU) working on (un)natural language processing, speaking \u03c0torch & C++. Opinions sampled from MY OWN 100T param LM.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "searchivarius.org/about", "expanded_url": "http://searchivarius.org/about", "indices": [0, 23], "url": "https://t.co/Do0zhhL3OQ"}]}}, "followers_count": 8253, "location": "Pittsburgh, PA", "url": "https://x.com/srchvrs", "follow_url": "https://x.com/intent/follow?screen_name=srchvrs"}, "url": "https://x.com/srchvrs/status/1748368421719310731", "like_url": "https://x.com/intent/like?tweet_id=1748368421719310731", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748368421719310731", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748392877477265486": {"created_at": "Fri Jan 19 17:12:00 +0000 2024", "entities": [{"indices": [0, 80], "type": "text", "text": "\"An Emulator for Fine-Tuning Large Language Models using Small Language Models\"\n"}, {"display_url": "arxiv.org/abs/2310.12962", "expanded_url": "https://arxiv.org/abs/2310.12962", "indices": [80, 103], "url": "https://t.co/k4wkKH7eW5", "type": "url", "href": "https://arxiv.org/abs/2310.12962", "text": "arxiv.org/abs/2310.12962"}, {"indices": [103, 139], "type": "text", "text": "\n\n\"Tuning Language Models by Proxy\"\n"}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [139, 162], "url": "https://t.co/rRKRTxuP1F", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}], "favorite_count": 1, "id_str": "1748392877477265486", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/kCkE6VjGdr", "expanded_url": "https://x.com/whoisnnamdi/status/1748392877477265486/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1748257031717588992", "indices": [163, 186], "media_key": "3_1748257031717588992", "media_results": {"result": {"media_key": "3_1748257031717588992"}}, "media_url_https": "https://pbs.twimg.com/media/GEMOgfebEAAxwns.jpg", "original_info": {"focus_rects": [{"h": 412, "w": 736, "x": 468, "y": 0}, {"h": 412, "w": 412, "x": 782, "y": 0}, {"h": 412, "w": 361, "x": 808, "y": 0}, {"h": 412, "w": 206, "x": 885, "y": 0}, {"h": 412, "w": 1204, "x": 0, "y": 0}], "height": 412, "width": 1204}, "sizes": {"large": {"h": 412, "resize": "fit", "w": 1204}, "medium": {"h": 411, "resize": "fit", "w": 1200}, "small": {"h": 233, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/kCkE6VjGdr"}], "user": {"id_str": "9137302", "name": "Nnamdi Iregbulem", "screen_name": "whoisnnamdi", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1557270096317333505/zwiPbxUv_normal.jpg", "description": "Partner @LightspeedVP\n\nDev tools, infrastructure, and ML nerd. Soft spot for devs \u2764\n\nI write every few weeks @ https://t.co/ag6mmQzyjS", "entities": {"description": {"urls": [{"display_url": "whoisnnamdi.com", "expanded_url": "http://whoisnnamdi.com", "indices": [111, 134], "url": "https://t.co/ag6mmQzyjS"}]}, "url": {"urls": [{"display_url": "whoisnnamdi.com", "expanded_url": "https://whoisnnamdi.com", "indices": [0, 23], "url": "https://t.co/fY7Vu9TVuw"}]}}, "followers_count": 3836, "location": "San Francisco, CA", "url": "https://x.com/whoisnnamdi", "follow_url": "https://x.com/intent/follow?screen_name=whoisnnamdi"}, "url": "https://x.com/whoisnnamdi/status/1748392877477265486", "like_url": "https://x.com/intent/like?tweet_id=1748392877477265486", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748392877477265486", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0, "is_branch": true}, "1748398731274420723": {"created_at": "Fri Jan 19 17:35:15 +0000 2024", "entities": [{"indices": [19, 146], "type": "text", "text": "We tried it for another synthetic dataset (not TS). It seems to help a little bit, but not very significantly from what we saw."}], "favorite_count": 2, "id_str": "1748398731274420723", "in_reply_to_status_id_str": "1748029229994795170", "lang": "en", "user": {"id_str": "1213524255838593024", "name": "Ronen Eldan", "screen_name": "EldanRonen", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1574594835776176128/Yp0ZPmZg_normal.jpg", "description": "Previously doing maths at @WeizmannScience, currently at OpenAI.\n\nPretty good at loading a dishwasher.", "entities": {"description": {"urls": []}}, "followers_count": 2171, "location": "", "url": "https://x.com/EldanRonen", "follow_url": "https://x.com/intent/follow?screen_name=EldanRonen"}, "url": "https://x.com/EldanRonen/status/1748398731274420723", "like_url": "https://x.com/intent/like?tweet_id=1748398731274420723", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748398731274420723", "replies": ["1748399777979761042"], "score": 0, "thread_score": 0, "reply_count": 2}, "1748399777979761042": {"created_at": "Fri Jan 19 17:39:25 +0000 2024", "entities": [{"indices": [19, 248], "type": "text", "text": "That being said, it's not completely clear how to define the loss function and we didn't really spend much time playing with it. I agree that it seems that using all top 10 should give a boost (and doesn't affect compute so much)"}], "favorite_count": 1, "id_str": "1748399777979761042", "in_reply_to_status_id_str": "1748398731274420723", "lang": "en", "user": {"id_str": "1213524255838593024", "name": "Ronen Eldan", "screen_name": "EldanRonen", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1574594835776176128/Yp0ZPmZg_normal.jpg", "description": "Previously doing maths at @WeizmannScience, currently at OpenAI.\n\nPretty good at loading a dishwasher.", "entities": {"description": {"urls": []}}, "followers_count": 2171, "location": "", "url": "https://x.com/EldanRonen", "follow_url": "https://x.com/intent/follow?screen_name=EldanRonen"}, "url": "https://x.com/EldanRonen/status/1748399777979761042", "like_url": "https://x.com/intent/like?tweet_id=1748399777979761042", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748399777979761042", "replies": ["1748400306537562508"], "score": 0, "thread_score": 0, "reply_count": 1}, "1748400306537562508": {"created_at": "Fri Jan 19 17:41:31 +0000 2024", "entities": [{"indices": [19, 129], "type": "text", "text": "We do have a slightly different thing (but somewhat related) that seems to work better, paper will be out soon"}], "favorite_count": 1, "id_str": "1748400306537562508", "in_reply_to_status_id_str": "1748399777979761042", "lang": "en", "user": {"id_str": "1213524255838593024", "name": "Ronen Eldan", "screen_name": "EldanRonen", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1574594835776176128/Yp0ZPmZg_normal.jpg", "description": "Previously doing maths at @WeizmannScience, currently at OpenAI.\n\nPretty good at loading a dishwasher.", "entities": {"description": {"urls": []}}, "followers_count": 2171, "location": "", "url": "https://x.com/EldanRonen", "follow_url": "https://x.com/intent/follow?screen_name=EldanRonen"}, "url": "https://x.com/EldanRonen/status/1748400306537562508", "like_url": "https://x.com/intent/like?tweet_id=1748400306537562508", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748400306537562508", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748417473257361917": {"created_at": "Fri Jan 19 18:49:44 +0000 2024", "entities": [{"indices": [7, 58], "type": "text", "text": "That means you need to run inference with 3 models?"}], "favorite_count": 0, "id_str": "1748417473257361917", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1672688247275765770", "name": "Rambo", "screen_name": "rambostinko", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1672688332877299714/CMs71bUM_normal.png", "description": "", "entities": {"description": {"urls": []}}, "followers_count": 1, "location": "", "url": "https://x.com/rambostinko", "follow_url": "https://x.com/intent/follow?screen_name=rambostinko"}, "url": "https://x.com/rambostinko/status/1748417473257361917", "like_url": "https://x.com/intent/like?tweet_id=1748417473257361917", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748417473257361917", "replies": [], "score": 0.1, "thread_score": 0.1, "reply_count": 0, "is_branch": true}, "1748485259224887353": {"created_at": "Fri Jan 19 23:19:05 +0000 2024", "entities": [{"indices": [98, 200], "type": "text", "text": "in our related works section, we discuss the relationship to EFT (the concurrent but independent work "}, {"id_str": "1299856802268377090", "indices": [200, 215], "name": "Ben (e/treats)", "screen_name": "andersonbcdefg", "type": "mention", "href": "https://x.com/andersonbcdefg", "text": "@andersonbcdefg"}, {"indices": [215, 364], "type": "text", "text": " mentioned)! our paper goes further by quantifying effectiveness on benchmarks, and experimenting with domain adaptation and task-specific finetuning"}], "favorite_count": 8, "id_str": "1748485259224887353", "in_reply_to_status_id_str": "1748207242984276281", "lang": "en", "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1748485259224887353", "like_url": "https://x.com/intent/like?tweet_id=1748485259224887353", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748485259224887353", "replies": ["1748485553576907177"], "score": 0.8999999999999999, "thread_score": 0.2, "reply_count": 1, "is_author": true}, "1748485553576907177": {"created_at": "Fri Jan 19 23:20:15 +0000 2024", "entities": [{"indices": [98, 113], "type": "text", "text": "thanks also to "}, {"id_str": "2815077014", "indices": [113, 124], "name": "Christopher Manning", "screen_name": "chrmanning", "type": "mention", "href": "https://x.com/chrmanning", "text": "@chrmanning"}, {"indices": [124, 209], "type": "text", "text": " for pointing out what the EFT and proxy-tuning papers share in common with DExperts!"}], "favorite_count": 7, "id_str": "1748485553576907177", "in_reply_to_status_id_str": "1748485259224887353", "lang": "en", "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1748485553576907177", "like_url": "https://x.com/intent/like?tweet_id=1748485553576907177", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748485553576907177", "replies": [], "score": 0.8, "thread_score": 0.2, "reply_count": 0, "is_author": true}, "1748580229134831757": {"created_at": "Sat Jan 20 05:36:28 +0000 2024", "entities": [{"indices": [0, 9], "type": "text", "text": "dexperts\u3060"}], "favorite_count": 0, "id_str": "1748580229134831757", "quoted_status_id_str": "1748021765790376385", "lang": "ja", "user": {"id_str": "1373435799002181633", "name": "Masato Umakoshi", "screen_name": "Oishii_Curryyy", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1728356950872907776/eCc-kQn1_normal.jpg", "description": "Software Engineer / NLProc", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "sites.google.com/view/masato-um\u2026", "expanded_url": "https://sites.google.com/view/masato-umakoshi", "indices": [0, 23], "url": "https://t.co/fMk30TeZrd"}]}}, "followers_count": 220, "location": "", "url": "https://x.com/Oishii_Curryyy", "follow_url": "https://x.com/intent/follow?screen_name=Oishii_Curryyy"}, "url": "https://x.com/Oishii_Curryyy/status/1748580229134831757", "like_url": "https://x.com/intent/like?tweet_id=1748580229134831757", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748580229134831757", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748605662186426449": {"created_at": "Sat Jan 20 07:17:32 +0000 2024", "entities": [{"indices": [23, 233], "type": "text", "text": "we discuss the relationship to EFT (concurrent but independent work) in our related works \u2014 our paper goes further by quantifying effectiveness on benchmarks &amp; experimenting w/ domain + task tuning. thanks "}, {"id_str": "2815077014", "indices": [233, 244], "name": "Christopher Manning", "screen_name": "chrmanning", "type": "mention", "href": "https://x.com/chrmanning", "text": "@chrmanning"}, {"indices": [244, 306], "type": "text", "text": " for also noting what both papers share in common w/ DExperts!"}], "favorite_count": 5, "id_str": "1748605662186426449", "in_reply_to_status_id_str": "1748030792624935034", "lang": "en", "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1748605662186426449", "like_url": "https://x.com/intent/like?tweet_id=1748605662186426449", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748605662186426449", "replies": ["1748606271820005538"], "score": 0.2, "thread_score": 0.2, "reply_count": 1, "is_author": true}, "1748606271820005538": {"created_at": "Sat Jan 20 07:19:57 +0000 2024", "entities": [{"indices": [33, 64], "type": "text", "text": "thanks for the clarification :)"}], "favorite_count": 2, "id_str": "1748606271820005538", "in_reply_to_status_id_str": "1748605662186426449", "lang": "en", "user": {"id_str": "1299856802268377090", "name": "Ben (e/treats)", "screen_name": "andersonbcdefg", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1299864018081865729/CMlOyn1u_normal.jpg", "description": "\ud83e\udd16 Computer scientist, next-word-prediction enjoyer\n\ud83d\udcca Prev. research fellow @ Stanford RegLab\n\ud83d\udee0\ufe0f bUiLdiNg sOmeThiNg nEw (https://t.co/mdYPZmjSzN - YC S23)\n\ud83c\udff3\ufe0f\u200d\ud83c\udf08", "entities": {"description": {"urls": [{"display_url": "trytaylor.ai", "expanded_url": "http://trytaylor.ai", "indices": [120, 143], "url": "https://t.co/mdYPZmjSzN"}]}, "url": {"urls": [{"display_url": "trytaylor.ai", "expanded_url": "https://trytaylor.ai", "indices": [0, 23], "url": "https://t.co/8ndhXQEa9x"}]}}, "followers_count": 5268, "location": "San Francisco, CA", "url": "https://x.com/andersonbcdefg", "follow_url": "https://x.com/intent/follow?screen_name=andersonbcdefg"}, "url": "https://x.com/andersonbcdefg/status/1748606271820005538", "like_url": "https://x.com/intent/like?tweet_id=1748606271820005538", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748606271820005538", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748614903412490492": {"created_at": "Sat Jan 20 07:54:15 +0000 2024", "entities": [{"id_str": "94301650", "indices": [7, 20], "name": "Shubhi Shukla", "screen_name": "shubhishukla", "type": "mention", "href": "https://x.com/shubhishukla", "text": "@shubhishukla"}], "favorite_count": 0, "id_str": "1748614903412490492", "in_reply_to_status_id_str": "1748021765790376385", "lang": "qam", "user": {"id_str": "3105073717", "name": "Abhishek Kumar", "screen_name": "merealone2516", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1279335156084424704/cO5OVaB1_normal.jpg", "description": "Research Fellow at IIT Kharagpur\nArea: Software Engineering and AI", "entities": {"description": {"urls": []}}, "followers_count": 15, "location": "IIT Kharagpur", "url": "https://x.com/merealone2516", "follow_url": "https://x.com/intent/follow?screen_name=merealone2516"}, "url": "https://x.com/merealone2516/status/1748614903412490492", "like_url": "https://x.com/intent/like?tweet_id=1748614903412490492", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748614903412490492", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1748668111274832002": {"created_at": "Sat Jan 20 11:25:41 +0000 2024", "entities": [{"id_str": "1316495843621511168", "indices": [23, 32], "name": "Mem", "screen_name": "memdotai", "type": "mention", "href": "https://x.com/memdotai", "text": "@memdotai"}, {"indices": [32, 39], "type": "text", "text": " mem it"}], "favorite_count": 0, "id_str": "1748668111274832002", "in_reply_to_status_id_str": "1748075477703479741", "lang": "en", "user": {"id_str": "746988974191837184", "name": "Nguyen D. H. Phuong", "screen_name": "towardthesea_vn", "profile_image_url_https": "https://pbs.twimg.com/profile_images/746994343030951936/yZKTEtfI_normal.jpg", "description": "Roboticist, Head of Robotics Application at NEURA Robotics, Germany.", "entities": {"description": {"urls": []}}, "followers_count": 109, "location": "Reutlingen, Germany", "url": "https://x.com/towardthesea_vn", "follow_url": "https://x.com/intent/follow?screen_name=towardthesea_vn"}, "url": "https://x.com/towardthesea_vn/status/1748668111274832002", "like_url": "https://x.com/intent/like?tweet_id=1748668111274832002", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748668111274832002", "replies": ["1748668232565661857"], "score": 0, "thread_score": 0, "reply_count": 1}, "1748668232565661857": {"created_at": "Sat Jan 20 11:26:09 +0000 2024", "entities": [{"indices": [40, 75], "type": "text", "text": "Saved! Here's the compiled thread: "}, {"display_url": "mem.ai/p/CM7CehIRzs1g\u2026", "expanded_url": "https://mem.ai/p/CM7CehIRzs1gxrMip6Mn", "indices": [75, 98], "url": "https://t.co/ZG4vNDk407", "type": "url", "href": "https://mem.ai/p/CM7CehIRzs1gxrMip6Mn", "text": "mem.ai/p/CM7CehIRzs1g\u2026"}], "favorite_count": 0, "id_str": "1748668232565661857", "in_reply_to_status_id_str": "1748668111274832002", "lang": "en", "user": {"id_str": "1316495843621511168", "name": "Mem", "screen_name": "memdotai", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1343666213067530240/3mLsB1kf_normal.jpg", "description": "The AI Notes App That Keeps You Organized.\n\nGet Mem: https://t.co/hRTM2OXs2k\nSet up Mem It for Twitter: https://t.co/QbeULB4VF3", "entities": {"description": {"urls": [{"display_url": "mem.ai", "expanded_url": "http://mem.ai", "indices": [53, 76], "url": "https://t.co/hRTM2OXs2k"}, {"display_url": "mem.ai/sources/mem-it\u2026", "expanded_url": "http://mem.ai/sources/mem-it-for-twitter", "indices": [104, 127], "url": "https://t.co/QbeULB4VF3"}]}, "url": {"urls": [{"display_url": "mem.ai", "expanded_url": "http://mem.ai", "indices": [0, 23], "url": "https://t.co/hRTM2OXs2k"}]}}, "followers_count": 71062, "location": "San Francisco, CA", "url": "https://x.com/memdotai", "follow_url": "https://x.com/intent/follow?screen_name=memdotai"}, "url": "https://x.com/memdotai/status/1748668232565661857", "like_url": "https://x.com/intent/like?tweet_id=1748668232565661857", "reply_url": "https://x.com/intent/tweet?in_reply_to=1748668232565661857", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1749103950677111162": {"created_at": "Sun Jan 21 16:17:33 +0000 2024", "entities": [{"indices": [0, 197], "type": "text", "text": "The Top ML Papers of the Week (Jan 15 - Jan 21): \n\n- AlphaCodium\n- AlphaGeometry\n- RAG vs. Finetuning\n- Self-Rewarding Models\n- Overview of LLMs for Evaluation\n- Tuning Language Models by Proxy\n..."}], "favorite_count": 549, "id_str": "1749103950677111162", "lang": "en", "user": {"id_str": "889050642903293953", "name": "DAIR.AI", "screen_name": "dair_ai", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1643277398522187778/31dedbLo_normal.jpg", "description": "Democratizing AI research, education, and technologies. Learn how to build with AI in our new AI Academy: https://t.co/zQXQt0Pem8", "entities": {"description": {"urls": [{"display_url": "dair-ai.thinkific.com", "expanded_url": "https://dair-ai.thinkific.com/", "indices": [106, 129], "url": "https://t.co/zQXQt0Pem8"}]}, "url": {"urls": [{"display_url": "github.com/dair-ai", "expanded_url": "https://github.com/dair-ai", "indices": [0, 23], "url": "https://t.co/W6313m1okg"}]}}, "followers_count": 70180, "location": "", "url": "https://x.com/dair_ai", "follow_url": "https://x.com/intent/follow?screen_name=dair_ai"}, "url": "https://x.com/dair_ai/status/1749103950677111162", "like_url": "https://x.com/intent/like?tweet_id=1749103950677111162", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749103950677111162", "replies": ["1749103952317002044", "1749112618735075379", "1749287915295826129"], "score": 0, "thread_score": 0, "reply_count": 2, "is_branch": true}, "1749112618735075379": {"created_at": "Sun Jan 21 16:51:59 +0000 2024", "entities": [{"indices": [9, 51], "type": "text", "text": "can you tell from  where you get this data"}], "favorite_count": 1, "id_str": "1749112618735075379", "in_reply_to_status_id_str": "1749103950677111162", "lang": "en", "user": {"id_str": "1703247086626729985", "name": "Riteshhhhhhh", "screen_name": "ritesh_bhadana", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1771101192858574848/u1TCkbgW_normal.jpg", "description": "Pursuing Engineering (CSAI)", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "riteshbhadana.vercel.app", "expanded_url": "http://riteshbhadana.vercel.app", "indices": [0, 23], "url": "https://t.co/LjplCy99qB"}]}}, "followers_count": 91, "location": "New Delhi, IN", "url": "https://x.com/ritesh_bhadana", "follow_url": "https://x.com/intent/follow?screen_name=ritesh_bhadana"}, "url": "https://x.com/ritesh_bhadana/status/1749112618735075379", "like_url": "https://x.com/intent/like?tweet_id=1749112618735075379", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749112618735075379", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1749126417219199088": {"created_at": "Sun Jan 21 17:46:49 +0000 2024", "entities": [{"indices": [0, 168], "type": "text", "text": "Researchers from the University of Washington and Allen Institute for AI Present Proxy-Tuning: An Efficient Alternative to Finetuning Large Language Models\nQuick read: "}, {"display_url": "marktechpost.com/2024/01/21/res\u2026", "expanded_url": "https://www.marktechpost.com/2024/01/21/researchers-from-the-university-of-washington-and-allen-institute-for-ai-present-proxy-tuning-an-efficient-alternative-to-finetuning-large-language-models/", "indices": [168, 191], "url": "https://t.co/Mf9OKD1bhC", "type": "url", "href": "https://www.marktechpost.com/2024/01/21/researchers-from-the-university-of-washington-and-allen-institute-for-ai-present-proxy-tuning-an-efficient-alternative-to-finetuning-large-language-models/", "text": "marktechpost.com/2024/01/21/res\u2026"}, {"indices": [191, 199], "type": "text", "text": "\nPaper: "}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [199, 222], "url": "https://t.co/oCH3V1sOLe", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}, {"indices": [222, 224], "type": "text", "text": "\n\n"}, {"indices": [224, 247], "text": "#ArtificialIntelligence", "type": "hashtag", "href": "https://x.com/hashtag/ArtificialIntelligence"}, {"indices": [247, 248], "type": "text", "text": " "}, {"indices": [248, 252], "text": "#LLM", "type": "hashtag", "href": "https://x.com/hashtag/LLM"}, {"indices": [252, 253], "type": "text", "text": " "}, {"indices": [253, 265], "text": "#DataScience", "type": "hashtag", "href": "https://x.com/hashtag/DataScience"}], "favorite_count": 21, "id_str": "1749126417219199088", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/851co3M6Xw", "expanded_url": "https://x.com/Marktechpost/status/1749126417219199088/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1749126413058539521", "indices": [266, 289], "media_key": "3_1749126413058539521", "media_results": {"result": {"media_key": "3_1749126413058539521"}}, "media_url_https": "https://pbs.twimg.com/media/GEYlNJWbgAEd_B8.jpg", "original_info": {"focus_rects": [{"h": 999, "w": 1784, "x": 0, "y": 0}, {"h": 1252, "w": 1252, "x": 0, "y": 0}, {"h": 1252, "w": 1098, "x": 0, "y": 0}, {"h": 1252, "w": 626, "x": 0, "y": 0}, {"h": 1252, "w": 1784, "x": 0, "y": 0}], "height": 1252, "width": 1784}, "sizes": {"large": {"h": 1252, "resize": "fit", "w": 1784}, "medium": {"h": 842, "resize": "fit", "w": 1200}, "small": {"h": 477, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/851co3M6Xw"}], "user": {"id_str": "717930546391687170", "name": "Marktechpost AI Research News \u26a1", "screen_name": "Marktechpost", "profile_image_url_https": "https://pbs.twimg.com/profile_images/994114664874180608/tD0vcytP_normal.jpg", "description": "\ud83d\udc1d AI/ML Research and Dev News Platform (1 million+monthly traffic) | 70k+ ML subreddit | Contact: Asif@marktechpost.com", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "marktechpost.com", "expanded_url": "http://www.marktechpost.com", "indices": [0, 23], "url": "https://t.co/QPl2C7v1Lz"}]}}, "followers_count": 8453, "location": "What is trending in AI? ", "url": "https://x.com/Marktechpost", "follow_url": "https://x.com/intent/follow?screen_name=Marktechpost"}, "url": "https://x.com/Marktechpost/status/1749126417219199088", "like_url": "https://x.com/intent/like?tweet_id=1749126417219199088", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749126417219199088", "replies": [], "score": 0, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Teaser", "is_branch": true}, "1749236068296298904": {"created_at": "Mon Jan 22 01:02:32 +0000 2024", "entities": [{"indices": [23, 115], "type": "text", "text": "There is difference between them. Proxy tuning can adapt model with different size 7b vs 70b"}], "favorite_count": 1, "id_str": "1749236068296298904", "in_reply_to_status_id_str": "1748034121383719132", "lang": "en", "user": {"id_str": "1601959303560454144", "name": "Peyton", "screen_name": "dongpeyton98", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1795343582444068864/nbl_8gep_normal.jpg", "description": "Sometimes you gotta make a change to make a change.", "entities": {"description": {"urls": []}}, "followers_count": 63, "location": "", "url": "https://x.com/dongpeyton98", "follow_url": "https://x.com/intent/follow?screen_name=dongpeyton98"}, "url": "https://x.com/dongpeyton98/status/1749236068296298904", "like_url": "https://x.com/intent/like?tweet_id=1749236068296298904", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749236068296298904", "replies": ["1749380148443427013"], "score": 0.3, "thread_score": 0, "reply_count": 2}, "1749287915295826129": {"created_at": "Mon Jan 22 04:28:33 +0000 2024", "entities": [{"indices": [9, 28], "type": "text", "text": "Worth checking out."}], "favorite_count": 0, "id_str": "1749287915295826129", "in_reply_to_status_id_str": "1749103950677111162", "lang": "en", "user": {"id_str": "1448498502", "name": "Obaloluwa", "screen_name": "kinglyjoeai", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1866008902271164416/f0mJdhRj_normal.jpg", "description": "Exploring and Sharing the latest developments in the world of AI and Tech.", "entities": {"description": {"urls": []}}, "followers_count": 194, "location": "", "url": "https://x.com/kinglyjoeai", "follow_url": "https://x.com/intent/follow?screen_name=kinglyjoeai"}, "url": "https://x.com/kinglyjoeai/status/1749287915295826129", "like_url": "https://x.com/intent/like?tweet_id=1749287915295826129", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749287915295826129", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1749337217020166597": {"created_at": "Mon Jan 22 07:44:28 +0000 2024", "entities": [{"indices": [0, 253], "type": "text", "text": "If you're interested in this direction, check out our paper Inference-Time Policy Adapters (IPA\ud83c\udf7a). \n\nIPA guides a frozen LLM such as GPT-3 during decoding time through a lightweight policy adapter trained to optimize an arbitrary user objective with RL."}], "favorite_count": 114, "id_str": "1749337217020166597", "quoted_status_id_str": "1748021765790376385", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/TFkOwmCwO2", "expanded_url": "https://x.com/GXiming/status/1749337217020166597/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1749337045984759808", "indices": [254, 277], "media_key": "3_1749337045984759808", "media_results": {"result": {"media_key": "3_1749337045984759808"}}, "media_url_https": "https://pbs.twimg.com/media/GEbkxmJaUAA4d3i.jpg", "original_info": {"focus_rects": [{"h": 634, "w": 1132, "x": 122, "y": 0}, {"h": 634, "w": 634, "x": 371, "y": 0}, {"h": 634, "w": 556, "x": 410, "y": 0}, {"h": 634, "w": 317, "x": 530, "y": 0}, {"h": 634, "w": 1452, "x": 0, "y": 0}], "height": 634, "width": 1452}, "sizes": {"large": {"h": 634, "resize": "fit", "w": 1452}, "medium": {"h": 524, "resize": "fit", "w": 1200}, "small": {"h": 297, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/TFkOwmCwO2"}], "user": {"id_str": "965093642456023040", "name": "Ximing Lu", "screen_name": "GXiming", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1639812447887581184/ZPzs4oRM_normal.jpg", "description": "PhD @uwcse @uwnlp.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "gloriaximinglu.github.io", "expanded_url": "https://gloriaximinglu.github.io/", "indices": [0, 23], "url": "https://t.co/eNssmykILo"}]}}, "followers_count": 779, "location": "Santa Clara, CA", "url": "https://x.com/GXiming", "follow_url": "https://x.com/intent/follow?screen_name=GXiming"}, "url": "https://x.com/GXiming/status/1749337217020166597", "like_url": "https://x.com/intent/like?tweet_id=1749337217020166597", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749337217020166597", "replies": ["1749338031797252409"], "score": 0, "thread_score": 0.4, "reply_count": 1, "tweet_type": "Related Work", "location": "related work", "is_branch": true}, "1749338031797252409": {"created_at": "Mon Jan 22 07:47:42 +0000 2024", "entities": [{"indices": [0, 8], "type": "text", "text": "\ud83d\udcddarXiv: "}, {"display_url": "arxiv.org/abs/2305.15065", "expanded_url": "https://arxiv.org/abs/2305.15065", "indices": [8, 31], "url": "https://t.co/XzbD1Oegqi", "type": "url", "href": "https://arxiv.org/abs/2305.15065", "text": "arxiv.org/abs/2305.15065"}], "favorite_count": 4, "id_str": "1749338031797252409", "in_reply_to_status_id_str": "1749337217020166597", "lang": "ca", "user": {"id_str": "965093642456023040", "name": "Ximing Lu", "screen_name": "GXiming", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1639812447887581184/ZPzs4oRM_normal.jpg", "description": "PhD @uwcse @uwnlp.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "gloriaximinglu.github.io", "expanded_url": "https://gloriaximinglu.github.io/", "indices": [0, 23], "url": "https://t.co/eNssmykILo"}]}}, "followers_count": 779, "location": "Santa Clara, CA", "url": "https://x.com/GXiming", "follow_url": "https://x.com/intent/follow?screen_name=GXiming"}, "url": "https://x.com/GXiming/status/1749338031797252409", "like_url": "https://x.com/intent/like?tweet_id=1749338031797252409", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749338031797252409", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1749342873039110303": {"created_at": "Mon Jan 22 08:06:56 +0000 2024", "entities": [{"indices": [7, 267], "type": "text", "text": "Thanks for this post! I have one question, is there any backpropagation happening? I see that the whole point of this is not change the parameters of 70B model. So anytime we want to do inference on the 70B model, we need both the small tuned and untuned ones?"}], "favorite_count": 1, "id_str": "1749342873039110303", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "1523920036322512896", "name": "Machine Quest", "screen_name": "machine_quest", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1523920185081868289/8Ys9RXKJ_normal.jpg", "description": "i think therefore i exist", "entities": {"description": {"urls": []}}, "followers_count": 30, "location": "", "url": "https://x.com/machine_quest", "follow_url": "https://x.com/intent/follow?screen_name=machine_quest"}, "url": "https://x.com/machine_quest/status/1749342873039110303", "like_url": "https://x.com/intent/like?tweet_id=1749342873039110303", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749342873039110303", "replies": ["1749409290077491209"], "score": 0.7, "thread_score": 0.7, "reply_count": 4, "tweet_type": "Q&A", "location": "method", "is_branch": true}, "1749354006340853805": {"created_at": "Mon Jan 22 08:51:11 +0000 2024", "entities": [{"indices": [7, 205], "type": "text", "text": "If my understanding is correct, do we need two extra models (7B-Chat and 7B) at each decoding step to get the prob to offset.  This would be a big overhead for recomputing the KV-cache of 7B models?"}], "favorite_count": 1, "id_str": "1749354006340853805", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "3303495356", "name": "Lei Li", "screen_name": "_TobiasLee", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1663018432936443905/2NeC26wJ_normal.jpg", "description": "Ph.D. student@HKUNLP. Previously @PKU1898 COYG @Arsenal", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "lilei-nlp.github.io", "expanded_url": "http://lilei-nlp.github.io", "indices": [0, 23], "url": "https://t.co/alEVqZyq6a"}]}}, "followers_count": 1705, "location": "Hong Kong", "url": "https://x.com/_TobiasLee", "follow_url": "https://x.com/intent/follow?screen_name=_TobiasLee"}, "url": "https://x.com/_TobiasLee/status/1749354006340853805", "like_url": "https://x.com/intent/like?tweet_id=1749354006340853805", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749354006340853805", "replies": [], "score": 0.7, "thread_score": 0.4, "reply_count": 0, "tweet_type": "Q&A", "location": "method", "is_branch": true}, "1749380148443427013": {"created_at": "Mon Jan 22 10:35:03 +0000 2024", "entities": [{"indices": [21, 108], "type": "text", "text": "Never claimed that.\nAlso model arithmetic also expresses the small/large model setting."}], "favorite_count": 1, "id_str": "1749380148443427013", "in_reply_to_status_id_str": "1749236068296298904", "lang": "en", "user": {"id_str": "120802673", "name": "Marc Fischer", "screen_name": "marc_r_fischer", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1197644760892289024/AumEHp_A_normal.jpg", "description": "Co-Founder of @InvariantLabsAI, PhD student at ETH Zurich. I care about security and reliability of AI systems. @mrf@sigmoid.social", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "marcfischer.at", "expanded_url": "http://marcfischer.at", "indices": [0, 23], "url": "https://t.co/9ZWqbrWz7g"}]}}, "followers_count": 428, "location": "Zurich, Switzerland", "url": "https://x.com/marc_r_fischer", "follow_url": "https://x.com/intent/follow?screen_name=marc_r_fischer"}, "url": "https://x.com/marc_r_fischer/status/1749380148443427013", "like_url": "https://x.com/intent/like?tweet_id=1749380148443427013", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749380148443427013", "replies": ["1751462713300226306"], "score": 0.2, "thread_score": 0, "reply_count": 1}, "1749409290077491209": {"created_at": "Mon Jan 22 12:30:51 +0000 2024", "entities": [{"indices": [15, 116], "type": "text", "text": "That\u2019s correct, there\u2019s no backprop happening. Any yeah, you\u2019d need to keep the larger models around."}], "favorite_count": 2, "id_str": "1749409290077491209", "in_reply_to_status_id_str": "1749342873039110303", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321142, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1749409290077491209", "like_url": "https://x.com/intent/like?tweet_id=1749409290077491209", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749409290077491209", "replies": ["1749410256491552938"], "score": 0.7, "thread_score": 0.7, "reply_count": 3}, "1749410256491552938": {"created_at": "Mon Jan 22 12:34:42 +0000 2024", "entities": [{"indices": [7, 184], "type": "text", "text": "I see! Thank you very much! There is something very cool about it, but at the same time,  i feel it has some redundant about it as well...so having mixed feelings about this lol"}], "favorite_count": 0, "id_str": "1749410256491552938", "in_reply_to_status_id_str": "1749409290077491209", "lang": "en", "user": {"id_str": "1523920036322512896", "name": "Machine Quest", "screen_name": "machine_quest", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1523920185081868289/8Ys9RXKJ_normal.jpg", "description": "i think therefore i exist", "entities": {"description": {"urls": []}}, "followers_count": 30, "location": "", "url": "https://x.com/machine_quest", "follow_url": "https://x.com/intent/follow?screen_name=machine_quest"}, "url": "https://x.com/machine_quest/status/1749410256491552938", "like_url": "https://x.com/intent/like?tweet_id=1749410256491552938", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749410256491552938", "replies": ["1749415698625888688"], "score": 0.4, "thread_score": 0, "reply_count": 2}, "1749415698625888688": {"created_at": "Mon Jan 22 12:56:19 +0000 2024", "entities": [{"indices": [15, 118], "type": "text", "text": "Yeah it may not be the most practical method but the fact that it works is kind of neat and fascinating"}], "favorite_count": 2, "id_str": "1749415698625888688", "in_reply_to_status_id_str": "1749410256491552938", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321142, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1749415698625888688", "like_url": "https://x.com/intent/like?tweet_id=1749415698625888688", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749415698625888688", "replies": ["1749416477403296102"], "score": 0.3, "thread_score": 0, "reply_count": 1}, "1749416477403296102": {"created_at": "Mon Jan 22 12:59:25 +0000 2024", "entities": [{"indices": [7, 19], "type": "text", "text": "Yes exactly!"}], "favorite_count": 0, "id_str": "1749416477403296102", "in_reply_to_status_id_str": "1749415698625888688", "lang": "en", "user": {"id_str": "1523920036322512896", "name": "Machine Quest", "screen_name": "machine_quest", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1523920185081868289/8Ys9RXKJ_normal.jpg", "description": "i think therefore i exist", "entities": {"description": {"urls": []}}, "followers_count": 30, "location": "", "url": "https://x.com/machine_quest", "follow_url": "https://x.com/intent/follow?screen_name=machine_quest"}, "url": "https://x.com/machine_quest/status/1749416477403296102", "like_url": "https://x.com/intent/like?tweet_id=1749416477403296102", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749416477403296102", "replies": [], "score": 0.1, "thread_score": 0, "reply_count": 0}, "1749593140187877411": {"created_at": "Tue Jan 23 00:41:25 +0000 2024", "entities": [{"indices": [0, 408], "type": "text", "text": "7B\u30e2\u30c7\u30eb\u306e\u91cd\u307f\u309213B\u30e2\u30c7\u30eb\u306b\u30de\u30fc\u30b8\u53ef\u80fd\uff01\uff1f\n\nproxy-tuning\u306f\u30ed\u30b8\u30c3\u30c8(logits)\u3064\u307e\u308a\u3001\u6574\u5f62\u3055\u308c\u308b\u524d\u306e\u30e2\u30c7\u30eb\u306e\u6700\u7d42\u51fa\u529b\u30ec\u30a4\u30e4\u30fc\u306b\u6ce8\u76ee\u3057\u3001\u305d\u306e\u90e8\u5206\u3060\u3051\u3092\u30de\u30fc\u30b8\u3059\u308b\u30a2\u30a4\u30c7\u30a3\u30a2\n\n\u30ed\u30b8\u30c3\u30c8\u90e8\u5206\u306b\u3064\u3044\u3066\u4ee5\u4e0b\u306e\u91cd\u307f\u6f14\u7b97\u3092\u3059\u308b\n\n7B\u306e\u5fae\u8abf\u6574\u6e08\u30e2\u30c7\u30eb - 7B\u306e\u30d9\u30fc\u30b9\u30e2\u30c7\u30eb + 13B\u306e\u30d9\u30fc\u30b9\u30e2\u30c7\u30eb = \u30d5\u30e9\u30f3\u30b1\u30f3\u724813B\u306e\u5fae\u8abf\u6574\u6e08\u30e2\u30c7\u30eb\n\n\u3053\u308c\u304c\u6c4e\u7528\u7684\u306b\u5b9f\u884c\u53ef\u80fd\u3067\u3042\u308c\u3070\u3001\u5927\u5909\u306a\u601d\u3044\u3092\u3057\u3066\u5927\u304d\u3044\u30e2\u30c7\u30eb\u3092\u9811\u5f35\u3063\u3066\u5fae\u8abf\u6574\u3059\u308b\u5fc5\u8981\u306f\u306a\u304f\u306a\u308b\u30027B\u3092\u5fae\u8abf\u6574\u5f8c\u306b\u6700\u7d42\u30ec\u30a4\u30e4\u30fc\u3092\u62dd\u501f\u3057\u3066\u540c\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e13B\u306b\u304f\u3063\u3064\u3051\u308c\u3070\u3088\u3044\u4e8b\u306b\u306a\u308b\n\n\u3057\u304b\u3057\u3001\u3053\u308c\u3082\u3001\u51fa\u529b\u90e8\u5206\u306e\u6574\u5f62\u65b9\u6cd5\u3092\u79fb\u690d\u3057\u3066\u3044\u308b\u3068\u898b\u306a\u305b\u308b\u306e\u3067\u30017B\u306813B\u306e\u4e8b\u524d\u5b66\u7fd2\u5185\u5bb9\u304c\u7570\u306a\u308b\u3068\u5927\u304d\u306a\u52b9\u679c\u306f\u898b\u8fbc\u3081\u306a\u3044\u306e\u3067\u306f\u306a\u3044\u304b\u3068\u601d\u3046\n\n\u4f8b\u3048\u30707B\u30e2\u30c7\u30eb\u3067Json\u51fa\u529b\u3092\u5b88\u308b\u3088\u3046\u306b\u30d0\u30c3\u30c1\u30ea\u5b66\u7fd2\u3055\u305b\u3066\u3001\u305d\u308c\u309213B\u308470B\u306b\u79fb\u690d\u3059\u308b\u3068\u3044\u3046\u4f7f\u3044\u65b9\u306a\u3069\u304c\u8003\u3048\u3089\u308c\u308b\u304b\u3082\u3057\u308c\u306a\u3044"}], "favorite_count": 63, "id_str": "1749593140187877411", "quoted_status_id_str": "1748021765790376385", "lang": "ja", "user": {"id_str": "1242664125743783936", "name": "webbigdata", "screen_name": "webbigdata", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1246499148771127298/7s2lsloe_normal.jpg", "description": "chatGPT\u306e\u3088\u3046\u306a\u5927\u898f\u6a21\u8a00\u8a9e\u30e2\u30c7\u30eb(LLM)\u3092\u5fdc\u7528\u3057\u305f\u6a5f\u68b0\u7ffb\u8a33AI\u306e\u958b\u767a\u3084\u91cf\u5b50\u5316\u3084\u5fae\u8abf\u6574\u306b\u3088\u308b\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002\nhttps://t.co/xJqZm3mKcM", "entities": {"description": {"urls": [{"display_url": "huggingface.co/webbigdata", "expanded_url": "https://huggingface.co/webbigdata", "indices": [64, 87], "url": "https://t.co/xJqZm3mKcM"}]}, "url": {"urls": [{"display_url": "webbigdata.jp", "expanded_url": "https://webbigdata.jp/", "indices": [0, 23], "url": "https://t.co/qGiH0D6Fkr"}]}}, "followers_count": 2088, "location": "", "url": "https://x.com/webbigdata", "follow_url": "https://x.com/intent/follow?screen_name=webbigdata"}, "url": "https://x.com/webbigdata/status/1749593140187877411", "like_url": "https://x.com/intent/like?tweet_id=1749593140187877411", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749593140187877411", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1749602912051872066": {"created_at": "Tue Jan 23 01:20:14 +0000 2024", "entities": [{"indices": [0, 179], "type": "text", "text": "Tuning Language Models by Proxy - using small tuned LMs to efficiently customize large, potentially proprietary LMs through decoding-time guidance.\n\nThis is pretty interesting. \n\n"}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [179, 202], "url": "https://t.co/Vu6zrqDCis", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}], "favorite_count": 0, "id_str": "1749602912051872066", "lang": "en", "user": {"id_str": "39632781", "name": "Janaka Abeywardhana", "screen_name": "janaka_a", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1816876128209870848/pv_gAoqY_normal.jpg", "description": "Building @docqai. ex-@truelayer. ex-@hudl. Fullstack generalist, master of none. Product & Engineering. #GenAI #RAG #AIAgents #Infra.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "janaka.dev", "expanded_url": "https://janaka.dev", "indices": [0, 23], "url": "https://t.co/Bj1NHHDlLZ"}]}}, "followers_count": 1317, "location": "London, England", "url": "https://x.com/janaka_a", "follow_url": "https://x.com/intent/follow?screen_name=janaka_a"}, "url": "https://x.com/janaka_a/status/1749602912051872066", "like_url": "https://x.com/intent/like?tweet_id=1749602912051872066", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749602912051872066", "replies": [], "score": 0, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Teaser", "is_branch": true}, "1749702052731568252": {"created_at": "Tue Jan 23 07:54:11 +0000 2024", "entities": [{"indices": [0, 168], "type": "text", "text": "Imagine an AI that not only understands language but thinks and adapts like us. \ud83e\udd2f We're exploring a conceptual Semantic AI Platform that could revolutionize our world. "}, {"indices": [168, 181], "text": "#AIRevolution", "type": "hashtag", "href": "https://x.com/hashtag/AIRevolution"}, {"indices": [181, 182], "type": "text", "text": " "}, {"indices": [182, 193], "text": "#FutureOfAI", "type": "hashtag", "href": "https://x.com/hashtag/FutureOfAI"}, {"indices": [193, 210], "type": "text", "text": " \ud83d\ude80 Let's dive in!"}], "favorite_count": 3, "id_str": "1749702052731568252", "lang": "en", "mediaDetails": [{"additional_media_info": {"monetizable": false}, "display_url": "pic.x.com/TTHBeHk8rL", "expanded_url": "https://x.com/StraughterG/status/1749702052731568252/video/1", "ext_media_availability": {"status": "Available"}, "id_str": "1749691468510355456", "indices": [211, 234], "media_key": "7_1749691468510355456", "media_results": {"result": {"media_key": "7_1749691468510355456"}}, "media_url_https": "https://pbs.twimg.com/ext_tw_video_thumb/1749691468510355456/pu/img/pZxZqFNg3V7krzKs.jpg", "original_info": {"focus_rects": [], "height": 576, "width": 1024}, "sizes": {"large": {"h": 576, "resize": "fit", "w": 1024}, "medium": {"h": 576, "resize": "fit", "w": 1024}, "small": {"h": 383, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "video", "url": "https://t.co/TTHBeHk8rL", "video_info": {"aspect_ratio": [16, 9], "duration_millis": 4173, "variants": [{"content_type": "application/x-mpegURL", "url": "https://video.twimg.com/ext_tw_video/1749691468510355456/pu/pl/vFT6y0fXaOYDsLc_.m3u8?tag=12"}, {"bitrate": 256000, "content_type": "video/mp4", "url": "https://video.twimg.com/ext_tw_video/1749691468510355456/pu/vid/avc1/480x270/O__QKwcU1Wh4lueR.mp4?tag=12"}, {"bitrate": 832000, "content_type": "video/mp4", "url": "https://video.twimg.com/ext_tw_video/1749691468510355456/pu/vid/avc1/640x360/Lvx6tMRExxx1P_ju.mp4?tag=12"}, {"bitrate": 2176000, "content_type": "video/mp4", "url": "https://video.twimg.com/ext_tw_video/1749691468510355456/pu/vid/avc1/1024x576/2LiwBXVvDwxufBHG.mp4?tag=12"}]}}], "user": {"id_str": "466018955", "name": "Jay Guthrie", "screen_name": "StraughterG", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1749768702596087808/F-AzGzRu_normal.jpg", "description": "Machine Learning Expert | Specializing in GPT Development & AI-Powered Systems | Innovator in Agent-Based Modeling | Advancing AI with Robust RAG Pipelines.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "\u2026guthrieportfolio-o30x277mn.vercel.app", "expanded_url": "https://straughterguthrieportfolio-o30x277mn.vercel.app", "indices": [0, 23], "url": "https://t.co/o9cfAtA0S4"}]}}, "followers_count": 985, "location": "The United States", "url": "https://x.com/StraughterG", "follow_url": "https://x.com/intent/follow?screen_name=StraughterG"}, "url": "https://x.com/StraughterG/status/1749702052731568252", "like_url": "https://x.com/intent/like?tweet_id=1749702052731568252", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749702052731568252", "replies": ["1749702054300307704"], "score": 0, "thread_score": 0.4, "reply_count": 7, "tweet_type": "Resource", "location": "related work", "is_branch": true}, "1749702054300307704": {"created_at": "Tue Jan 23 07:54:12 +0000 2024", "entities": [{"indices": [0, 226], "type": "text", "text": "What if AI could understand us better than ever before? \ud83e\udde0 Introducing the core of our conceptual platform:\n\u26d3\ufe0fSemantic Retrieval with ColBERTv2\n\u26d3\ufe0fAdaptive Learning via Semantic Proxy\n\u26d3\ufe0fSeamless Integration with Semantic Kernel "}, {"indices": [226, 237], "text": "#SemanticAI", "type": "hashtag", "href": "https://x.com/hashtag/SemanticAI"}, {"indices": [237, 238], "type": "text", "text": " "}, {"indices": [238, 249], "text": "#TechTrends", "type": "hashtag", "href": "https://x.com/hashtag/TechTrends"}], "favorite_count": 0, "id_str": "1749702054300307704", "in_reply_to_status_id_str": "1749702052731568252", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/ZCgmXRXP4B", "expanded_url": "https://x.com/StraughterG/status/1749702054300307704/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": [{"h": 53, "w": 53, "x": 443, "y": 957}]}, "medium": {"faces": [{"h": 53, "w": 53, "x": 443, "y": 957}]}, "orig": {"faces": [{"h": 53, "w": 53, "x": 443, "y": 957}]}, "small": {"faces": [{"h": 35, "w": 35, "x": 294, "y": 635}]}}, "id_str": "1749692690248110080", "indices": [250, 273], "media_key": "3_1749692690248110080", "media_results": {"result": {"media_key": "3_1749692690248110080"}}, "media_url_https": "https://pbs.twimg.com/media/GEgoO0RWEAAWrx1.jpg", "original_info": {"focus_rects": [{"h": 573, "w": 1024, "x": 0, "y": 451}, {"h": 1024, "w": 1024, "x": 0, "y": 0}, {"h": 1024, "w": 898, "x": 0, "y": 0}, {"h": 1024, "w": 512, "x": 76, "y": 0}, {"h": 1024, "w": 1024, "x": 0, "y": 0}], "height": 1024, "width": 1024}, "sizes": {"large": {"h": 1024, "resize": "fit", "w": 1024}, "medium": {"h": 1024, "resize": "fit", "w": 1024}, "small": {"h": 680, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/ZCgmXRXP4B"}], "user": {"id_str": "466018955", "name": "Jay Guthrie", "screen_name": "StraughterG", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1749768702596087808/F-AzGzRu_normal.jpg", "description": "Machine Learning Expert | Specializing in GPT Development & AI-Powered Systems | Innovator in Agent-Based Modeling | Advancing AI with Robust RAG Pipelines.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "\u2026guthrieportfolio-o30x277mn.vercel.app", "expanded_url": "https://straughterguthrieportfolio-o30x277mn.vercel.app", "indices": [0, 23], "url": "https://t.co/o9cfAtA0S4"}]}}, "followers_count": 985, "location": "The United States", "url": "https://x.com/StraughterG", "follow_url": "https://x.com/intent/follow?screen_name=StraughterG"}, "url": "https://x.com/StraughterG/status/1749702054300307704", "like_url": "https://x.com/intent/like?tweet_id=1749702054300307704", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749702054300307704", "replies": ["1749702056275759602"], "score": 0, "thread_score": 0, "reply_count": 6}, "1749702056275759602": {"created_at": "Tue Jan 23 07:54:12 +0000 2024", "entities": [{"indices": [0, 221], "type": "text", "text": "Picture this: An AI that chunks language by its meaning, not just words. \ud83c\udf10 This is the power of Semantic Chunking. Combined with ColBERTv2\u2019s precision, we're talking about a breakthrough in understanding and interaction. "}, {"indices": [221, 225], "text": "#NLP", "type": "hashtag", "href": "https://x.com/hashtag/NLP"}, {"indices": [225, 226], "type": "text", "text": " "}, {"indices": [226, 233], "text": "#AITECH", "type": "hashtag", "href": "https://x.com/hashtag/AITECH"}], "favorite_count": 0, "id_str": "1749702056275759602", "in_reply_to_status_id_str": "1749702054300307704", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/qFuyFIhtAn", "expanded_url": "https://x.com/StraughterG/status/1749702056275759602/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": [{"h": 284, "w": 284, "x": 822, "y": 462}, {"h": 490, "w": 490, "x": 720, "y": 824}]}, "medium": {"faces": [{"h": 166, "w": 166, "x": 481, "y": 270}, {"h": 287, "w": 287, "x": 421, "y": 482}]}, "orig": {"faces": [{"h": 284, "w": 284, "x": 822, "y": 462}, {"h": 490, "w": 490, "x": 720, "y": 824}]}, "small": {"faces": [{"h": 94, "w": 94, "x": 272, "y": 153}, {"h": 162, "w": 162, "x": 239, "y": 273}]}}, "id_str": "1749693165160841216", "indices": [234, 257], "media_key": "3_1749693165160841216", "media_results": {"result": {"media_key": "3_1749693165160841216"}}, "media_url_https": "https://pbs.twimg.com/media/GEgoqddXQAAa_tX.jpg", "original_info": {"focus_rects": [{"h": 1147, "w": 2048, "x": 0, "y": 0}, {"h": 2048, "w": 2048, "x": 0, "y": 0}, {"h": 2048, "w": 1796, "x": 177, "y": 0}, {"h": 2048, "w": 1024, "x": 563, "y": 0}, {"h": 2048, "w": 2048, "x": 0, "y": 0}], "height": 2048, "width": 2048}, "sizes": {"large": {"h": 2048, "resize": "fit", "w": 2048}, "medium": {"h": 1200, "resize": "fit", "w": 1200}, "small": {"h": 680, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/qFuyFIhtAn"}], "user": {"id_str": "466018955", "name": "Jay Guthrie", "screen_name": "StraughterG", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1749768702596087808/F-AzGzRu_normal.jpg", "description": "Machine Learning Expert | Specializing in GPT Development & AI-Powered Systems | Innovator in Agent-Based Modeling | Advancing AI with Robust RAG Pipelines.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "\u2026guthrieportfolio-o30x277mn.vercel.app", "expanded_url": "https://straughterguthrieportfolio-o30x277mn.vercel.app", "indices": [0, 23], "url": "https://t.co/o9cfAtA0S4"}]}}, "followers_count": 985, "location": "The United States", "url": "https://x.com/StraughterG", "follow_url": "https://x.com/intent/follow?screen_name=StraughterG"}, "url": "https://x.com/StraughterG/status/1749702056275759602", "like_url": "https://x.com/intent/like?tweet_id=1749702056275759602", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749702056275759602", "replies": ["1749702058834375114"], "score": 0, "thread_score": 0, "reply_count": 5}, "1749702058834375114": {"created_at": "Tue Jan 23 07:54:13 +0000 2024", "entities": [{"indices": [0, 169], "type": "text", "text": "How would a super-intelligent AI change your daily life or business? \ud83c\udfe2\ud83d\udca1 From smart search engines to intuitive chatbots, the applications are endless. Share your ideas! "}, {"indices": [169, 184], "text": "#AIApplications", "type": "hashtag", "href": "https://x.com/hashtag/AIApplications"}, {"indices": [184, 185], "type": "text", "text": " "}, {"indices": [185, 199], "text": "#DigitalFuture", "type": "hashtag", "href": "https://x.com/hashtag/DigitalFuture"}], "favorite_count": 0, "id_str": "1749702058834375114", "in_reply_to_status_id_str": "1749702056275759602", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/9TfxxZwvR3", "expanded_url": "https://x.com/StraughterG/status/1749702058834375114/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1749694041493581825", "indices": [200, 223], "media_key": "3_1749694041493581825", "media_results": {"result": {"media_key": "3_1749694041493581825"}}, "media_url_https": "https://pbs.twimg.com/media/GEgpdeDXsAE5EzV.jpg", "original_info": {"focus_rects": [{"h": 573, "w": 1024, "x": 0, "y": 0}, {"h": 1024, "w": 1024, "x": 0, "y": 0}, {"h": 1024, "w": 898, "x": 37, "y": 0}, {"h": 1024, "w": 512, "x": 230, "y": 0}, {"h": 1024, "w": 1024, "x": 0, "y": 0}], "height": 1024, "width": 1024}, "sizes": {"large": {"h": 1024, "resize": "fit", "w": 1024}, "medium": {"h": 1024, "resize": "fit", "w": 1024}, "small": {"h": 680, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/9TfxxZwvR3"}], "user": {"id_str": "466018955", "name": "Jay Guthrie", "screen_name": "StraughterG", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1749768702596087808/F-AzGzRu_normal.jpg", "description": "Machine Learning Expert | Specializing in GPT Development & AI-Powered Systems | Innovator in Agent-Based Modeling | Advancing AI with Robust RAG Pipelines.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "\u2026guthrieportfolio-o30x277mn.vercel.app", "expanded_url": "https://straughterguthrieportfolio-o30x277mn.vercel.app", "indices": [0, 23], "url": "https://t.co/o9cfAtA0S4"}]}}, "followers_count": 985, "location": "The United States", "url": "https://x.com/StraughterG", "follow_url": "https://x.com/intent/follow?screen_name=StraughterG"}, "url": "https://x.com/StraughterG/status/1749702058834375114", "like_url": "https://x.com/intent/like?tweet_id=1749702058834375114", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749702058834375114", "replies": ["1749702060805697765"], "score": 0, "thread_score": 0, "reply_count": 4}, "1749702060805697765": {"created_at": "Tue Jan 23 07:54:13 +0000 2024", "entities": [{"indices": [0, 222], "type": "text", "text": "Ever wished for tech that\u2019s powerful yet simple? That's our goal. \u2728 Imagine an AI platform that\u2019s:\n\u26d3\ufe0fEasy and efficient to scale\n\u26d3\ufe0fFlexible across industries\n\u26d3\ufe0fAt the forefront of AI tech\n\nWhat's your priority in AI tech? "}, {"indices": [222, 234], "text": "#EfficientAI", "type": "hashtag", "href": "https://x.com/hashtag/EfficientAI"}, {"indices": [234, 235], "type": "text", "text": " "}, {"indices": [235, 250], "text": "#TechInnovation", "type": "hashtag", "href": "https://x.com/hashtag/TechInnovation"}], "favorite_count": 1, "id_str": "1749702060805697765", "in_reply_to_status_id_str": "1749702058834375114", "lang": "en", "mediaDetails": [{"additional_media_info": {"monetizable": false}, "display_url": "pic.x.com/KLZXYKGd2j", "expanded_url": "https://x.com/StraughterG/status/1749702060805697765/video/1", "ext_media_availability": {"status": "Available"}, "id_str": "1749695061959303168", "indices": [251, 274], "media_key": "7_1749695061959303168", "media_results": {"result": {"media_key": "7_1749695061959303168"}}, "media_url_https": "https://pbs.twimg.com/ext_tw_video_thumb/1749695061959303168/pu/img/HwFAWD3rS3y2C1DO.jpg", "original_info": {"focus_rects": [], "height": 576, "width": 1024}, "sizes": {"large": {"h": 576, "resize": "fit", "w": 1024}, "medium": {"h": 576, "resize": "fit", "w": 1024}, "small": {"h": 383, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "video", "url": "https://t.co/KLZXYKGd2j", "video_info": {"aspect_ratio": [16, 9], "duration_millis": 4173, "variants": [{"content_type": "application/x-mpegURL", "url": "https://video.twimg.com/ext_tw_video/1749695061959303168/pu/pl/e_PLQZkqtX-c_Sbu.m3u8?tag=12"}, {"bitrate": 256000, "content_type": "video/mp4", "url": "https://video.twimg.com/ext_tw_video/1749695061959303168/pu/vid/avc1/480x270/ekVQDHv2ZfHRGUVF.mp4?tag=12"}, {"bitrate": 832000, "content_type": "video/mp4", "url": "https://video.twimg.com/ext_tw_video/1749695061959303168/pu/vid/avc1/640x360/ux1ir5DmspQwqzsX.mp4?tag=12"}, {"bitrate": 2176000, "content_type": "video/mp4", "url": "https://video.twimg.com/ext_tw_video/1749695061959303168/pu/vid/avc1/1024x576/9C863WYZgCqMloIy.mp4?tag=12"}]}}], "user": {"id_str": "466018955", "name": "Jay Guthrie", "screen_name": "StraughterG", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1749768702596087808/F-AzGzRu_normal.jpg", "description": "Machine Learning Expert | Specializing in GPT Development & AI-Powered Systems | Innovator in Agent-Based Modeling | Advancing AI with Robust RAG Pipelines.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "\u2026guthrieportfolio-o30x277mn.vercel.app", "expanded_url": "https://straughterguthrieportfolio-o30x277mn.vercel.app", "indices": [0, 23], "url": "https://t.co/o9cfAtA0S4"}]}}, "followers_count": 985, "location": "The United States", "url": "https://x.com/StraughterG", "follow_url": "https://x.com/intent/follow?screen_name=StraughterG"}, "url": "https://x.com/StraughterG/status/1749702060805697765", "like_url": "https://x.com/intent/like?tweet_id=1749702060805697765", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749702060805697765", "replies": ["1749702062403731559"], "score": 0, "thread_score": 0, "reply_count": 3}, "1749702062403731559": {"created_at": "Tue Jan 23 07:54:14 +0000 2024", "entities": [{"indices": [0, 177], "type": "text", "text": "No breakthrough comes without challenges. \ud83d\udea7 We\u2019re talking complex tech integration, ongoing learning, and navigating ethics in AI. How would you tackle these? Let's brainstorm! "}, {"indices": [177, 190], "text": "#AIChallenges", "type": "hashtag", "href": "https://x.com/hashtag/AIChallenges"}, {"indices": [190, 191], "type": "text", "text": " "}, {"indices": [191, 201], "text": "#EthicalAI", "type": "hashtag", "href": "https://x.com/hashtag/EthicalAI"}], "favorite_count": 0, "id_str": "1749702062403731559", "in_reply_to_status_id_str": "1749702060805697765", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/KbpRPEvqjd", "expanded_url": "https://x.com/StraughterG/status/1749702062403731559/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1749695322417143810", "indices": [202, 225], "media_key": "3_1749695322417143810", "media_results": {"result": {"media_key": "3_1749695322417143810"}}, "media_url_https": "https://pbs.twimg.com/media/GEgqoB3WIAI9jA1.jpg", "original_info": {"focus_rects": [{"h": 573, "w": 1024, "x": 0, "y": 200}, {"h": 1024, "w": 1024, "x": 0, "y": 0}, {"h": 1024, "w": 898, "x": 0, "y": 0}, {"h": 1024, "w": 512, "x": 76, "y": 0}, {"h": 1024, "w": 1024, "x": 0, "y": 0}], "height": 1024, "width": 1024}, "sizes": {"large": {"h": 1024, "resize": "fit", "w": 1024}, "medium": {"h": 1024, "resize": "fit", "w": 1024}, "small": {"h": 680, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/KbpRPEvqjd"}], "user": {"id_str": "466018955", "name": "Jay Guthrie", "screen_name": "StraughterG", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1749768702596087808/F-AzGzRu_normal.jpg", "description": "Machine Learning Expert | Specializing in GPT Development & AI-Powered Systems | Innovator in Agent-Based Modeling | Advancing AI with Robust RAG Pipelines.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "\u2026guthrieportfolio-o30x277mn.vercel.app", "expanded_url": "https://straughterguthrieportfolio-o30x277mn.vercel.app", "indices": [0, 23], "url": "https://t.co/o9cfAtA0S4"}]}}, "followers_count": 985, "location": "The United States", "url": "https://x.com/StraughterG", "follow_url": "https://x.com/intent/follow?screen_name=StraughterG"}, "url": "https://x.com/StraughterG/status/1749702062403731559", "like_url": "https://x.com/intent/like?tweet_id=1749702062403731559", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749702062403731559", "replies": ["1749702064299508206"], "score": 0, "thread_score": 0, "reply_count": 2}, "1749702064299508206": {"created_at": "Tue Jan 23 07:54:14 +0000 2024", "entities": [{"indices": [0, 195], "type": "text", "text": "This journey into the future of AI is more than a thought experiment. It's a conversation starter. \ud83c\udf1f What\u2019s your vision for AI\u2019s next big leap? Comment below and let\u2019s shape the future together! "}, {"indices": [195, 204], "text": "#AIFuture", "type": "hashtag", "href": "https://x.com/hashtag/AIFuture"}, {"indices": [204, 205], "type": "text", "text": " "}, {"indices": [205, 219], "text": "#TechCommunity", "type": "hashtag", "href": "https://x.com/hashtag/TechCommunity"}], "favorite_count": 0, "id_str": "1749702064299508206", "in_reply_to_status_id_str": "1749702062403731559", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/0PUCmOGASP", "expanded_url": "https://x.com/StraughterG/status/1749702064299508206/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1749696611456868352", "indices": [220, 243], "media_key": "3_1749696611456868352", "media_results": {"result": {"media_key": "3_1749696611456868352"}}, "media_url_https": "https://pbs.twimg.com/media/GEgrzD6XYAAM8Cq.jpg", "original_info": {"focus_rects": [{"h": 573, "w": 1024, "x": 0, "y": 149}, {"h": 1024, "w": 1024, "x": 0, "y": 0}, {"h": 1024, "w": 898, "x": 0, "y": 0}, {"h": 1024, "w": 512, "x": 128, "y": 0}, {"h": 1024, "w": 1024, "x": 0, "y": 0}], "height": 1024, "width": 1024}, "sizes": {"large": {"h": 1024, "resize": "fit", "w": 1024}, "medium": {"h": 1024, "resize": "fit", "w": 1024}, "small": {"h": 680, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/0PUCmOGASP"}], "user": {"id_str": "466018955", "name": "Jay Guthrie", "screen_name": "StraughterG", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1749768702596087808/F-AzGzRu_normal.jpg", "description": "Machine Learning Expert | Specializing in GPT Development & AI-Powered Systems | Innovator in Agent-Based Modeling | Advancing AI with Robust RAG Pipelines.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "\u2026guthrieportfolio-o30x277mn.vercel.app", "expanded_url": "https://straughterguthrieportfolio-o30x277mn.vercel.app", "indices": [0, 23], "url": "https://t.co/o9cfAtA0S4"}]}}, "followers_count": 985, "location": "The United States", "url": "https://x.com/StraughterG", "follow_url": "https://x.com/intent/follow?screen_name=StraughterG"}, "url": "https://x.com/StraughterG/status/1749702064299508206", "like_url": "https://x.com/intent/like?tweet_id=1749702064299508206", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749702064299508206", "replies": ["1749702066799354301"], "score": 0, "thread_score": 0, "reply_count": 1}, "1749702066799354301": {"created_at": "Tue Jan 23 07:54:15 +0000 2024", "entities": [{"indices": [0, 37], "type": "text", "text": "Craving more AI insights? Check out \n"}, {"display_url": "arxiv.org/abs/2112.01488", "expanded_url": "https://arxiv.org/abs/2112.01488", "indices": [37, 60], "url": "https://t.co/84oWrqMq3W", "type": "url", "href": "https://arxiv.org/abs/2112.01488", "text": "arxiv.org/abs/2112.01488"}, {"indices": [60, 62], "type": "text", "text": ", "}, {"display_url": "github.com/microsoft/sema\u2026", "expanded_url": "https://github.com/microsoft/semantic-kernel", "indices": [62, 85], "url": "https://t.co/3DtgATu3FP", "type": "url", "href": "https://github.com/microsoft/semantic-kernel", "text": "github.com/microsoft/sema\u2026"}, {"indices": [85, 87], "type": "text", "text": ", "}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [87, 110], "url": "https://t.co/z8oHa6GKmx", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}, {"indices": [110, 112], "type": "text", "text": ", "}, {"display_url": "reddit.com/r/LocalLLaMA/c\u2026", "expanded_url": "https://www.reddit.com/r/LocalLLaMA/comments/19dg8pk/new_paper_proxytuning_an_efficient_alternative_to/", "indices": [112, 135], "url": "https://t.co/rrskiKK4Jj", "type": "url", "href": "https://www.reddit.com/r/LocalLLaMA/comments/19dg8pk/new_paper_proxytuning_an_efficient_alternative_to/", "text": "reddit.com/r/LocalLLaMA/c\u2026"}, {"indices": [135, 137], "type": "text", "text": ", "}, {"display_url": "medium.com/@zz1409/colber\u2026", "expanded_url": "https://medium.com/@zz1409/colbert-a-late-interaction-model-for-semantic-search-da00f052d30e", "indices": [137, 160], "url": "https://t.co/OxDtyeMgCf", "type": "url", "href": "https://medium.com/@zz1409/colbert-a-late-interaction-model-for-semantic-search-da00f052d30e", "text": "medium.com/@zz1409/colber\u2026"}, {"indices": [160, 162], "type": "text", "text": ", "}, {"display_url": "x.com/gregkamradt/st\u2026", "expanded_url": "https://twitter.com/GregKamradt/status/1745467853799874969", "indices": [162, 185], "url": "https://t.co/fo3Waucobl", "type": "url", "href": "https://twitter.com/GregKamradt/status/1745467853799874969", "text": "x.com/gregkamradt/st\u2026"}, {"indices": [185, 266], "type": "text", "text": ". But first, tell us: What's one AI innovation you hope to see in your lifetime? "}, {"indices": [266, 280], "text": "#AIExploration", "type": "hashtag", "href": "https://x.com/hashtag/AIExploration"}, {"indices": [280, 281], "type": "text", "text": " "}, {"indices": [281, 291], "text": "#TechTalks", "type": "hashtag", "href": "https://x.com/hashtag/TechTalks"}], "favorite_count": 0, "id_str": "1749702066799354301", "quoted_status_id_str": "1745467853799874969", "in_reply_to_status_id_str": "1749702064299508206", "lang": "en", "mediaDetails": [{"additional_media_info": {"monetizable": false}, "display_url": "pic.x.com/8snfWO7NxG", "expanded_url": "https://x.com/StraughterG/status/1749702066799354301/video/1", "ext_media_availability": {"status": "Available"}, "id_str": "1749697337771868160", "indices": [282, 305], "media_key": "7_1749697337771868160", "media_results": {"result": {"media_key": "7_1749697337771868160"}}, "media_url_https": "https://pbs.twimg.com/ext_tw_video_thumb/1749697337771868160/pu/img/P2K3kml4JlIb2cgV.jpg", "original_info": {"focus_rects": [], "height": 576, "width": 1024}, "sizes": {"large": {"h": 576, "resize": "fit", "w": 1024}, "medium": {"h": 576, "resize": "fit", "w": 1024}, "small": {"h": 383, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "video", "url": "https://t.co/8snfWO7NxG", "video_info": {"aspect_ratio": [16, 9], "duration_millis": 4173, "variants": [{"content_type": "application/x-mpegURL", "url": "https://video.twimg.com/ext_tw_video/1749697337771868160/pu/pl/hALYE0WMSBzKaWiL.m3u8?tag=12"}, {"bitrate": 256000, "content_type": "video/mp4", "url": "https://video.twimg.com/ext_tw_video/1749697337771868160/pu/vid/avc1/480x270/zo2kAKYuwQ5e4mNv.mp4?tag=12"}, {"bitrate": 832000, "content_type": "video/mp4", "url": "https://video.twimg.com/ext_tw_video/1749697337771868160/pu/vid/avc1/640x360/948fVZOavR89ps2V.mp4?tag=12"}, {"bitrate": 2176000, "content_type": "video/mp4", "url": "https://video.twimg.com/ext_tw_video/1749697337771868160/pu/vid/avc1/1024x576/KmdPTuy9mwI7U1dV.mp4?tag=12"}]}}], "user": {"id_str": "466018955", "name": "Jay Guthrie", "screen_name": "StraughterG", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1749768702596087808/F-AzGzRu_normal.jpg", "description": "Machine Learning Expert | Specializing in GPT Development & AI-Powered Systems | Innovator in Agent-Based Modeling | Advancing AI with Robust RAG Pipelines.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "\u2026guthrieportfolio-o30x277mn.vercel.app", "expanded_url": "https://straughterguthrieportfolio-o30x277mn.vercel.app", "indices": [0, 23], "url": "https://t.co/o9cfAtA0S4"}]}}, "followers_count": 985, "location": "The United States", "url": "https://x.com/StraughterG", "follow_url": "https://x.com/intent/follow?screen_name=StraughterG"}, "url": "https://x.com/StraughterG/status/1749702066799354301", "like_url": "https://x.com/intent/like?tweet_id=1749702066799354301", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749702066799354301", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1749749451772817478": {"created_at": "Tue Jan 23 11:02:32 +0000 2024", "entities": [{"indices": [0, 1], "type": "text", "text": "\ud83d\udc40"}], "favorite_count": 0, "id_str": "1749749451772817478", "quoted_status_id_str": "1748021765790376385", "lang": "art", "user": {"id_str": "105658557", "name": "John K.Happy", "screen_name": "manjiroukeigo", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1883358251435311104/QddhNMeZ_normal.jpg", "description": "Physics/Computational Neuroscience/DevOps GitOps AIOps engineer/SRE/Generative AI/ \u500b\u4eba\u958b\u767a", "entities": {"description": {"urls": []}}, "followers_count": 1702, "location": "", "url": "https://x.com/manjiroukeigo", "follow_url": "https://x.com/intent/follow?screen_name=manjiroukeigo"}, "url": "https://x.com/manjiroukeigo/status/1749749451772817478", "like_url": "https://x.com/intent/like?tweet_id=1749749451772817478", "reply_url": "https://x.com/intent/tweet?in_reply_to=1749749451772817478", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1750308954427568374": {"created_at": "Thu Jan 25 00:05:48 +0000 2024", "entities": [{"indices": [0, 39], "type": "text", "text": "[30/30] 85 Likes, 17 Comments, 2 Posts\n"}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [39, 62], "url": "https://t.co/qJYJde1EbE", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}, {"indices": [62, 199], "type": "text", "text": " cs\u2024CL, 16 Jan 2024\n\n\ud83c\udd95Tuning Language Models by Proxy\n\nAlisa Liu, Xiaochuang Han, Yizhong Wang, Yulia Tsvetkov, Yejin Choi, Noah A. Smith"}], "favorite_count": 0, "id_str": "1750308954427568374", "lang": "in", "mediaDetails": [{"display_url": "pic.x.com/0Ib8BIWpuT", "expanded_url": "https://x.com/susumuota/status/1750308954427568374/photo/1", "ext_alt_text": "Despite the general capabilities of large pretrained language models, they consistently benefit from further adaptation to better achieve desired behaviors.  However, tuning these models has become increasingly resource-intensive, or impossible when model weights are private.  We introduce proxy-tuning, a lightweight decoding-time algorithm that operates on top of black-box LMs to achieve the result of directly tuning the model, but by accessing only its prediction over the output vocabulary.  Our method instead tunes a smaller LM, then applies the difference between the predictions of the small tuned and untuned LMs to shift the original predictions of the base model in the direction of tuning, while retaining the benefits of larger scale pretraining.  In experiments, when we apply proxy-tuning to Llama2-70B using proxies of only 7B size, we can close 88% of the gap between Llama2-70B and its truly-tuned chat version, when evaluated across knowledge, reasoning, and safety benchmark...", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1750308951218913281", "indices": [200, 223], "media_key": "3_1750308951218913281", "media_results": {"result": {"media_key": "3_1750308951218913281"}}, "media_url_https": "https://pbs.twimg.com/media/GEpYt7SXAAEutFD.jpg", "original_info": {"focus_rects": [{"h": 672, "w": 1200, "x": 0, "y": 0}, {"h": 1200, "w": 1200, "x": 0, "y": 0}, {"h": 1368, "w": 1200, "x": 0, "y": 0}, {"h": 1553, "w": 777, "x": 194, "y": 0}, {"h": 1553, "w": 1200, "x": 0, "y": 0}], "height": 1553, "width": 1200}, "sizes": {"large": {"h": 1553, "resize": "fit", "w": 1200}, "medium": {"h": 1200, "resize": "fit", "w": 927}, "small": {"h": 680, "resize": "fit", "w": 525}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/0Ib8BIWpuT"}], "user": {"id_str": "279718877", "name": "S. Ota", "screen_name": "susumuota", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1622591377971507202/EcBLlAUc_normal.png", "description": "Summarize the top 30 most popular arXiv papers on Reddit, Hacker News and Hugging Face in the last 30 days.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "github.com/susumuota/arxi\u2026", "expanded_url": "https://github.com/susumuota/arxiv-reddit-summary", "indices": [0, 23], "url": "https://t.co/2elTmmwsNY"}]}}, "followers_count": 671, "location": "Japan", "url": "https://x.com/susumuota", "follow_url": "https://x.com/intent/follow?screen_name=susumuota"}, "url": "https://x.com/susumuota/status/1750308954427568374", "like_url": "https://x.com/intent/like?tweet_id=1750308954427568374", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750308954427568374", "replies": ["1750308960266035360"], "score": 0, "thread_score": 0, "reply_count": 4}, "1750308960266035360": {"created_at": "Thu Jan 25 00:05:49 +0000 2024", "entities": [{"indices": [0, 9], "type": "text", "text": "Twitter: "}, {"display_url": "x.com/search?q=arxiv\u2026", "expanded_url": "https://x.com/search?q=arxiv.org%2Fabs%2F2401.08565%20OR%20arxiv.org%2Fpdf%2F2401.08565.pdf", "indices": [9, 32], "url": "https://t.co/vo662NrJZ0", "type": "url", "href": "https://x.com/search?q=arxiv.org%2Fabs%2F2401.08565%20OR%20arxiv.org%2Fpdf%2F2401.08565.pdf", "text": "x.com/search?q=arxiv\u2026"}, {"indices": [32, 42], "type": "text", "text": " \nReddit: "}, {"display_url": "reddit.com/search/?q=%222\u2026", "expanded_url": "https://www.reddit.com/search/?q=%222401.08565%22&sort=top", "indices": [42, 65], "url": "https://t.co/yq16LHK0k4", "type": "url", "href": "https://www.reddit.com/search/?q=%222401.08565%22&sort=top", "text": "reddit.com/search/?q=%222\u2026"}], "favorite_count": 0, "id_str": "1750308960266035360", "in_reply_to_status_id_str": "1750308954427568374", "lang": "en", "user": {"id_str": "279718877", "name": "S. Ota", "screen_name": "susumuota", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1622591377971507202/EcBLlAUc_normal.png", "description": "Summarize the top 30 most popular arXiv papers on Reddit, Hacker News and Hugging Face in the last 30 days.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "github.com/susumuota/arxi\u2026", "expanded_url": "https://github.com/susumuota/arxiv-reddit-summary", "indices": [0, 23], "url": "https://t.co/2elTmmwsNY"}]}}, "followers_count": 671, "location": "Japan", "url": "https://x.com/susumuota", "follow_url": "https://x.com/intent/follow?screen_name=susumuota"}, "url": "https://x.com/susumuota/status/1750308960266035360", "like_url": "https://x.com/intent/like?tweet_id=1750308960266035360", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750308960266035360", "replies": ["1750308965257277667"], "score": 0, "thread_score": 0, "reply_count": 3}, "1750308965257277667": {"created_at": "Thu Jan 25 00:05:51 +0000 2024", "entities": [{"indices": [0, 49], "type": "text", "text": "(1/2) 70 Likes, 15 Comments, 23 Jan 2024, Reddit\n"}, {"display_url": "reddit.com/19dg8pk", "expanded_url": "https://reddit.com/19dg8pk", "indices": [49, 72], "url": "https://t.co/PLgFm3pRZ7", "type": "url", "href": "https://reddit.com/19dg8pk", "text": "reddit.com/19dg8pk"}], "favorite_count": 0, "id_str": "1750308965257277667", "in_reply_to_status_id_str": "1750308960266035360", "lang": "en", "user": {"id_str": "279718877", "name": "S. Ota", "screen_name": "susumuota", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1622591377971507202/EcBLlAUc_normal.png", "description": "Summarize the top 30 most popular arXiv papers on Reddit, Hacker News and Hugging Face in the last 30 days.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "github.com/susumuota/arxi\u2026", "expanded_url": "https://github.com/susumuota/arxiv-reddit-summary", "indices": [0, 23], "url": "https://t.co/2elTmmwsNY"}]}}, "followers_count": 671, "location": "Japan", "url": "https://x.com/susumuota", "follow_url": "https://x.com/intent/follow?screen_name=susumuota"}, "url": "https://x.com/susumuota/status/1750308965257277667", "like_url": "https://x.com/intent/like?tweet_id=1750308965257277667", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750308965257277667", "replies": ["1750308970219147453"], "score": 0, "thread_score": 0, "reply_count": 2}, "1750308970219147453": {"created_at": "Thu Jan 25 00:05:52 +0000 2024", "entities": [{"indices": [0, 54], "type": "text", "text": "(2/2) 15 Likes, 2 Comments, 17 Jan 2024, Hugging Face\n"}, {"display_url": "huggingface.co/papers/2401.08\u2026", "expanded_url": "https://huggingface.co/papers/2401.08565", "indices": [54, 77], "url": "https://t.co/alNTxb6mRE", "type": "url", "href": "https://huggingface.co/papers/2401.08565", "text": "huggingface.co/papers/2401.08\u2026"}], "favorite_count": 0, "id_str": "1750308970219147453", "in_reply_to_status_id_str": "1750308965257277667", "lang": "en", "user": {"id_str": "279718877", "name": "S. Ota", "screen_name": "susumuota", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1622591377971507202/EcBLlAUc_normal.png", "description": "Summarize the top 30 most popular arXiv papers on Reddit, Hacker News and Hugging Face in the last 30 days.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "github.com/susumuota/arxi\u2026", "expanded_url": "https://github.com/susumuota/arxiv-reddit-summary", "indices": [0, 23], "url": "https://t.co/2elTmmwsNY"}]}}, "followers_count": 671, "location": "Japan", "url": "https://x.com/susumuota", "follow_url": "https://x.com/intent/follow?screen_name=susumuota"}, "url": "https://x.com/susumuota/status/1750308970219147453", "like_url": "https://x.com/intent/like?tweet_id=1750308970219147453", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750308970219147453", "replies": ["1750308991735910553"], "score": 0, "thread_score": 0, "reply_count": 1}, "1750308991735910553": {"created_at": "Thu Jan 25 00:05:57 +0000 2024", "entities": [{"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [0, 23], "url": "https://t.co/qJYJde1EbE", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}, {"indices": [23, 149], "type": "text", "text": "\n\u4e8b\u524d\u306b\u8a13\u7df4\u3055\u308c\u305f\u5927\u898f\u6a21\u306a\u8a00\u8a9e\u30e2\u30c7\u30eb\u306e\u4e00\u822c\u7684\u306a\u80fd\u529b\u306b\u3082\u304b\u304b\u308f\u3089\u305a\u3001\u305d\u308c\u3089\u306f\u5e38\u306b\u3001\u671b\u307e\u3057\u3044\u52d5\u4f5c\u3092\u3088\u308a\u3088\u304f\u9054\u6210\u3059\u308b\u305f\u3081\u306e\u3055\u3089\u306a\u308b\u9069\u5fdc\u304b\u3089\u6069\u6075\u3092\u53d7\u3051\u308b\u3002\u3057\u304b\u3057\u3001\u3053\u306e\u3088\u3046\u306a\u30e2\u30c7\u30eb\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306f\u3001\u307e\u3059\u307e\u3059\u30ea\u30bd\u30fc\u30b9\u3092\u5fc5\u8981\u3068\u3059\u308b\u3088\u3046\u306b\u306a\u308a\u3001\u30e2\u30c7\u30eb\u306e\u91cd\u307f\u304c\u975e\u516c..."}], "favorite_count": 0, "id_str": "1750308991735910553", "in_reply_to_status_id_str": "1750308970219147453", "lang": "ja", "mediaDetails": [{"display_url": "pic.x.com/MlSGycjjZh", "expanded_url": "https://x.com/susumuota/status/1750308991735910553/photo/1", "ext_alt_text": "\u4e8b\u524d\u306b\u8a13\u7df4\u3055\u308c\u305f\u5927\u898f\u6a21\u306a\u8a00\u8a9e\u30e2\u30c7\u30eb\u306e\u4e00\u822c\u7684\u306a\u80fd\u529b\u306b\u3082\u304b\u304b\u308f\u3089\u305a\u3001\u305d\u308c\u3089\u306f\u5e38\u306b\u3001\u671b\u307e\u3057\u3044\u52d5\u4f5c\u3092\u3088\u308a\u3088\u304f\u9054\u6210\u3059\u308b\u305f\u3081\u306e\u3055\u3089\u306a\u308b\u9069\u5fdc\u304b\u3089\u6069\u6075\u3092\u53d7\u3051\u308b\u3002\u3057\u304b\u3057\u3001\u3053\u306e\u3088\u3046\u306a\u30e2\u30c7\u30eb\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306f\u3001\u307e\u3059\u307e\u3059\u30ea\u30bd\u30fc\u30b9\u3092\u5fc5\u8981\u3068\u3059\u308b\u3088\u3046\u306b\u306a\u308a\u3001\u30e2\u30c7\u30eb\u306e\u91cd\u307f\u304c\u975e\u516c\u958b\u306e\u5834\u5408\u306f\u4e0d\u53ef\u80fd\u306b\u306a\u308b\u3002\u30d7\u30ed\u30ad\u30b7\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3068\u306f\u3001\u30d6\u30e9\u30c3\u30af\u30dc\u30c3\u30af\u30b9LM\u306e\u4e0a\u3067\u52d5\u4f5c\u3057\u3001\u51fa\u529b\u8a9e\u5f59\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u306e\u307f\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b\u3053\u3068\u3067\u3001\u30e2\u30c7\u30eb\u3092\u76f4\u63a5\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u7d50\u679c\u3092\u9054\u6210\u3059\u308b\u3001\u8efd\u91cf\u306a\u5fa9\u53f7\u6642\u9593\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067\u3042\u308b\u3002\u6211\u3005\u306e\u65b9\u6cd5\u306f\u3001\u3088\u308a\u5c0f\u3055\u306aLM\u3092\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u4ee3\u308f\u308a\u306b\u3001\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u305f\u5c0f\u3055\u306aLM\u3068\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u3066\u3044\u306a\u3044LM\u306e\u4e88\u6e2c\u5024\u306e\u5dee\u3092\u9069\u7528\u3057\u3001\u3088\u308a\u5927\u898f\u6a21\u306a\u4e8b\u524d\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u306e\u5229\u70b9\u3092\u4fdd\u6301\u3057\u306a\u304c\u3089\u3001\u30d9\u30fc\u30b9\u30e2\u30c7\u30eb\u306e\u5143\u306e\u4e88\u6e2c\u5024\u3092\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u65b9\u5411\u306b\u30b7\u30d5\u30c8\u3055\u305b\u308b\u3002\u5b9f\u9a13\u3067\u306f\u3001Llama2-70B\u306b\u308f\u305a\u304b7B\u30b5\u30a4\u30ba\u306e\u30d7\u30ed\u30ad\u30b7\u3092\u4f7f\u7528\u3057\u3066\u30d7\u30ed\u30ad\u30b7\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u9069\u7528\u3057\u305f\u5834\u5408\u3001\u77e5\u8b58\u3001\u63a8\u8ad6\u3001\u5b89\u5168\u6027\u306e\u5404\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3067\u8a55\u4fa1\u3057\u305f\u5834\u5408\u3001Llama2-70B\u3068\u771f\u306b\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u305f\u30c1\u30e3\u30c3\u30c8\u30d0\u30fc\u30b8\u30e7\u30f3\u3068\u306e\u9593\u306e\u30ae\u30e3\u30c3\u30d7\u306e88\uff05\u3092\u57cb\u3081\u308b\u3053\u3068\u304c\u3067\u304d\u305f\u3002\u8208\u5473\u6df1\u3044\u3053\u3068\u306b\u3001TruthfulQA\u3067\u30c6\u30b9\u30c8\u3059\u308b\u3068\u3001\u4ee3\u7406\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u305f\u30e2\u30c7...", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1750308988581822465", "indices": [150, 173], "media_key": "3_1750308988581822465", "media_results": {"result": {"media_key": "3_1750308988581822465"}}, "media_url_https": "https://pbs.twimg.com/media/GEpYwGeXwAETyRV.jpg", "original_info": {"focus_rects": [{"h": 672, "w": 1200, "x": 0, "y": 0}, {"h": 1200, "w": 1200, "x": 0, "y": 0}, {"h": 1368, "w": 1200, "x": 0, "y": 0}, {"h": 1619, "w": 810, "x": 202, "y": 0}, {"h": 1619, "w": 1200, "x": 0, "y": 0}], "height": 1619, "width": 1200}, "sizes": {"large": {"h": 1619, "resize": "fit", "w": 1200}, "medium": {"h": 1200, "resize": "fit", "w": 889}, "small": {"h": 680, "resize": "fit", "w": 504}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/MlSGycjjZh"}], "user": {"id_str": "279718877", "name": "S. Ota", "screen_name": "susumuota", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1622591377971507202/EcBLlAUc_normal.png", "description": "Summarize the top 30 most popular arXiv papers on Reddit, Hacker News and Hugging Face in the last 30 days.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "github.com/susumuota/arxi\u2026", "expanded_url": "https://github.com/susumuota/arxiv-reddit-summary", "indices": [0, 23], "url": "https://t.co/2elTmmwsNY"}]}}, "followers_count": 671, "location": "Japan", "url": "https://x.com/susumuota", "follow_url": "https://x.com/intent/follow?screen_name=susumuota"}, "url": "https://x.com/susumuota/status/1750308991735910553", "like_url": "https://x.com/intent/like?tweet_id=1750308991735910553", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750308991735910553", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1750549967599804916": {"created_at": "Thu Jan 25 16:03:30 +0000 2024", "entities": [{"indices": [0, 246], "type": "text", "text": "LMs are increasingly large\ud83d\udc18 and proprietary\ud83d\udd12 \u2014 what if we could \u201ctune\u201d\ud83d\udd27 them without accessing their internal weights?\n\nEnter: proxy-tuning, which operates on only the *outputs* of LMs at decoding-time to achieve the effect of direct tuning!\n\n\ud83d\udcc4: "}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [246, 269], "url": "https://t.co/mx2SRlyTD2", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}, {"indices": [269, 272], "type": "text", "text": " 1/"}], "favorite_count": 376, "id_str": "1750549967599804916", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/gK0eeVRrhD", "expanded_url": "https://x.com/alisawuffles/status/1750549967599804916/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1750548560289075200", "indices": [273, 296], "media_key": "3_1750548560289075200", "media_results": {"result": {"media_key": "3_1750548560289075200"}}, "media_url_https": "https://pbs.twimg.com/media/GEsypAoaEAA3t7c.png", "original_info": {"focus_rects": [{"h": 476, "w": 850, "x": 0, "y": 0}, {"h": 592, "w": 592, "x": 0, "y": 0}, {"h": 592, "w": 519, "x": 0, "y": 0}, {"h": 592, "w": 296, "x": 0, "y": 0}, {"h": 592, "w": 850, "x": 0, "y": 0}], "height": 592, "width": 850}, "sizes": {"large": {"h": 592, "resize": "fit", "w": 850}, "medium": {"h": 592, "resize": "fit", "w": 850}, "small": {"h": 474, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/gK0eeVRrhD"}], "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1750549967599804916", "like_url": "https://x.com/intent/like?tweet_id=1750549967599804916", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750549967599804916", "replies": ["1750690335192219927", "1750608839182028920"], "score": 0.2, "thread_score": 2.2, "in_thread": ["1750549967599804916", "1750549970330255818", "1750549972783882256", "1750549975552155699", "1750549977234071899", "1750549979444441293", "1750549981612884116"], "reply_count": 2, "tweet_type": "Overview", "is_author": true, "location": "author", "is_branch": true}, "1750549970330255818": {"created_at": "Thu Jan 25 16:03:31 +0000 2024", "entities": [{"indices": [0, 282], "type": "text", "text": "The \ud83d\udca1: tune a smaller open model instead (possibly available off-the-shelf), then apply the logit difference between small tuned &amp; untuned models to logits of the original model, effectively shifting them\u27a1\ufe0f in the direction of tuning while retaining benefits of larger scale! 2/"}], "favorite_count": 7, "id_str": "1750549970330255818", "in_reply_to_status_id_str": "1750549967599804916", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/phhPP2N17L", "expanded_url": "https://x.com/alisawuffles/status/1750549970330255818/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1750546930835550208", "indices": [283, 306], "media_key": "3_1750546930835550208", "media_results": {"result": {"media_key": "3_1750546930835550208"}}, "media_url_https": "https://pbs.twimg.com/media/GEsxKKcacAApnLd.png", "original_info": {"focus_rects": [{"h": 404, "w": 722, "x": 0, "y": 104}, {"h": 538, "w": 538, "x": 0, "y": 0}, {"h": 538, "w": 472, "x": 0, "y": 0}, {"h": 538, "w": 269, "x": 0, "y": 0}, {"h": 538, "w": 722, "x": 0, "y": 0}], "height": 538, "width": 722}, "sizes": {"large": {"h": 538, "resize": "fit", "w": 722}, "medium": {"h": 538, "resize": "fit", "w": 722}, "small": {"h": 507, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/phhPP2N17L"}], "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1750549970330255818", "like_url": "https://x.com/intent/like?tweet_id=1750549970330255818", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750549970330255818", "replies": [], "score": 0.2, "thread_score": 2.2, "in_thread": ["1750549967599804916", "1750549970330255818", "1750549972783882256", "1750549975552155699", "1750549977234071899", "1750549979444441293", "1750549981612884116"], "reply_count": 0, "tweet_type": "Overview", "is_author": true, "location": "abstract"}, "1750549972783882256": {"created_at": "Thu Jan 25 16:03:31 +0000 2024", "entities": [{"indices": [0, 265], "type": "text", "text": "In experiments\ud83e\uddea, we apply proxy-tuning to 1\ufe0f\u20e3instruction-tuning, 2\ufe0f\u20e3domain adaptation, and 3\ufe0f\u20e3task finetuning. For 1\ufe0f\u20e3, we find that proxy-tuning Llama-70B with proxies of 7B size (10x smaller) closes 88% of the performance gap with its truly-tuned chat version! 3/"}], "favorite_count": 6, "id_str": "1750549972783882256", "in_reply_to_status_id_str": "1750549970330255818", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/RIsSIyfQBq", "expanded_url": "https://x.com/alisawuffles/status/1750549972783882256/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": [{"h": 154, "w": 154, "x": 1121, "y": 546}, {"h": 187, "w": 187, "x": 1105, "y": 292}]}, "medium": {"faces": [{"h": 94, "w": 94, "x": 687, "y": 334}, {"h": 114, "w": 114, "x": 677, "y": 179}]}, "orig": {"faces": [{"h": 154, "w": 154, "x": 1121, "y": 546}, {"h": 187, "w": 187, "x": 1105, "y": 292}]}, "small": {"faces": [{"h": 53, "w": 53, "x": 389, "y": 189}, {"h": 65, "w": 65, "x": 384, "y": 101}]}}, "id_str": "1750547726935457792", "indices": [266, 289], "media_key": "3_1750547726935457792", "media_results": {"result": {"media_key": "3_1750547726935457792"}}, "media_url_https": "https://pbs.twimg.com/media/GEsx4gJbAAA-Ymx.png", "original_info": {"focus_rects": [{"h": 1095, "w": 1956, "x": 0, "y": 0}, {"h": 1228, "w": 1228, "x": 728, "y": 0}, {"h": 1228, "w": 1077, "x": 879, "y": 0}, {"h": 1228, "w": 614, "x": 1342, "y": 0}, {"h": 1228, "w": 1956, "x": 0, "y": 0}], "height": 1228, "width": 1956}, "sizes": {"large": {"h": 1228, "resize": "fit", "w": 1956}, "medium": {"h": 753, "resize": "fit", "w": 1200}, "small": {"h": 427, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/RIsSIyfQBq"}], "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1750549972783882256", "like_url": "https://x.com/intent/like?tweet_id=1750549972783882256", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750549972783882256", "replies": [], "score": 0.30000000000000004, "thread_score": 0.30000000000000004, "in_thread": ["1750549967599804916", "1750549970330255818", "1750549972783882256", "1750549975552155699", "1750549977234071899", "1750549979444441293", "1750549981612884116"], "reply_count": 0, "tweet_type": "Overview", "is_author": true, "location": "introduction", "is_branch": true}, "1750549975552155699": {"created_at": "Thu Jan 25 16:03:32 +0000 2024", "entities": [{"indices": [0, 277], "type": "text", "text": "In fact, proxy-instruction-tuned models are *more truthful* than directly-tuned models on TruthfulQA, suggesting decoding-time tuning may better preserve learned knowledge\ud83e\udd2f. Here we also analyze which tokens proxy-tuning influences most, finding they are mostly stylistic\ud83d\udd8c\ufe0f. 4/"}], "favorite_count": 9, "id_str": "1750549975552155699", "in_reply_to_status_id_str": "1750549972783882256", "lang": "en", "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1750549975552155699", "like_url": "https://x.com/intent/like?tweet_id=1750549975552155699", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750549975552155699", "replies": [], "score": 0.6000000000000001, "thread_score": 0.4, "in_thread": ["1750549967599804916", "1750549970330255818", "1750549972783882256", "1750549975552155699", "1750549977234071899", "1750549979444441293", "1750549981612884116"], "reply_count": 0, "tweet_type": "Overview", "is_author": true, "location": "on", "is_branch": true}, "1750549977234071899": {"created_at": "Thu Jan 25 16:03:32 +0000 2024", "entities": [{"indices": [0, 220], "type": "text", "text": "Proxy-tuning is actually an application of our earlier work DExperts (2021), where the small tuned model acts as an expert\ud83d\ude07 and the small untuned model an anti-expert\ud83d\ude08. We were super excited to see this work for tuning! "}, {"display_url": "aclanthology.org/2021.acl-long.\u2026", "expanded_url": "https://aclanthology.org/2021.acl-long.522", "indices": [220, 243], "url": "https://t.co/zcbVxDJLIo", "type": "url", "href": "https://aclanthology.org/2021.acl-long.522", "text": "aclanthology.org/2021.acl-long.\u2026"}, {"indices": [243, 246], "type": "text", "text": " 5/"}], "favorite_count": 9, "id_str": "1750549977234071899", "in_reply_to_status_id_str": "1750549975552155699", "lang": "en", "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1750549977234071899", "like_url": "https://x.com/intent/like?tweet_id=1750549977234071899", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750549977234071899", "replies": [], "score": 0.4, "thread_score": 0.4, "in_thread": ["1750549967599804916", "1750549970330255818", "1750549972783882256", "1750549975552155699", "1750549977234071899", "1750549979444441293", "1750549981612884116"], "reply_count": 0, "tweet_type": "Overview", "is_author": true, "location": "related work", "is_branch": true}, "1750549979444441293": {"created_at": "Thu Jan 25 16:03:33 +0000 2024", "entities": [{"indices": [0, 97], "type": "text", "text": "We weren\u2019t the only ones with this idea \u2014 \ud83d\udd0d check out the concurrent &amp; independent work from "}, {"id_str": "942749627627065344", "indices": [97, 112], "name": "Eric", "screen_name": "ericmitchellai", "type": "mention", "href": "https://x.com/ericmitchellai", "text": "@ericmitchellai"}, {"indices": [112, 245], "type": "text", "text": " et al. Their focus was on using the same equation to analyze the effects of independently scaling up pretraining versus finetuning. "}, {"display_url": "arxiv.org/abs/2310.12962", "expanded_url": "https://arxiv.org/abs/2310.12962", "indices": [245, 268], "url": "https://t.co/og3AMlIgIE", "type": "url", "href": "https://arxiv.org/abs/2310.12962", "text": "arxiv.org/abs/2310.12962"}, {"indices": [268, 271], "type": "text", "text": " 6/"}], "favorite_count": 11, "id_str": "1750549979444441293", "in_reply_to_status_id_str": "1750549977234071899", "lang": "en", "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1750549979444441293", "like_url": "https://x.com/intent/like?tweet_id=1750549979444441293", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750549979444441293", "replies": [], "score": 0.4, "thread_score": 0.4, "in_thread": ["1750549967599804916", "1750549970330255818", "1750549972783882256", "1750549975552155699", "1750549977234071899", "1750549979444441293", "1750549981612884116"], "reply_count": 0, "tweet_type": "Overview", "is_author": true, "location": "conclusion", "is_branch": true}, "1750549981612884116": {"created_at": "Thu Jan 25 16:03:33 +0000 2024", "entities": [{"indices": [0, 148], "type": "text", "text": "We hope our work shows the promise of customizing large, potentially proprietary LMs through decoding-time guidance! Co-authored with the wonderful "}, {"id_str": "4916685123", "indices": [148, 162], "name": "Xiaochuang Han", "screen_name": "XiaochuangHan", "type": "mention", "href": "https://x.com/XiaochuangHan", "text": "@XiaochuangHan"}, {"indices": [162, 163], "type": "text", "text": " "}, {"id_str": "3129176335", "indices": [163, 174], "name": "Yizhong Wang", "screen_name": "yizhongwyz", "type": "mention", "href": "https://x.com/yizhongwyz", "text": "@yizhongwyz"}, {"indices": [174, 190], "type": "text", "text": " Yulia Tsvetkov "}, {"id_str": "893882282175471616", "indices": [190, 203], "name": "Yejin Choi", "screen_name": "YejinChoinka", "type": "mention", "href": "https://x.com/YejinChoinka", "text": "@YejinChoinka"}, {"indices": [203, 204], "type": "text", "text": " "}, {"id_str": "158789494", "indices": [204, 212], "name": "Noah A. Smith", "screen_name": "nlpnoah", "type": "mention", "href": "https://x.com/nlpnoah", "text": "@nlpnoah"}, {"indices": [212, 233], "type": "text", "text": " \ud83d\udc9b\n\nFind our code at "}, {"display_url": "github.com/alisawuffles/p\u2026", "expanded_url": "https://github.com/alisawuffles/proxy-tuning", "indices": [233, 256], "url": "https://t.co/TfVtCeeg5c", "type": "url", "href": "https://github.com/alisawuffles/proxy-tuning", "text": "github.com/alisawuffles/p\u2026"}, {"indices": [256, 260], "type": "text", "text": " 7/7"}], "favorite_count": 9, "id_str": "1750549981612884116", "in_reply_to_status_id_str": "1750549979444441293", "lang": "en", "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1750549981612884116", "like_url": "https://x.com/intent/like?tweet_id=1750549981612884116", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750549981612884116", "replies": [], "score": 0.2, "thread_score": 0.2, "in_thread": ["1750549967599804916", "1750549970330255818", "1750549972783882256", "1750549975552155699", "1750549977234071899", "1750549979444441293", "1750549981612884116"], "reply_count": 0, "tweet_type": "Overview", "is_author": true, "location": "author", "is_branch": true}, "1750608839182028920": {"created_at": "Thu Jan 25 19:57:26 +0000 2024", "entities": [{"indices": [14, 230], "type": "text", "text": "Looks interesting, will definitely try it out! Does it also work for chain of thought prompting where the 3 models can potentially have different outputs and hence, arithmetic operations on logits might not be valid?"}], "favorite_count": 0, "id_str": "1750608839182028920", "in_reply_to_status_id_str": "1750549967599804916", "lang": "en", "user": {"id_str": "1529802792864731138", "name": "Sourabh Agrawal", "screen_name": "SourabhAgr03", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1543129025341964288/p5c-UKFP_normal.jpg", "description": "Founder of @UpTrainAI (@ycombinator W23) || Open-source LLM Evaluations\n\nhttps://t.co/nRmptEjg6E\n\n2x founder, Prev. @GoldmanSachs, @IITBombay", "entities": {"description": {"urls": [{"display_url": "github.com/uptrain-ai/upt\u2026", "expanded_url": "https://github.com/uptrain-ai/uptrain", "indices": [73, 96], "url": "https://t.co/nRmptEjg6E"}]}, "url": {"urls": [{"display_url": "uptrain.ai", "expanded_url": "https://uptrain.ai/", "indices": [0, 23], "url": "https://t.co/WjEpv7hyj7"}]}}, "followers_count": 649, "location": "San Francisco", "url": "https://x.com/SourabhAgr03", "follow_url": "https://x.com/intent/follow?screen_name=SourabhAgr03"}, "url": "https://x.com/SourabhAgr03/status/1750608839182028920", "like_url": "https://x.com/intent/like?tweet_id=1750608839182028920", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750608839182028920", "replies": [], "score": 0.4, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Q&A", "location": "method", "is_branch": true}, "1750690335192219927": {"created_at": "Fri Jan 26 01:21:16 +0000 2024", "entities": [{"indices": [14, 118], "type": "text", "text": "Oh I see. This is similar to creating a \"me\" model which is translates between my prompts and other LLMs"}], "favorite_count": 0, "id_str": "1750690335192219927", "in_reply_to_status_id_str": "1750549967599804916", "lang": "en", "user": {"id_str": "2964539431", "name": "Karl Smith", "screen_name": "karlbykarlsmith", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1280320583046180864/1dv1ODoF_normal.jpg", "description": "MB Archives https://t.co/NwFxSqWHrc || Opinion my own || Still just that same age-old problem: how does one get from three to four?", "entities": {"description": {"urls": [{"display_url": "modeledbehavior.wordpress.com", "expanded_url": "http://modeledbehavior.wordpress.com", "indices": [12, 35], "url": "https://t.co/NwFxSqWHrc"}]}}, "followers_count": 13766, "location": "Washington, DC", "url": "https://x.com/karlbykarlsmith", "follow_url": "https://x.com/intent/follow?screen_name=karlbykarlsmith"}, "url": "https://x.com/karlbykarlsmith/status/1750690335192219927", "like_url": "https://x.com/intent/like?tweet_id=1750690335192219927", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750690335192219927", "replies": [], "score": 0.3, "thread_score": 0.3, "reply_count": 0, "is_branch": true}, "1750733596619632662": {"created_at": "Fri Jan 26 04:13:11 +0000 2024", "entities": [{"indices": [0, 42], "type": "text", "text": "\u6559\u3048\u3066\u3082\u3089\u3063\u305f\u8ad6\u6587\nTuning Language Models by Proxy\n"}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [42, 65], "url": "https://t.co/7nNWJ3Vn1Z", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}, {"indices": [65, 110], "type": "text", "text": "\n\n\u5c0f\u898f\u6a21\u30e2\u30c7\u30eb\u306e\u8a13\u7df4\u7d50\u679c\u3092\u5927\u898f\u6a21\u306b\u8ee2\u5199\u3059\u308b\u611f\u3058\u3067\u3057\u3087\u3046\u304b\uff61 \u306a\u3093\u304b\u3059\u3054\u305d\u3046\u3067\u3059\uff61 \u8981\u52c9\u5f37"}], "favorite_count": 1, "id_str": "1750733596619632662", "lang": "ja", "mediaDetails": [{"display_url": "pic.x.com/0YjbmFMERm", "expanded_url": "https://x.com/kanhatakeyama/status/1750733596619632662/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1750733433347969024", "indices": [111, 134], "media_key": "3_1750733433347969024", "media_results": {"result": {"media_key": "3_1750733433347969024"}}, "media_url_https": "https://pbs.twimg.com/media/GEvayCcbEAABD9q.png", "original_info": {"focus_rects": [{"h": 449, "w": 801, "x": 0, "y": 236}, {"h": 697, "w": 697, "x": 0, "y": 0}, {"h": 697, "w": 611, "x": 0, "y": 0}, {"h": 697, "w": 349, "x": 0, "y": 0}, {"h": 697, "w": 801, "x": 0, "y": 0}], "height": 697, "width": 801}, "sizes": {"large": {"h": 697, "resize": "fit", "w": 801}, "medium": {"h": 697, "resize": "fit", "w": 801}, "small": {"h": 592, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/0YjbmFMERm"}], "user": {"id_str": "1639772416816873473", "name": "\u7560\u5c71\u3000\u6b53\u3000Kan Hatakeyama", "screen_name": "kanhatakeyama", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1639773968319262721/Q2gCyYfx_normal.jpg", "description": "\u535a\u58eb(\u5de5\u5b66)\u30fbAI\u3068\u30ed\u30dc\u30c3\u30c8\u304c\u5316\u5b66\u7814\u7a76\u3059\u308b\u305f\u3081\u306e\u304a\u624b\u4f1d\u3044\u3092\u3059\u308b\u306e\u304c\u30de\u30a4\u30d6\u30fc\u30e0\u3067\u3059\u3002\nai\u30fb\u79d1\u5b66\u30fb\u30ed\u30dc\u30c3\u30c8\u7cfb\u306ediscord\u304c\u52d5\u3044\u3066\u3044\u307e\u3059", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "discord.gg/uxCquwV4n4", "expanded_url": "https://discord.gg/uxCquwV4n4", "indices": [0, 23], "url": "https://t.co/9LGkzlBiWQ"}]}}, "followers_count": 2253, "location": "\u6771\u4eac", "url": "https://x.com/kanhatakeyama", "follow_url": "https://x.com/intent/follow?screen_name=kanhatakeyama"}, "url": "https://x.com/kanhatakeyama/status/1750733596619632662", "like_url": "https://x.com/intent/like?tweet_id=1750733596619632662", "reply_url": "https://x.com/intent/tweet?in_reply_to=1750733596619632662", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1751000610030117013": {"created_at": "Fri Jan 26 21:54:12 +0000 2024", "entities": [{"indices": [0, 92], "type": "text", "text": "Una forma eficiente de hacer finetuning de modelos grandes LLM usando sus \"hermanos chicos\" "}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [92, 115], "url": "https://t.co/cZuP8ANz6k", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}], "favorite_count": 0, "id_str": "1751000610030117013", "lang": "es", "user": {"id_str": "87851587", "name": "Max Kreimerman", "screen_name": "maxkreimerman", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1496790067037224962/Uk2WYBMa_normal.jpg", "description": "Computin, Empresario, Techie, sediento de conocimiento, aficionado a la econom\u00eda, la politica,la ciencia, la comida y la vida.", "entities": {"description": {"urls": []}}, "followers_count": 500, "location": "", "url": "https://x.com/maxkreimerman", "follow_url": "https://x.com/intent/follow?screen_name=maxkreimerman"}, "url": "https://x.com/maxkreimerman/status/1751000610030117013", "like_url": "https://x.com/intent/like?tweet_id=1751000610030117013", "reply_url": "https://x.com/intent/tweet?in_reply_to=1751000610030117013", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1751304868097143100": {"created_at": "Sat Jan 27 18:03:12 +0000 2024", "entities": [{"indices": [0, 148], "type": "text", "text": "Proxy tuning: Do fine-tuning on a small model. Then add the fine-tuning-induced logit changes directly onto a larger base model without fine-tuning."}], "favorite_count": 2, "id_str": "1751304868097143100", "quoted_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "20451961", "name": "Shanqing Cai", "screen_name": "sqcai", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1653770032009162756/0T28W0u__normal.jpg", "description": "Software Engineer @Google. Tweets about AI, speech science, & neuroscience.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "caisq.github.io", "expanded_url": "https://caisq.github.io/", "indices": [0, 23], "url": "https://t.co/C2EJF2tGYh"}]}}, "followers_count": 2881, "location": "Cambridge, MA", "url": "https://x.com/sqcai", "follow_url": "https://x.com/intent/follow?screen_name=sqcai"}, "url": "https://x.com/sqcai/status/1751304868097143100", "like_url": "https://x.com/intent/like?tweet_id=1751304868097143100", "reply_url": "https://x.com/intent/tweet?in_reply_to=1751304868097143100", "replies": [], "score": 0, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Teaser", "is_branch": true}, "1751462713300226306": {"created_at": "Sun Jan 28 04:30:26 +0000 2024", "entities": [{"indices": [23, 43], "type": "text", "text": "any recommendations?"}], "favorite_count": 0, "id_str": "1751462713300226306", "in_reply_to_status_id_str": "1749380148443427013", "lang": "en", "user": {"id_str": "1601959303560454144", "name": "Peyton", "screen_name": "dongpeyton98", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1795343582444068864/nbl_8gep_normal.jpg", "description": "Sometimes you gotta make a change to make a change.", "entities": {"description": {"urls": []}}, "followers_count": 63, "location": "", "url": "https://x.com/dongpeyton98", "follow_url": "https://x.com/intent/follow?screen_name=dongpeyton98"}, "url": "https://x.com/dongpeyton98/status/1751462713300226306", "like_url": "https://x.com/intent/like?tweet_id=1751462713300226306", "reply_url": "https://x.com/intent/tweet?in_reply_to=1751462713300226306", "replies": [], "score": 0.1, "thread_score": 0, "reply_count": 0}, "1751960496226336938": {"created_at": "Mon Jan 29 13:28:26 +0000 2024", "entities": [{"indices": [0, 7], "type": "text", "text": "Tuning "}, {"indices": [7, 11], "text": "#LLM", "type": "hashtag", "href": "https://x.com/hashtag/LLM"}, {"indices": [11, 23], "type": "text", "text": "'s by proxy "}, {"display_url": "arxiv.org/pdf/2401.08565\u2026", "expanded_url": "https://arxiv.org/pdf/2401.08565.pdf", "indices": [23, 46], "url": "https://t.co/N521VrPUl3", "type": "url", "href": "https://arxiv.org/pdf/2401.08565.pdf", "text": "arxiv.org/pdf/2401.08565\u2026"}, {"indices": [46, 49], "type": "text", "text": ". \n"}, {"indices": [49, 55], "text": "#Proxy", "type": "hashtag", "href": "https://x.com/hashtag/Proxy"}, {"indices": [55, 209], "type": "text", "text": "-tuning involves training a smaller LM, and then applying the difference between its tuned and untuned predictions to adjust the base model's predictions."}], "favorite_count": 0, "id_str": "1751960496226336938", "lang": "en", "user": {"id_str": "756533013010341889", "name": "ozgurguler", "screen_name": "ozgurgulerx", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1888512204011429888/tzMPwdHW_normal.jpg", "description": "AI & Startups #Ataturk #komorebi", "entities": {"description": {"urls": []}}, "followers_count": 434, "location": "Istanbul, Turkey", "url": "https://x.com/ozgurgulerx", "follow_url": "https://x.com/intent/follow?screen_name=ozgurgulerx"}, "url": "https://x.com/ozgurgulerx/status/1751960496226336938", "like_url": "https://x.com/intent/like?tweet_id=1751960496226336938", "reply_url": "https://x.com/intent/tweet?in_reply_to=1751960496226336938", "replies": [], "score": 0, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Teaser", "is_branch": true}, "1752349456421261335": {"created_at": "Tue Jan 30 15:14:02 +0000 2024", "entities": [{"indices": [0, 204], "type": "text", "text": "Proxy-tuning is a way to adapt LLMs without changing the model's weights. \nFollowing up on the proxy-tuning paper discussion from last week, I implemented it in code and gave it a try. It actually works: "}, {"display_url": "lightning.ai/lightning-ai/s\u2026", "expanded_url": "https://lightning.ai/lightning-ai/studios/improve-llms-with-proxy-tuning?view=public", "indices": [204, 227], "url": "https://t.co/WLxmEvoXo8", "type": "url", "href": "https://lightning.ai/lightning-ai/studios/improve-llms-with-proxy-tuning?view=public", "text": "lightning.ai/lightning-ai/s\u2026"}, {"indices": [227, 1269], "type": "text", "text": "\n\nIn a nutshell, the method is like this:\n\n1. Select a base LLM (e.g., an untuned 7B Llama 2 model) smaller and cheaper than the target LLM (e.g., a 10x larger, untuned 70B Llama 2 model).\n\n2. Finetune this smaller base LLM to obtain a small finetuned LLM (e.g., instruction-finetune a 7B Llama 2 model to get a finetuned 7B model).\n\n3. Compute the output difference between the base model (step 1) and the tuned model (step 2).\n\n4. Add this difference in outputs to the target LLM's outputs.\n\n5. Normalize the modified outputs from step 4, and then generate the answer.\n\nI tried the following query:\n\n\"If I have 5 apples and eat 2, but then find 3 more on my way home, how many do I have?\"\n\nThe proxy-tuned model was indeed able to answer correctly, whereas the base models failed: \"You start with 5 apples and eat 2, so you have 5 - 2 = 3 apples left. Then, you find 3 more apples on your way home, so you have 3 + 3 = 6 apples in total.\"\n\nUsing the same approach, it was also possible to give Llama 2 13B coding abilities via CodeLlama 7B."}], "favorite_count": 802, "id_str": "1752349456421261335", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1752349456421261335", "like_url": "https://x.com/intent/like?tweet_id=1752349456421261335", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752349456421261335", "replies": ["1752616549347954814", "1752368665704411276", "1752474511025553888", "1752931701159076021", "1752360528696242581", "1752401263713792164", "1752536610032492762", "1752397854478389398", "1752930902374580430", "1753173434366861712"], "score": 0, "thread_score": 0.4, "in_thread": ["1752349456421261335", "1752359475430760577"], "reply_count": 25, "tweet_type": "Resource", "location": "author", "is_branch": true}, "1752349699892211906": {"created_at": "Tue Jan 30 15:15:00 +0000 2024", "entities": [{"indices": [0, 50], "type": "text", "text": "Here\u2019s the link to the relevant paper discussion: "}, {"display_url": "x.com/rasbt/status/1\u2026", "expanded_url": "https://x.com/rasbt/status/1748021765790376385?s=20", "indices": [50, 73], "url": "https://t.co/NONGR19r0N", "type": "url", "href": "https://x.com/rasbt/status/1748021765790376385?s=20", "text": "x.com/rasbt/status/1\u2026"}], "favorite_count": 30, "id_str": "1752349699892211906", "quoted_status_id_str": "1748021765790376385", "in_reply_to_status_id_str": "1752349456421261335", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1752349699892211906", "like_url": "https://x.com/intent/like?tweet_id=1752349699892211906", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752349699892211906", "replies": [], "score": 0, "thread_score": 2, "in_thread": ["1752349456421261335", "1752349699892211906"], "reply_count": 0, "tweet_type": "Overview", "location": null}, "1752359475430760577": {"created_at": "Tue Jan 30 15:53:50 +0000 2024", "entities": [{"indices": [0, 431], "type": "text", "text": "It would be nice if we could avoid constantly running the smaller models by maintaining a delta tensor, which could then be applied to the larger untuned model.\nHowever, I checked the deltas and they are not constant. In the plot attached below I computed the mean and variance over ~4000 input tokens. Then, I plotted the variance and mean for the first 50 tokens in the 32k vocabulary. As one can see, the variance is quite high."}], "favorite_count": 11, "id_str": "1752359475430760577", "in_reply_to_status_id_str": "1752349456421261335", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/t4B9XzuoST", "expanded_url": "https://x.com/rasbt/status/1752359475430760577/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1752359211713880065", "indices": [279, 302], "media_key": "3_1752359211713880065", "media_results": {"result": {"media_key": "3_1752359211713880065"}}, "media_url_https": "https://pbs.twimg.com/media/GFGhay0W4AE64Kz.png", "original_info": {"focus_rects": [{"h": 357, "w": 638, "x": 82, "y": 0}, {"h": 357, "w": 357, "x": 271, "y": 0}, {"h": 357, "w": 313, "x": 293, "y": 0}, {"h": 357, "w": 179, "x": 360, "y": 0}, {"h": 357, "w": 720, "x": 0, "y": 0}], "height": 357, "width": 720}, "sizes": {"large": {"h": 357, "resize": "fit", "w": 720}, "medium": {"h": 357, "resize": "fit", "w": 720}, "small": {"h": 337, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/t4B9XzuoST"}], "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1752359475430760577", "like_url": "https://x.com/intent/like?tweet_id=1752359475430760577", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752359475430760577", "replies": [], "score": 0, "thread_score": 2, "in_thread": ["1752349456421261335", "1752359475430760577"], "reply_count": 0, "tweet_type": "Overview", "location": "method"}, "1752360528696242581": {"created_at": "Tue Jan 30 15:58:01 +0000 2024", "entities": [{"indices": [7, 120], "type": "text", "text": "Will be reading this next once I compete Jeremy Howard\u2019s CUDA for python devs \ud83d\udd25 \n\nThanks for sharing Sebastian! \ud83d\ude4f"}], "favorite_count": 3, "id_str": "1752360528696242581", "in_reply_to_status_id_str": "1752349456421261335", "lang": "en", "user": {"id_str": "703601972", "name": "Akshay \ud83d\ude80", "screen_name": "akshay_pachaar", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1578327351544360960/YFpWSWIX_normal.jpg", "description": "Simplifying LLMs, AI Agents, RAGs and Machine Learning for you! \u2022 Co-founder @dailydoseofds_\u2022 BITS Pilani \u2022 3 Patents \u2022 ex-AI Engineer @ LightningAI", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "join.dailydoseofds.com", "expanded_url": "http://join.dailydoseofds.com", "indices": [0, 23], "url": "https://t.co/TLsKA1fohN"}]}}, "followers_count": 189790, "location": "Learn AI Engineering \ud83d\udc49", "url": "https://x.com/akshay_pachaar", "follow_url": "https://x.com/intent/follow?screen_name=akshay_pachaar"}, "url": "https://x.com/akshay_pachaar/status/1752360528696242581", "like_url": "https://x.com/intent/like?tweet_id=1752360528696242581", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752360528696242581", "replies": [], "score": 0.0, "thread_score": 0.0, "reply_count": 0, "is_branch": true}, "1752368665704411276": {"created_at": "Tue Jan 30 16:30:21 +0000 2024", "entities": [{"indices": [7, 279], "type": "text", "text": "So step 3 is basically vector subtraction between the logits of the finetuned small model and the logits of the same small model before fineuning?\n\nWe then do vector addition between this delta and the logits of the big model.\n\nAnd this delta is different for every input?"}], "favorite_count": 3, "id_str": "1752368665704411276", "in_reply_to_status_id_str": "1752349456421261335", "lang": "en", "user": {"id_str": "954123758", "name": "Amgad Hasan", "screen_name": "AmgadGamalHasan", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1719448114816225280/QNIg0Knr_normal.jpg", "description": "A machine learning engineer specializing in LLMs and ASR models", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "substack.com/@amgadhasan", "expanded_url": "https://substack.com/@amgadhasan", "indices": [0, 23], "url": "https://t.co/WcmgSn7xni"}]}}, "followers_count": 256, "location": "", "url": "https://x.com/AmgadGamalHasan", "follow_url": "https://x.com/intent/follow?screen_name=AmgadGamalHasan"}, "url": "https://x.com/AmgadGamalHasan/status/1752368665704411276", "like_url": "https://x.com/intent/like?tweet_id=1752368665704411276", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752368665704411276", "replies": ["1752370095198711887"], "score": 0.4, "thread_score": 0.4, "reply_count": 9, "tweet_type": "Q&A", "location": "method", "is_branch": true}, "1752370095198711887": {"created_at": "Tue Jan 30 16:36:02 +0000 2024", "entities": [{"indices": [17, 68], "type": "text", "text": "Yes, to use the code example from my article above."}], "favorite_count": 5, "id_str": "1752370095198711887", "in_reply_to_status_id_str": "1752368665704411276", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/IwfHBzsl8Z", "expanded_url": "https://x.com/rasbt/status/1752370095198711887/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1752370055256424448", "indices": [69, 92], "media_key": "3_1752370055256424448", "media_results": {"result": {"media_key": "3_1752370055256424448"}}, "media_url_https": "https://pbs.twimg.com/media/GFGrR-KXQAAxdsp.jpg", "original_info": {"focus_rects": [{"h": 956, "w": 1708, "x": 0, "y": 80}, {"h": 1036, "w": 1036, "x": 122, "y": 0}, {"h": 1036, "w": 909, "x": 186, "y": 0}, {"h": 1036, "w": 518, "x": 381, "y": 0}, {"h": 1036, "w": 1708, "x": 0, "y": 0}], "height": 1036, "width": 1708}, "sizes": {"large": {"h": 1036, "resize": "fit", "w": 1708}, "medium": {"h": 728, "resize": "fit", "w": 1200}, "small": {"h": 412, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/IwfHBzsl8Z"}], "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1752370095198711887", "like_url": "https://x.com/intent/like?tweet_id=1752370095198711887", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752370095198711887", "replies": ["1752370320986484844", "1753245478886539544", "1752372467106984252"], "score": 0.2, "thread_score": 0, "reply_count": 8}, "1752370320986484844": {"created_at": "Tue Jan 30 16:36:56 +0000 2024", "entities": [{"indices": [17, 176], "type": "text", "text": "And yes, good question, the deltas are different because self-attention is dynamic wrt to the inputs. I plotted the mean and variance of 4000 token-deltas here"}], "favorite_count": 2, "id_str": "1752370320986484844", "in_reply_to_status_id_str": "1752370095198711887", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/hr1nwY48QS", "expanded_url": "https://x.com/rasbt/status/1752370320986484844/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1752370255500918784", "indices": [177, 200], "media_key": "3_1752370255500918784", "media_results": {"result": {"media_key": "3_1752370255500918784"}}, "media_url_https": "https://pbs.twimg.com/media/GFGrdoIXwAAkk9S.png", "original_info": {"focus_rects": [{"h": 357, "w": 638, "x": 82, "y": 0}, {"h": 357, "w": 357, "x": 271, "y": 0}, {"h": 357, "w": 313, "x": 293, "y": 0}, {"h": 357, "w": 179, "x": 360, "y": 0}, {"h": 357, "w": 720, "x": 0, "y": 0}], "height": 357, "width": 720}, "sizes": {"large": {"h": 357, "resize": "fit", "w": 720}, "medium": {"h": 357, "resize": "fit", "w": 720}, "small": {"h": 337, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/hr1nwY48QS"}], "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1752370320986484844", "like_url": "https://x.com/intent/like?tweet_id=1752370320986484844", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752370320986484844", "replies": ["1752373304218759426"], "score": 0.4, "thread_score": 0, "reply_count": 4}, "1752372467106984252": {"created_at": "Tue Jan 30 16:45:28 +0000 2024", "entities": [{"indices": [7, 40], "type": "text", "text": "Thanks! The code made it clearer."}], "favorite_count": 0, "id_str": "1752372467106984252", "in_reply_to_status_id_str": "1752370095198711887", "lang": "en", "user": {"id_str": "954123758", "name": "Amgad Hasan", "screen_name": "AmgadGamalHasan", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1719448114816225280/QNIg0Knr_normal.jpg", "description": "A machine learning engineer specializing in LLMs and ASR models", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "substack.com/@amgadhasan", "expanded_url": "https://substack.com/@amgadhasan", "indices": [0, 23], "url": "https://t.co/WcmgSn7xni"}]}}, "followers_count": 256, "location": "", "url": "https://x.com/AmgadGamalHasan", "follow_url": "https://x.com/intent/follow?screen_name=AmgadGamalHasan"}, "url": "https://x.com/AmgadGamalHasan/status/1752372467106984252", "like_url": "https://x.com/intent/like?tweet_id=1752372467106984252", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752372467106984252", "replies": [], "score": 0.1, "thread_score": 0, "reply_count": 0}, "1752373304218759426": {"created_at": "Tue Jan 30 16:48:47 +0000 2024", "entities": [{"indices": [7, 257], "type": "text", "text": "Hmm. So it's not so much of a \"free\" win since we need to get predictions from 3 models. Interesting. I think there's an analogy here with speculative decoding but we use the small model to improve the big model's output quality instead of its speed."}], "favorite_count": 2, "id_str": "1752373304218759426", "in_reply_to_status_id_str": "1752370320986484844", "lang": "en", "user": {"id_str": "954123758", "name": "Amgad Hasan", "screen_name": "AmgadGamalHasan", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1719448114816225280/QNIg0Knr_normal.jpg", "description": "A machine learning engineer specializing in LLMs and ASR models", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "substack.com/@amgadhasan", "expanded_url": "https://substack.com/@amgadhasan", "indices": [0, 23], "url": "https://t.co/WcmgSn7xni"}]}}, "followers_count": 256, "location": "", "url": "https://x.com/AmgadGamalHasan", "follow_url": "https://x.com/intent/follow?screen_name=AmgadGamalHasan"}, "url": "https://x.com/AmgadGamalHasan/status/1752373304218759426", "like_url": "https://x.com/intent/like?tweet_id=1752373304218759426", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752373304218759426", "replies": ["1752373608586817927"], "score": 0.4, "thread_score": 0, "reply_count": 3}, "1752373608586817927": {"created_at": "Tue Jan 30 16:50:00 +0000 2024", "entities": [{"indices": [17, 165], "type": "text", "text": "Yeah, it's a good method for improving the quality of a model but you definitely trade it off with speed. Unless you can run the models in parallel."}], "favorite_count": 2, "id_str": "1752373608586817927", "in_reply_to_status_id_str": "1752373304218759426", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1752373608586817927", "like_url": "https://x.com/intent/like?tweet_id=1752373608586817927", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752373608586817927", "replies": ["1752374277171458498"], "score": 0.2, "thread_score": 0, "reply_count": 2}, "1752374277171458498": {"created_at": "Tue Jan 30 16:52:39 +0000 2024", "entities": [{"indices": [7, 192], "type": "text", "text": "The main question is does it work with entirely different models that have the same vocab?\nFor example if there's a source available 7B model out there that has the same vocab as gpt-4."}], "favorite_count": 3, "id_str": "1752374277171458498", "in_reply_to_status_id_str": "1752373608586817927", "lang": "en", "user": {"id_str": "954123758", "name": "Amgad Hasan", "screen_name": "AmgadGamalHasan", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1719448114816225280/QNIg0Knr_normal.jpg", "description": "A machine learning engineer specializing in LLMs and ASR models", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "substack.com/@amgadhasan", "expanded_url": "https://substack.com/@amgadhasan", "indices": [0, 23], "url": "https://t.co/WcmgSn7xni"}]}}, "followers_count": 256, "location": "", "url": "https://x.com/AmgadGamalHasan", "follow_url": "https://x.com/intent/follow?screen_name=AmgadGamalHasan"}, "url": "https://x.com/AmgadGamalHasan/status/1752374277171458498", "like_url": "https://x.com/intent/like?tweet_id=1752374277171458498", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752374277171458498", "replies": ["1752376007250555380"], "score": 0.3, "thread_score": 0, "reply_count": 1}, "1752376007250555380": {"created_at": "Tue Jan 30 16:59:32 +0000 2024", "entities": [{"indices": [0, 360], "type": "text", "text": "I'd like to know the answer to that as well :). You could give it a try by swapping \n\nmodel_names = [\n    \"meta-llama/Llama-2-7b-hf\",\n    \"meta-llama/Llama-2-7b-chat-hf\",\n    \"meta-llama/Llama-2-13b-hf\",\n]\n\nwith \n\nmodel_names = [\n    \"meta-llama/Llama-2-7b-hf\",\n    \"kittn/mistral-7B-v0.1-hf\",\n    \"meta-llama/Llama-2-13b-hf\",\n]\n\nin the code above for example."}], "favorite_count": 3, "id_str": "1752376007250555380", "in_reply_to_status_id_str": "1752374277171458498", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1752376007250555380", "like_url": "https://x.com/intent/like?tweet_id=1752376007250555380", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752376007250555380", "replies": [], "score": 0.3, "thread_score": 0, "reply_count": 0}, "1752397854478389398": {"created_at": "Tue Jan 30 18:26:21 +0000 2024", "entities": [{"indices": [7, 143], "type": "text", "text": "Nice work! This opens up the possibility to have a 70B based MoE by added additional Small Tuned LLMs to the mix with a routing layer..."}], "favorite_count": 0, "id_str": "1752397854478389398", "in_reply_to_status_id_str": "1752349456421261335", "lang": "en", "user": {"id_str": "2784765784", "name": "Sense", "screen_name": "WitCelebs", "profile_image_url_https": "https://pbs.twimg.com/profile_images/515667036735684608/-Sk8oKxW_normal.jpeg", "description": "Busy getting rich. IQ on diff, Ekko main, and AI hobbies, bullion dealer, currency trader. Christian", "entities": {"description": {"urls": []}}, "followers_count": 89, "location": "Dallas", "url": "https://x.com/WitCelebs", "follow_url": "https://x.com/intent/follow?screen_name=WitCelebs"}, "url": "https://x.com/WitCelebs/status/1752397854478389398", "like_url": "https://x.com/intent/like?tweet_id=1752397854478389398", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752397854478389398", "replies": [], "score": 0.2, "thread_score": 0.2, "reply_count": 0, "is_branch": true}, "1752401263713792164": {"created_at": "Tue Jan 30 18:39:53 +0000 2024", "entities": [{"indices": [7, 102], "type": "text", "text": "I think this is the method which byte dance used to copy openai models and make them efficient."}], "favorite_count": 2, "id_str": "1752401263713792164", "in_reply_to_status_id_str": "1752349456421261335", "lang": "en", "user": {"id_str": "1298552278308122625", "name": "Dhruv Sahu", "screen_name": "DhruvSahu98", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1463005756312088578/JXnOIv_K_normal.jpg", "description": "Analysis on #Economics and #Tech implementation l\n\nBS@iitmadras", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "dhruvsahu98.github.io", "expanded_url": "https://dhruvsahu98.github.io/", "indices": [0, 23], "url": "https://t.co/0Ghi4rWlgR"}]}}, "followers_count": 42, "location": "Jabalpur, India", "url": "https://x.com/DhruvSahu98", "follow_url": "https://x.com/intent/follow?screen_name=DhruvSahu98"}, "url": "https://x.com/DhruvSahu98/status/1752401263713792164", "like_url": "https://x.com/intent/like?tweet_id=1752401263713792164", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752401263713792164", "replies": [], "score": 0.1, "thread_score": 0.1, "reply_count": 0, "is_branch": true}, "1752474511025553888": {"created_at": "Tue Jan 30 23:30:57 +0000 2024", "entities": [{"indices": [7, 177], "type": "text", "text": "hmmm, very cool!\n\nit would be interesting to know how far you can push the parameter count down and still achieve the effect.\n\n7B, 2B, 700M, 200M, 70M\u2026worth a try i guess"}], "favorite_count": 0, "id_str": "1752474511025553888", "in_reply_to_status_id_str": "1752349456421261335", "lang": "en", "user": {"id_str": "1536337772272930816", "name": "Jason", "screen_name": "KamaraiCode", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1732159006331023360/urOtDUNz_normal.jpg", "description": "Building at https://t.co/ncypvcnQ1V, Writing about SSMs https://t.co/VJbUbcubHN, Hosting the PyTorch ATX meetup in Austin https://t.co/I6VSSl161S", "entities": {"description": {"urls": [{"display_url": "PageTurn.io", "expanded_url": "https://PageTurn.io", "indices": [12, 35], "url": "https://t.co/ncypvcnQ1V"}, {"display_url": "statespace.info", "expanded_url": "https://statespace.info", "indices": [56, 79], "url": "https://t.co/VJbUbcubHN"}, {"display_url": "meetup.com/pytorch-atx", "expanded_url": "https://www.meetup.com/pytorch-atx", "indices": [122, 145], "url": "https://t.co/I6VSSl161S"}]}}, "followers_count": 240, "location": "Austin, TX", "url": "https://x.com/KamaraiCode", "follow_url": "https://x.com/intent/follow?screen_name=KamaraiCode"}, "url": "https://x.com/KamaraiCode/status/1752474511025553888", "like_url": "https://x.com/intent/like?tweet_id=1752474511025553888", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752474511025553888", "replies": ["1752798629360697583"], "score": 0.7, "thread_score": 0.6, "reply_count": 1, "is_branch": true}, "1752536610032492762": {"created_at": "Wed Jan 31 03:37:43 +0000 2024", "entities": [{"indices": [0, 590], "type": "text", "text": "Very interesting! Thanks for sharing.\n\nConceptually speaking, is the case that in this approach we are combining three models (Target + small tuned - small base) to produce one final model?\n\nIf it is the case, can we look at these three models as Experts and we are explicitly combining them in parametric way (Target + small tuned - small base)?\n\nFor instance, I am curious to know if one can fine tune the way these models are combines like Target + lambda_1 *small tuned - lambda_2*small base? or more generally some very lightweight function F(Target, small tuned, small base)?\n\nThanks!"}], "favorite_count": 1, "id_str": "1752536610032492762", "in_reply_to_status_id_str": "1752349456421261335", "lang": "en", "user": {"id_str": "1720100390581268480", "name": "My Custom AI", "screen_name": "MyCustomAI", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1720102870585143296/DiZxqOWH_normal.jpg", "description": "Building Customized AIs", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "mycustomai.io", "expanded_url": "https://www.mycustomai.io", "indices": [0, 23], "url": "https://t.co/lCrioLwsP1"}]}}, "followers_count": 40, "location": "Santa Clara, USA", "url": "https://x.com/MyCustomAI", "follow_url": "https://x.com/intent/follow?screen_name=MyCustomAI"}, "url": "https://x.com/MyCustomAI/status/1752536610032492762", "like_url": "https://x.com/intent/like?tweet_id=1752536610032492762", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752536610032492762", "replies": [], "score": 0.5, "thread_score": 0.4, "reply_count": 0, "tweet_type": "Q&A", "location": "method", "is_branch": true}, "1752616549347954814": {"created_at": "Wed Jan 31 08:55:22 +0000 2024", "entities": [{"indices": [7, 94], "type": "text", "text": "The primary author of the proxy-tuning paper released their implementation last week.  "}, {"display_url": "github.com/alisawuffles/p\u2026", "expanded_url": "https://github.com/alisawuffles/proxy-tuning", "indices": [94, 117], "url": "https://t.co/QCb7n6dM1H", "type": "url", "href": "https://github.com/alisawuffles/proxy-tuning", "text": "github.com/alisawuffles/p\u2026"}], "favorite_count": 4, "id_str": "1752616549347954814", "in_reply_to_status_id_str": "1752349456421261335", "lang": "en", "user": {"id_str": "10927802", "name": "Tim Wu", "screen_name": "changtimwu", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1120126690/q602368881_3631_normal.jpg", "description": "Fight for the second half.", "entities": {"description": {"urls": []}}, "followers_count": 458, "location": "Taipei", "url": "https://x.com/changtimwu", "follow_url": "https://x.com/intent/follow?screen_name=changtimwu"}, "url": "https://x.com/changtimwu/status/1752616549347954814", "like_url": "https://x.com/intent/like?tweet_id=1752616549347954814", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752616549347954814", "replies": ["1753081790598668625"], "score": 0.4, "thread_score": 0.2, "reply_count": 1, "tweet_type": "Resource", "location": "related work", "is_branch": true}, "1752798629360697583": {"created_at": "Wed Jan 31 20:58:53 +0000 2024", "entities": [{"indices": [13, 218], "type": "text", "text": "Yes sure, I used the 7B models because the chat and codellama versions were already available. But yeah you could also apply that to smaller LLMs. If you decide to give it a try, let me know what you find!"}], "favorite_count": 1, "id_str": "1752798629360697583", "in_reply_to_status_id_str": "1752474511025553888", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1752798629360697583", "like_url": "https://x.com/intent/like?tweet_id=1752798629360697583", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752798629360697583", "replies": [], "score": 0.6, "thread_score": 0, "reply_count": 0}, "1752930902374580430": {"created_at": "Thu Feb 01 05:44:29 +0000 2024", "entities": [{"id_str": "1316495843621511168", "indices": [7, 16], "name": "Mem", "screen_name": "memdotai", "type": "mention", "href": "https://x.com/memdotai", "text": "@memdotai"}, {"indices": [16, 23], "type": "text", "text": " mem it"}], "favorite_count": 0, "id_str": "1752930902374580430", "in_reply_to_status_id_str": "1752349456421261335", "lang": "en", "user": {"id_str": "746988974191837184", "name": "Nguyen D. H. Phuong", "screen_name": "towardthesea_vn", "profile_image_url_https": "https://pbs.twimg.com/profile_images/746994343030951936/yZKTEtfI_normal.jpg", "description": "Roboticist, Head of Robotics Application at NEURA Robotics, Germany.", "entities": {"description": {"urls": []}}, "followers_count": 109, "location": "Reutlingen, Germany", "url": "https://x.com/towardthesea_vn", "follow_url": "https://x.com/intent/follow?screen_name=towardthesea_vn"}, "url": "https://x.com/towardthesea_vn/status/1752930902374580430", "like_url": "https://x.com/intent/like?tweet_id=1752930902374580430", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752930902374580430", "replies": ["1752931080879944101"], "score": 0.1, "thread_score": 0.1, "reply_count": 1, "is_branch": true}, "1752931080879944101": {"created_at": "Thu Feb 01 05:45:12 +0000 2024", "entities": [{"indices": [24, 59], "type": "text", "text": "Saved! Here's the compiled thread: "}, {"display_url": "mem.ai/p/londh02uZLEO\u2026", "expanded_url": "https://mem.ai/p/londh02uZLEOSpqRvkmV", "indices": [59, 82], "url": "https://t.co/WhOuBDMWNc", "type": "url", "href": "https://mem.ai/p/londh02uZLEOSpqRvkmV", "text": "mem.ai/p/londh02uZLEO\u2026"}], "favorite_count": 0, "id_str": "1752931080879944101", "in_reply_to_status_id_str": "1752930902374580430", "lang": "en", "user": {"id_str": "1316495843621511168", "name": "Mem", "screen_name": "memdotai", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1343666213067530240/3mLsB1kf_normal.jpg", "description": "The AI Notes App That Keeps You Organized.\n\nGet Mem: https://t.co/hRTM2OXs2k\nSet up Mem It for Twitter: https://t.co/QbeULB4VF3", "entities": {"description": {"urls": [{"display_url": "mem.ai", "expanded_url": "http://mem.ai", "indices": [53, 76], "url": "https://t.co/hRTM2OXs2k"}, {"display_url": "mem.ai/sources/mem-it\u2026", "expanded_url": "http://mem.ai/sources/mem-it-for-twitter", "indices": [104, 127], "url": "https://t.co/QbeULB4VF3"}]}, "url": {"urls": [{"display_url": "mem.ai", "expanded_url": "http://mem.ai", "indices": [0, 23], "url": "https://t.co/hRTM2OXs2k"}]}}, "followers_count": 71042, "location": "San Francisco, CA", "url": "https://x.com/memdotai", "follow_url": "https://x.com/intent/follow?screen_name=memdotai"}, "url": "https://x.com/memdotai/status/1752931080879944101", "like_url": "https://x.com/intent/like?tweet_id=1752931080879944101", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752931080879944101", "replies": [], "score": 0.1, "thread_score": 0, "reply_count": 0}, "1752931701159076021": {"created_at": "Thu Feb 01 05:47:40 +0000 2024", "entities": [{"indices": [7, 101], "type": "text", "text": "Great post, thanks for sharing! But I noticed there seems to be something wrong with the table"}], "favorite_count": 0, "id_str": "1752931701159076021", "in_reply_to_status_id_str": "1752349456421261335", "lang": "en", "user": {"id_str": "932230530766061569", "name": "Xinyu Zhu", "screen_name": "tianhongzxy", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1855301628783374336/dP7YRpXW_normal.jpg", "description": "CS PhD student @UVA. Previous master @Tsinghua_uni, intern @MSFTResearch Asia. #NLProc seeking 25 summer research internship.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "zhuxinyu.top", "expanded_url": "https://zhuxinyu.top", "indices": [0, 23], "url": "https://t.co/JAYnZ96teB"}]}}, "followers_count": 139, "location": "Charlottesville", "url": "https://x.com/tianhongzxy", "follow_url": "https://x.com/intent/follow?screen_name=tianhongzxy"}, "url": "https://x.com/tianhongzxy/status/1752931701159076021", "like_url": "https://x.com/intent/like?tweet_id=1752931701159076021", "reply_url": "https://x.com/intent/tweet?in_reply_to=1752931701159076021", "replies": ["1753042717167292839"], "score": 0.2, "thread_score": 0.2, "reply_count": 3, "is_branch": true}, "1753042717167292839": {"created_at": "Thu Feb 01 13:08:48 +0000 2024", "entities": [{"indices": [13, 156], "type": "text", "text": "Thanks for the note. Happy to look into it. Do you mean that the formatting is broken on your device or do you mean some of the values are off?"}], "favorite_count": 0, "id_str": "1753042717167292839", "in_reply_to_status_id_str": "1752931701159076021", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321142, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1753042717167292839", "like_url": "https://x.com/intent/like?tweet_id=1753042717167292839", "reply_url": "https://x.com/intent/tweet?in_reply_to=1753042717167292839", "replies": ["1753048450701378030"], "score": 0.2, "thread_score": 0, "reply_count": 2}, "1753048450701378030": {"created_at": "Thu Feb 01 13:31:35 +0000 2024", "entities": [{"indices": [7, 76], "type": "text", "text": "The 7B model has 82.5 accuracy on GSM, I think one column is missing?"}], "favorite_count": 0, "id_str": "1753048450701378030", "in_reply_to_status_id_str": "1753042717167292839", "lang": "en", "user": {"id_str": "932230530766061569", "name": "Xinyu Zhu", "screen_name": "tianhongzxy", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1855301628783374336/dP7YRpXW_normal.jpg", "description": "CS PhD student @UVA. Previous master @Tsinghua_uni, intern @MSFTResearch Asia. #NLProc seeking 25 summer research internship.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "zhuxinyu.top", "expanded_url": "https://zhuxinyu.top", "indices": [0, 23], "url": "https://t.co/JAYnZ96teB"}]}}, "followers_count": 139, "location": "Charlottesville", "url": "https://x.com/tianhongzxy", "follow_url": "https://x.com/intent/follow?screen_name=tianhongzxy"}, "url": "https://x.com/tianhongzxy/status/1753048450701378030", "like_url": "https://x.com/intent/like?tweet_id=1753048450701378030", "reply_url": "https://x.com/intent/tweet?in_reply_to=1753048450701378030", "replies": ["1753093691466723788"], "score": 0.2, "thread_score": 0, "reply_count": 1}, "1753081790598668625": {"created_at": "Thu Feb 01 15:44:04 +0000 2024", "entities": [{"indices": [12, 38], "type": "text", "text": "Nice, thanks for sharing!!"}], "favorite_count": 1, "id_str": "1753081790598668625", "in_reply_to_status_id_str": "1752616549347954814", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321139, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1753081790598668625", "like_url": "https://x.com/intent/like?tweet_id=1753081790598668625", "reply_url": "https://x.com/intent/tweet?in_reply_to=1753081790598668625", "replies": [], "score": 0.1, "thread_score": 0, "reply_count": 0}, "1753093691466723788": {"created_at": "Thu Feb 01 16:31:21 +0000 2024", "entities": [{"indices": [13, 135], "type": "text", "text": "Thanks for the note, there was a column-shift (arg, I love markdown, but markdown tables are tricky ...). Should be fixed!"}], "favorite_count": 1, "id_str": "1753093691466723788", "in_reply_to_status_id_str": "1753048450701378030", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321142, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1753093691466723788", "like_url": "https://x.com/intent/like?tweet_id=1753093691466723788", "reply_url": "https://x.com/intent/tweet?in_reply_to=1753093691466723788", "replies": [], "score": 0.2, "thread_score": 0, "reply_count": 0}, "1753173434366861712": {"created_at": "Thu Feb 01 21:48:13 +0000 2024", "entities": [{"indices": [0, 336], "type": "text", "text": "Is the net benefit that less $$$ has to be spent to get custom 70B models?\n\n1. Feels like by training the \"small tuned LLM\" less hardware is needed for the fine tuning. \n2. Feels like for the proxy inference, you then run 3 models but if the models are quantized then you still are using less hardware. \n\nIs the above intuition correct?"}], "favorite_count": 0, "id_str": "1753173434366861712", "in_reply_to_status_id_str": "1752349456421261335", "lang": "en", "user": {"id_str": "37522774", "name": "Ralph Brooks \ud83c\udfaf Precision SEO Targeting \ud83c\udfaf", "screen_name": "ralphbrooks", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1223010784344711169/2U0F3ciq_normal.jpg", "description": "UCLA MBA/Data Scientist turning data into SEO strategies. Track record in competitive landscapes (notary, hotels). Fortune 500 companies and law firms trust me.", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "fortenotary.com/ralphbrooks", "expanded_url": "https://fortenotary.com/ralphbrooks", "indices": [0, 23], "url": "https://t.co/9ubreRKTc4"}]}}, "followers_count": 2704, "location": "Frisco, TX", "url": "https://x.com/ralphbrooks", "follow_url": "https://x.com/intent/follow?screen_name=ralphbrooks"}, "url": "https://x.com/ralphbrooks/status/1753173434366861712", "like_url": "https://x.com/intent/like?tweet_id=1753173434366861712", "reply_url": "https://x.com/intent/tweet?in_reply_to=1753173434366861712", "replies": [], "score": 0.3, "thread_score": 0.3, "reply_count": 0, "tweet_type": "Q&A", "location": "abstract", "is_branch": true}, "1753245478886539544": {"created_at": "Fri Feb 02 02:34:30 +0000 2024", "entities": [{"indices": [24, 200], "type": "text", "text": "Thanks Sebastian. Useful and Cool. Fundamentally I can use this technique for a base model ie my target model as per your note which does not have SFT capabilities.  Correct ?."}], "favorite_count": 0, "id_str": "1753245478886539544", "in_reply_to_status_id_str": "1752370095198711887", "lang": "en", "user": {"id_str": "1685195446191263744", "name": "ramesh balaji", "screen_name": "rameshbala63065", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1685195536054312960/3TDxLSKj_normal.png", "description": "", "entities": {"description": {"urls": []}}, "followers_count": 1, "location": "", "url": "https://x.com/rameshbala63065", "follow_url": "https://x.com/intent/follow?screen_name=rameshbala63065"}, "url": "https://x.com/rameshbala63065/status/1753245478886539544", "like_url": "https://x.com/intent/like?tweet_id=1753245478886539544", "reply_url": "https://x.com/intent/tweet?in_reply_to=1753245478886539544", "replies": ["1753427536413868340"], "score": 0.2, "thread_score": 0, "reply_count": 1}, "1753427536413868340": {"created_at": "Fri Feb 02 14:37:56 +0000 2024", "entities": [{"indices": [34, 147], "type": "text", "text": "Yes that\u2019s correct. You can use a small SFT or Chat model to give a larger base (target) model these capabilities"}], "favorite_count": 0, "id_str": "1753427536413868340", "in_reply_to_status_id_str": "1753245478886539544", "lang": "en", "user": {"id_str": "865622395", "name": "Sebastian Raschka", "screen_name": "rasbt", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1661187442043486209/a3E4t1eV_normal.jpg", "description": "ML/AI researcher & former stats professor turned LLM research engineer. Author of \"Build a Large Language Model From Scratch\" (https://t.co/O8LAAMRzzW).", "entities": {"description": {"urls": [{"display_url": "amzn.to/4fqvn0D", "expanded_url": "https://amzn.to/4fqvn0D", "indices": [127, 150], "url": "https://t.co/O8LAAMRzzW"}]}, "url": {"urls": [{"display_url": "sebastianraschka.com", "expanded_url": "https://sebastianraschka.com", "indices": [0, 23], "url": "https://t.co/HrtQQ5tgJl"}]}}, "followers_count": 321142, "location": "United States", "url": "https://x.com/rasbt", "follow_url": "https://x.com/intent/follow?screen_name=rasbt"}, "url": "https://x.com/rasbt/status/1753427536413868340", "like_url": "https://x.com/intent/like?tweet_id=1753427536413868340", "reply_url": "https://x.com/intent/tweet?in_reply_to=1753427536413868340", "replies": [], "score": 0.2, "thread_score": 0, "reply_count": 0}, "1754016198805619119": {"created_at": "Sun Feb 04 05:37:04 +0000 2024", "entities": [{"indices": [0, 137], "type": "text", "text": "But proxy-tuned models don't really perform well compared to directly tuned ones.\nUse LoRA instead...\nThe former is truthful though!! \ud83d\udc40\n\n"}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [137, 160], "url": "https://t.co/jS0b6IOZ21", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}, {"indices": [160, 162], "type": "text", "text": "\n\n"}, {"id_str": "1197247629136203776", "indices": [162, 175], "name": "Alisa Liu", "screen_name": "alisawuffles", "type": "mention", "href": "https://x.com/alisawuffles", "text": "@alisawuffles"}, {"indices": [175, 176], "type": "text", "text": " "}, {"id_str": "4916685123", "indices": [176, 190], "name": "Xiaochuang Han", "screen_name": "XiaochuangHan", "type": "mention", "href": "https://x.com/XiaochuangHan", "text": "@XiaochuangHan"}, {"indices": [190, 191], "type": "text", "text": " "}, {"id_str": "3129176335", "indices": [191, 202], "name": "Yizhong Wang", "screen_name": "yizhongwyz", "type": "mention", "href": "https://x.com/yizhongwyz", "text": "@yizhongwyz"}, {"indices": [202, 203], "type": "text", "text": " "}, {"id_str": "893882282175471616", "indices": [203, 216], "name": "Yejin Choi", "screen_name": "YejinChoinka", "type": "mention", "href": "https://x.com/YejinChoinka", "text": "@YejinChoinka"}, {"indices": [216, 217], "type": "text", "text": " "}, {"id_str": "158789494", "indices": [217, 225], "name": "Noah A. Smith", "screen_name": "nlpnoah", "type": "mention", "href": "https://x.com/nlpnoah", "text": "@nlpnoah"}, {"indices": [225, 233], "type": "text", "text": " Python "}, {"indices": [233, 256], "text": "#ArtificialIntelligence", "type": "hashtag", "href": "https://x.com/hashtag/ArtificialIntelligence"}, {"indices": [256, 257], "type": "text", "text": " "}, {"indices": [257, 262], "text": "#LLMs", "type": "hashtag", "href": "https://x.com/hashtag/LLMs"}, {"indices": [262, 263], "type": "text", "text": " "}, {"indices": [263, 276], "text": "#GenerativeAI", "type": "hashtag", "href": "https://x.com/hashtag/GenerativeAI"}], "favorite_count": 1, "id_str": "1754016198805619119", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/lrGvUZ99PT", "expanded_url": "https://x.com/ArionDas/status/1754016198805619119/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": [{"h": 54, "w": 54, "x": 373, "y": 186}]}, "medium": {"faces": [{"h": 54, "w": 54, "x": 373, "y": 186}]}, "orig": {"faces": [{"h": 54, "w": 54, "x": 373, "y": 186}]}, "small": {"faces": [{"h": 54, "w": 54, "x": 373, "y": 186}]}}, "id_str": "1754014120930652160", "indices": [277, 300], "media_key": "3_1754014120930652160", "media_results": {"result": {"media_key": "3_1754014120930652160"}}, "media_url_https": "https://pbs.twimg.com/media/GFeCjMEXMAAtfhU.png", "original_info": {"focus_rects": [{"h": 260, "w": 464, "x": 0, "y": 0}, {"h": 260, "w": 260, "x": 0, "y": 0}, {"h": 260, "w": 228, "x": 0, "y": 0}, {"h": 260, "w": 130, "x": 17, "y": 0}, {"h": 260, "w": 658, "x": 0, "y": 0}], "height": 260, "width": 658}, "sizes": {"large": {"h": 260, "resize": "fit", "w": 658}, "medium": {"h": 260, "resize": "fit", "w": 658}, "small": {"h": 260, "resize": "fit", "w": 658}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/lrGvUZ99PT"}], "user": {"id_str": "1511284661972238337", "name": "Arion Das || Gen AI Research || LLMs || NLP", "screen_name": "ArionDas", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1734654049704869888/zEZQ767i_normal.jpg", "description": "Research @ AIISC (UoSC) || AI Eng. Intern @ CareerCafe || Ex NLP Research Intern @Oracle, @iiserkol || Junior, @IIITRanchi || Forza Ferrari @ScuderiaFerrari @F1", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "sites.google.com/view/ariondasa\u2026", "expanded_url": "https://sites.google.com/view/ariondasad/", "indices": [0, 23], "url": "https://t.co/AmLjc6avam"}]}}, "followers_count": 693, "location": "Kolkata, India", "url": "https://x.com/ArionDas", "follow_url": "https://x.com/intent/follow?screen_name=ArionDas"}, "url": "https://x.com/ArionDas/status/1754016198805619119", "like_url": "https://x.com/intent/like?tweet_id=1754016198805619119", "reply_url": "https://x.com/intent/tweet?in_reply_to=1754016198805619119", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0, "is_branch": true}, "1758205655675207912": {"created_at": "Thu Feb 15 19:04:28 +0000 2024", "entities": [{"indices": [7, 58], "type": "text", "text": "There was also stuff around this in 2021-2022 (see "}, {"display_url": "arxiv.org/pdf/2210.07229\u2026", "expanded_url": "https://arxiv.org/pdf/2210.07229.pdf", "indices": [58, 81], "url": "https://t.co/JIaBVcL8Op", "type": "url", "href": "https://arxiv.org/pdf/2210.07229.pdf", "text": "arxiv.org/pdf/2210.07229\u2026"}, {"indices": [81, 84], "type": "text", "text": ")\n\n"}, {"id_str": "1228506265665462272", "indices": [84, 93], "name": "Rohan Pandey", "screen_name": "khoomeik", "type": "mention", "href": "https://x.com/khoomeik", "text": "@khoomeik"}, {"indices": [93, 142], "type": "text", "text": " implemented some cool stuff around this recently"}], "favorite_count": 1, "id_str": "1758205655675207912", "in_reply_to_status_id_str": "1748021765790376385", "lang": "en", "user": {"id_str": "920825036461694976", "name": "Vibhu Sapra", "screen_name": "vibhuuuus", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1829938689298067456/d5wzdijo_normal.jpg", "description": "gpu go brrr", "entities": {"description": {"urls": []}}, "followers_count": 724, "location": "San Fransisco", "url": "https://x.com/vibhuuuus", "follow_url": "https://x.com/intent/follow?screen_name=vibhuuuus"}, "url": "https://x.com/vibhuuuus/status/1758205655675207912", "like_url": "https://x.com/intent/like?tweet_id=1758205655675207912", "reply_url": "https://x.com/intent/tweet?in_reply_to=1758205655675207912", "replies": [], "score": 0.2, "thread_score": 0.2, "reply_count": 0, "tweet_type": "Related Work", "location": "related work", "is_branch": true}, "1761535865589756084": {"created_at": "Sat Feb 24 23:37:32 +0000 2024", "entities": [{"indices": [13, 204], "type": "text", "text": "Btw, related question - what if there are no sentences to begin with?\nWhat is the best way to split this mess of words into sentences, while making sure nothing is skipped or lost on the way?"}], "favorite_count": 0, "id_str": "1761535865589756084", "in_reply_to_status_id_str": "1745467853799874969", "lang": "en", "mediaDetails": [{"display_url": "pic.x.com/aMAO6tqzOw", "expanded_url": "https://x.com/0x796/status/1761535865589756084/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1761526913539985409", "indices": [205, 228], "media_key": "3_1761526913539985409", "media_results": {"result": {"media_key": "3_1761526913539985409"}}, "media_url_https": "https://pbs.twimg.com/media/GHIzZRfXUAEsKYG.png", "original_info": {"focus_rects": [{"h": 701, "w": 1252, "x": 0, "y": 0}, {"h": 864, "w": 864, "x": 388, "y": 0}, {"h": 864, "w": 758, "x": 494, "y": 0}, {"h": 864, "w": 432, "x": 820, "y": 0}, {"h": 864, "w": 1252, "x": 0, "y": 0}], "height": 864, "width": 1252}, "sizes": {"large": {"h": 864, "resize": "fit", "w": 1252}, "medium": {"h": 828, "resize": "fit", "w": 1200}, "small": {"h": 469, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/aMAO6tqzOw"}], "user": {"id_str": "112655719", "name": "Convergence Boy", "screen_name": "0x796", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1550534056986771457/Er1kvAuV_normal.jpg", "description": "Be playful. Be true.\nLike building stuff for fun and rant about sheet.\nYou can never tell if serious or sarcasm.", "entities": {"description": {"urls": []}}, "followers_count": 1972, "location": "0x45564D", "url": "https://x.com/0x796", "follow_url": "https://x.com/intent/follow?screen_name=0x796"}, "url": "https://x.com/0x796/status/1761535865589756084", "like_url": "https://x.com/intent/like?tweet_id=1761535865589756084", "reply_url": "https://x.com/intent/tweet?in_reply_to=1761535865589756084", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1784559710978404861": {"created_at": "Sun Apr 28 12:26:05 +0000 2024", "entities": [{"indices": [0, 3814], "type": "text", "text": "\ud83d\udccc Pretty interesting proposal in this paper - Finetuning an LLM without actually training its own weights.\n\n\ud83d\udccc \"Tuning Language Models by Proxy\"\n\n\ud83d\udd25 Proxy-Tuning relies on a setup where you have a large LLM that you don't want to/can't fine-tune, and a pair of small LLMs that you have fine-tuned. The intervention occurs at the decoding logit, which outputs a distribution over the next token to output in the response.\n\n\ud83d\udccc proxy-tuning is a lightweight decoding-time algorithm that operates on top of black-box LMs to achieve the result of directly tuning the model, but by accessing only its prediction over the output vocabulary.\n\n\ud83d\udccc This method instead tunes a smaller LM, then applies the difference between the predictions of the small tuned and untuned LMs to shift the original predictions of the base model in the direction of tuning, while retaining the benefits of larger-scale pretraining.\n\n\ud83d\udccc Tokenizers are often open-source, even for closed-source models like GPT-4 (i.e. tiktken), making it feasible to steer these models with small, open-source models. When vocabularies do not match, techniques like \"Twist Decoding: Diverse Generators Guide Each Other\" could be applied.\"\n\n\ud83d\udccc Evaluation Results: When applied proxy-tuning to LAMA 2-70B using proxies of only 7B size, the researchers can close 88% of the gap\nbetween LLAMA 2-70B and its truly-tuned CHAT version, when evaluated across knowledge, reasoning, and safety benchmarks.\n\nInterestingly, when tested on TruthfulQA, proxy-tuned models are actually more truthful than directly tuned models, possibly because decoding-time guidance better retains the model\u2019s factual knowledge.\n\nThe paper also demonstrate the generality of proxy-tuning by applying it for domain adaptation on code, and task-specific finetuning on question-answering and math problems.\n\n\ud83d\udccc So this work demonstrates the promise of using small tuned LMs to efficiently customize large, potentially proprietary LMs through decoding-time guidance.\n\n---------\n\nProxy-Tuning will run your prompt on all 3 models\n\n\ud83d\udccc (Large, Small-base, Small-Finetuned).\n\n\ud83d\udccc It will take the output distribution for S-FT and S-Base, calculate a difference, and use that as a \"steering distribution\" to influence the output distribution of the large model.\n\n\ud83d\udccc The intuition is that if the small finetuned model can act as an expert in a particular domain, AND the vocabulary (set of tokens) is the same between all 3 models, then the specialized opinion of the expert - the uninformed opinion of the base model can serve as a good adjustment for the large model.\n\n---------\n\n\u2753 Why two smaller models, not one finetuned. \u2753\n\nThe goal was to improve a much larger model (e.g. Llama 2 70B Base model) to the level of its finetuned version (e.g. Llama 2 70B Chat) but without doing any RLHF. Because doing Base -> Finetuned Chat version for a 70B model is super expensive.\n\nSo they took a 10x smaller Llama 2 7B model and instruction-finetuned it, which cost much much less. After finetuning, they computed the difference in logits over the output vocabulary between 7B Base and 7B Finetuned\n\nAnd now finally applied the difference to the Llama-2-70B Base model. This pushed the 70B Base model's performance pretty close to 70B Chat.\n\nSo effectively we finetuned a 70B model at the cost of finetuning a 7B Model.\n\nThe main constraint of this technique however is that your smaller model and the larger model, have to be trained on the same vocabulary. Theoretically, if we knew vocabulary that GPT-4 was trained on, and have access to its logit outputs, we can create new specialized GPT-4 models with this approach.\n\nBut they also mention in the paper, when vocabularies do not match, techniques like \"Twist Decoding: Diverse Generators Guide Each Other\" could be applied.\" - as a partial solution."}], "favorite_count": 169, "id_str": "1784559710978404861", "lang": "en", "mediaDetails": [{"allow_download_status": {"allow_download": true}, "display_url": "pic.x.com/qN8UKwYM0Z", "expanded_url": "https://x.com/rohanpaul_ai/status/1784559710978404861/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1784559533429252096", "indices": [276, 299], "media_key": "3_1784559533429252096", "media_results": {"result": {"media_key": "3_1784559533429252096"}}, "media_url_https": "https://pbs.twimg.com/media/GMQHcM6WYAANb1J.jpg", "original_info": {"focus_rects": [{"h": 579, "w": 1034, "x": 0, "y": 0}, {"h": 736, "w": 736, "x": 149, "y": 0}, {"h": 736, "w": 646, "x": 194, "y": 0}, {"h": 736, "w": 368, "x": 333, "y": 0}, {"h": 736, "w": 1034, "x": 0, "y": 0}], "height": 736, "width": 1034}, "sizes": {"large": {"h": 736, "resize": "fit", "w": 1034}, "medium": {"h": 736, "resize": "fit", "w": 1034}, "small": {"h": 484, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/qN8UKwYM0Z"}], "user": {"id_str": "2588345408", "name": "Rohan Paul", "screen_name": "rohanpaul_ai", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1816185267037859840/Fd18CH0v_normal.jpg", "description": "\ud83d\udcbc Engineer.\n\n\ud83d\udcda I also write daily on actionable AI developments.\n\n\ud83d\uddde\ufe0f Get a 1300+ page free Python book as soon as you sign up \u2192 https://t.co/Jfj0r0wLUN", "entities": {"description": {"urls": [{"display_url": "rohanpaul.substack.com", "expanded_url": "http://rohanpaul.substack.com", "indices": [128, 151], "url": "https://t.co/Jfj0r0wLUN"}]}, "url": {"urls": [{"display_url": "rohanpaul.substack.com", "expanded_url": "http://rohanpaul.substack.com", "indices": [0, 23], "url": "https://t.co/Jfj0r0wLUN"}]}}, "followers_count": 62667, "location": "Ex Inv Banker (Deutsche)", "url": "https://x.com/rohanpaul_ai", "follow_url": "https://x.com/intent/follow?screen_name=rohanpaul_ai"}, "url": "https://x.com/rohanpaul_ai/status/1784559710978404861", "like_url": "https://x.com/intent/like?tweet_id=1784559710978404861", "reply_url": "https://x.com/intent/tweet?in_reply_to=1784559710978404861", "replies": ["1784559764459897096", "1784858642732241362", "1784865923309977916", "1784748677531103716"], "score": 0, "thread_score": 0.2, "reply_count": 4, "tweet_type": "Teaser", "is_branch": true}, "1784559764459897096": {"created_at": "Sun Apr 28 12:26:18 +0000 2024", "entities": [{"indices": [0, 8], "type": "text", "text": "Paper - "}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [8, 31], "url": "https://t.co/LzV89CHePC", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}], "favorite_count": 7, "id_str": "1784559764459897096", "in_reply_to_status_id_str": "1784559710978404861", "lang": "en", "user": {"id_str": "2588345408", "name": "Rohan Paul", "screen_name": "rohanpaul_ai", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1816185267037859840/Fd18CH0v_normal.jpg", "description": "\ud83d\udcbc Engineer.\n\n\ud83d\udcda I also write daily on actionable AI developments.\n\n\ud83d\uddde\ufe0f Get a 1300+ page free Python book as soon as you sign up \u2192 https://t.co/Jfj0r0wLUN", "entities": {"description": {"urls": [{"display_url": "rohanpaul.substack.com", "expanded_url": "http://rohanpaul.substack.com", "indices": [128, 151], "url": "https://t.co/Jfj0r0wLUN"}]}, "url": {"urls": [{"display_url": "rohanpaul.substack.com", "expanded_url": "http://rohanpaul.substack.com", "indices": [0, 23], "url": "https://t.co/Jfj0r0wLUN"}]}}, "followers_count": 62667, "location": "Ex Inv Banker (Deutsche)", "url": "https://x.com/rohanpaul_ai", "follow_url": "https://x.com/intent/follow?screen_name=rohanpaul_ai"}, "url": "https://x.com/rohanpaul_ai/status/1784559764459897096", "like_url": "https://x.com/intent/like?tweet_id=1784559764459897096", "reply_url": "https://x.com/intent/tweet?in_reply_to=1784559764459897096", "replies": [], "score": 0.0, "thread_score": 0.0, "reply_count": 0, "tweet_type": "Resource", "location": "related work", "is_branch": true}, "1784721454946468174": {"created_at": "Sun Apr 28 23:08:48 +0000 2024", "entities": [{"indices": [0, 32], "type": "text", "text": "Tuning Language Models by Proxy\n"}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [32, 55], "url": "https://t.co/5JgWS1bDXV", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}], "favorite_count": 0, "id_str": "1784721454946468174", "lang": "en", "user": {"id_str": "1487345386226614278", "name": "knishimae", "screen_name": "knishimae0531", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1652593598591045633/zjdRMgvG_normal.jpg", "description": "\u306f\u3058\u3081\u307e\u3057\u3066\n\u73fe\u5728\u3001\u97f3\u58f0\u8a8d\u8b58\u3084LLM\u306b\u53d6\u308a\u7d44\u3093\u3067\u304a\u308a\u307e\u3059\u3002\nAI\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u306b\u3082\u53c2\u52a0\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u304a\u4f1a\u3044\u3057\u305f\u969b\u306f\n\u3088\u308d\u3057\u304f\u304a\u9858\u3044\u3057\u307e\u3059\u3002\n\nAI\u30d9\u30f3\u30c1\u30e3\u30fc\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30de\u30cd\u30fc\u30b8\u30e3\u30fc", "entities": {"description": {"urls": []}}, "followers_count": 390, "location": "", "url": "https://x.com/knishimae0531", "follow_url": "https://x.com/intent/follow?screen_name=knishimae0531"}, "url": "https://x.com/knishimae0531/status/1784721454946468174", "like_url": "https://x.com/intent/like?tweet_id=1784721454946468174", "reply_url": "https://x.com/intent/tweet?in_reply_to=1784721454946468174", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0, "is_branch": true}, "1784748677531103716": {"created_at": "Mon Apr 29 00:56:58 +0000 2024", "entities": [{"indices": [14, 73], "type": "text", "text": "Yeah this is reminiscent of model merging, very interesting"}], "favorite_count": 0, "id_str": "1784748677531103716", "in_reply_to_status_id_str": "1784559710978404861", "lang": "en", "user": {"id_str": "1745974102811172864", "name": "Ji-Ha", "screen_name": "Ji_Ha_Kim", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1745975072018333696/w_rIDhL4_normal.jpg", "description": "", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "jiha-kim.github.io", "expanded_url": "http://jiha-kim.github.io", "indices": [0, 23], "url": "https://t.co/f1LwnBMUWG"}]}}, "followers_count": 2154, "location": "", "url": "https://x.com/Ji_Ha_Kim", "follow_url": "https://x.com/intent/follow?screen_name=Ji_Ha_Kim"}, "url": "https://x.com/Ji_Ha_Kim/status/1784748677531103716", "like_url": "https://x.com/intent/like?tweet_id=1784748677531103716", "reply_url": "https://x.com/intent/tweet?in_reply_to=1784748677531103716", "replies": [], "score": 0.2, "thread_score": 0.1, "reply_count": 0, "is_branch": true}, "1784858642732241362": {"created_at": "Mon Apr 29 08:13:56 +0000 2024", "entities": [{"indices": [14, 51], "type": "text", "text": "How is this different from DExperts? "}, {"display_url": "aclanthology.org/2021.acl-long.\u2026", "expanded_url": "https://aclanthology.org/2021.acl-long.522/", "indices": [51, 74], "url": "https://t.co/K8ZTaOmo32", "type": "url", "href": "https://aclanthology.org/2021.acl-long.522/", "text": "aclanthology.org/2021.acl-long.\u2026"}], "favorite_count": 7, "id_str": "1784858642732241362", "in_reply_to_status_id_str": "1784559710978404861", "lang": "en", "user": {"id_str": "512275659", "name": "Pasquale Minervini is hiring postdocs! \ud83d\ude80", "screen_name": "PMinervini", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1535176863827501056/q8SjC8WM_normal.jpg", "description": "Research in ML/NLP at the U of Edinburgh (tenured faculty @InfAtEd @EdinburghNLP), Co-Founder @Miniml_AI, @ELLISforEurope Scholar, https://t.co/5dUI3EFexo", "entities": {"description": {"urls": [{"display_url": "neuralnoise.com", "expanded_url": "https://www.neuralnoise.com", "indices": [131, 154], "url": "https://t.co/5dUI3EFexo"}]}, "url": {"urls": [{"display_url": "neuralnoise.com", "expanded_url": "https://www.neuralnoise.com", "indices": [0, 23], "url": "https://t.co/5dUI3EFexo"}]}}, "followers_count": 8405, "location": "Edinburgh, United Kingdom", "url": "https://x.com/PMinervini", "follow_url": "https://x.com/intent/follow?screen_name=PMinervini"}, "url": "https://x.com/PMinervini/status/1784858642732241362", "like_url": "https://x.com/intent/like?tweet_id=1784858642732241362", "reply_url": "https://x.com/intent/tweet?in_reply_to=1784858642732241362", "replies": [], "score": 0.4, "thread_score": 0.3, "reply_count": 0, "tweet_type": "Related Work", "location": "related work", "is_branch": true}, "1784865923309977916": {"created_at": "Mon Apr 29 08:42:51 +0000 2024", "entities": [{"indices": [14, 145], "type": "text", "text": "We tried it. Performance really deteriorated. The idea is good but on serious tasks it doesn\u2019t work that well from our experience \ud83d\ude33"}], "favorite_count": 1, "id_str": "1784865923309977916", "in_reply_to_status_id_str": "1784559710978404861", "lang": "en", "user": {"id_str": "1364749022", "name": "Haitham Bou Ammar", "screen_name": "hbouammar", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1900889242517024769/3Y3-RDzg_normal.jpg", "description": "RL team leader @Huawei R&D UK H. Assistant Professor @UCL | Ex-@Princeton, Upenn (thou/thine)", "entities": {"description": {"urls": []}}, "followers_count": 4155, "location": "Cambridge", "url": "https://x.com/hbouammar", "follow_url": "https://x.com/intent/follow?screen_name=hbouammar"}, "url": "https://x.com/hbouammar/status/1784865923309977916", "like_url": "https://x.com/intent/like?tweet_id=1784865923309977916", "reply_url": "https://x.com/intent/tweet?in_reply_to=1784865923309977916", "replies": [], "score": 0.4, "thread_score": 0.3, "reply_count": 0, "tweet_type": "Perspective", "location": "conclusion", "is_branch": true}, "1786518726537318734": {"created_at": "Fri May 03 22:10:30 +0000 2024", "entities": [{"indices": [0, 3261], "type": "text", "text": "\ud83d\udccc Really innovative proposal in this paper - Finetuning an LLM without actually training its own weights.\n\n\ud83d\udccc \"Tuning Language Models by Proxy\"\n\n\ud83d\udd25 Proxy-Tuning relies on a setup where you have a large LLM that you don't want to/can't fine-tune, and a pair of small LLMs that you have fine-tuned. The intervention occurs at the decoding logit, which outputs a distribution over the next token to output in the response.\n\n\ud83d\udccc This method instead tunes a smaller LM, then applies the difference between the predictions of the small tuned and untuned LMs to shift the original predictions of the base model in the direction of tuning, while retaining the benefits of larger-scale pretraining.\n\n\ud83d\udccc Tokenizers are often open-source, even for closed-source models like GPT-4 (i.e. tiktken), making it feasible to steer these models with small, open-source models. When vocabularies do not match, techniques like \"Twist Decoding: Diverse Generators Guide Each Other\" could be applied.\"\n\n\ud83d\udccc Evaluation Results: When applied proxy-tuning to LAMA 2-70B using proxies of only 7B size, the researchers can close 88% of the gap\nbetween LLAMA 2-70B and its truly-tuned CHAT version, when evaluated across knowledge, reasoning, and safety benchmarks.\n\nInterestingly, when tested on TruthfulQA, proxy-tuned models are actually more truthful than directly tuned models, possibly because decoding-time guidance better retains the model\u2019s factual knowledge.\n\n------\n\nProxy-Tuning will run your prompt on all 3 models\n\n\ud83d\udccc (Large, Small-base, Small-Finetuned).\n\n\ud83d\udccc It will take the output distribution for S-FT and S-Base, calculate a difference, and use that as a \"steering distribution\" to influence the output distribution of the large model.\n\n\ud83d\udccc The intuition is that if the small finetuned model can act as an expert in a particular domain, AND the vocabulary (set of tokens) is the same between all 3 models, then the specialized opinion of the expert - the uninformed opinion of the base model can serve as a good adjustment for the large model.\n\n---------\n\nWhy two smaller models, not one finetuned. \u2753\n\nThe goal was to improve a much larger model (e.g. Llama 2 70B Base model) to the level of its finetuned version (e.g. Llama 2 70B Chat) but without doing any RLHF. Because doing Base -> Finetuned Chat version for a 70B model is super expensive.\n\nSo they took a 10x smaller Llama 2 7B model and instruction-finetuned it, which cost much much less. After finetuning, they computed the difference in logits over the output vocabulary between 7B Base and 7B Finetuned\n\nAnd now finally applied the difference to the Llama-2-70B Base model. This pushed the 70B Base model's performance pretty close to 70B Chat.\n\nSo effectively we finetuned a 70B model at the cost of finetuning a 7B Model.\n\nThe main constraint of this technique however is that your smaller model and the larger model, have to be trained on the same vocabulary. Theoretically, if we knew vocabulary that GPT-4 was trained on, and have access to its logit outputs, we can create new specialized GPT-4 models with this approach.\n\nBut they also mention in the paper, when vocabularies do not match, techniques like \"Twist Decoding: Diverse Generators Guide Each Other\" could be applied.\" - as a partial solution."}], "favorite_count": 122, "id_str": "1786518726537318734", "lang": "en", "mediaDetails": [{"allow_download_status": {"allow_download": true}, "display_url": "pic.x.com/rv89pLDwx2", "expanded_url": "https://x.com/rohanpaul_ai/status/1786518726537318734/photo/1", "ext_media_availability": {"status": "Available"}, "features": {"large": {"faces": []}, "medium": {"faces": []}, "orig": {"faces": []}, "small": {"faces": []}}, "id_str": "1786518573403234304", "indices": [279, 302], "media_key": "3_1786518573403234304", "media_results": {"result": {"media_key": "3_1786518573403234304"}}, "media_url_https": "https://pbs.twimg.com/media/GMr9LVhWYAAFm1Y.jpg", "original_info": {"focus_rects": [{"h": 579, "w": 1034, "x": 0, "y": 0}, {"h": 736, "w": 736, "x": 149, "y": 0}, {"h": 736, "w": 646, "x": 194, "y": 0}, {"h": 736, "w": 368, "x": 333, "y": 0}, {"h": 736, "w": 1034, "x": 0, "y": 0}], "height": 736, "width": 1034}, "sizes": {"large": {"h": 736, "resize": "fit", "w": 1034}, "medium": {"h": 736, "resize": "fit", "w": 1034}, "small": {"h": 484, "resize": "fit", "w": 680}, "thumb": {"h": 150, "resize": "crop", "w": 150}}, "type": "photo", "url": "https://t.co/rv89pLDwx2"}], "user": {"id_str": "2588345408", "name": "Rohan Paul", "screen_name": "rohanpaul_ai", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1816185267037859840/Fd18CH0v_normal.jpg", "description": "\ud83d\udcbc Engineer.\n\n\ud83d\udcda I also write daily on actionable AI developments.\n\n\ud83d\uddde\ufe0f Get a 1300+ page free Python book as soon as you sign up \u2192 https://t.co/Jfj0r0wLUN", "entities": {"description": {"urls": [{"display_url": "rohanpaul.substack.com", "expanded_url": "http://rohanpaul.substack.com", "indices": [128, 151], "url": "https://t.co/Jfj0r0wLUN"}]}, "url": {"urls": [{"display_url": "rohanpaul.substack.com", "expanded_url": "http://rohanpaul.substack.com", "indices": [0, 23], "url": "https://t.co/Jfj0r0wLUN"}]}}, "followers_count": 62666, "location": "Ex Inv Banker (Deutsche)", "url": "https://x.com/rohanpaul_ai", "follow_url": "https://x.com/intent/follow?screen_name=rohanpaul_ai"}, "url": "https://x.com/rohanpaul_ai/status/1786518726537318734", "like_url": "https://x.com/intent/like?tweet_id=1786518726537318734", "reply_url": "https://x.com/intent/tweet?in_reply_to=1786518726537318734", "replies": ["1786518747403997298", "1786630651707314409", "1786841198189060415"], "score": 0, "thread_score": 0.2, "reply_count": 3, "tweet_type": "Teaser", "is_branch": true}, "1786518747403997298": {"created_at": "Fri May 03 22:10:35 +0000 2024", "entities": [{"indices": [0, 8], "type": "text", "text": "Paper - "}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [8, 31], "url": "https://t.co/LzV89CHePC", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}], "favorite_count": 7, "id_str": "1786518747403997298", "in_reply_to_status_id_str": "1786518726537318734", "lang": "en", "user": {"id_str": "2588345408", "name": "Rohan Paul", "screen_name": "rohanpaul_ai", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1816185267037859840/Fd18CH0v_normal.jpg", "description": "\ud83d\udcbc Engineer.\n\n\ud83d\udcda I also write daily on actionable AI developments.\n\n\ud83d\uddde\ufe0f Get a 1300+ page free Python book as soon as you sign up \u2192 https://t.co/Jfj0r0wLUN", "entities": {"description": {"urls": [{"display_url": "rohanpaul.substack.com", "expanded_url": "http://rohanpaul.substack.com", "indices": [128, 151], "url": "https://t.co/Jfj0r0wLUN"}]}, "url": {"urls": [{"display_url": "rohanpaul.substack.com", "expanded_url": "http://rohanpaul.substack.com", "indices": [0, 23], "url": "https://t.co/Jfj0r0wLUN"}]}}, "followers_count": 62666, "location": "Ex Inv Banker (Deutsche)", "url": "https://x.com/rohanpaul_ai", "follow_url": "https://x.com/intent/follow?screen_name=rohanpaul_ai"}, "url": "https://x.com/rohanpaul_ai/status/1786518747403997298", "like_url": "https://x.com/intent/like?tweet_id=1786518747403997298", "reply_url": "https://x.com/intent/tweet?in_reply_to=1786518747403997298", "replies": [], "score": 0.0, "thread_score": 0.0, "reply_count": 0, "tweet_type": "Teaser", "is_branch": true}, "1786533515875508616": {"created_at": "Fri May 03 23:09:17 +0000 2024", "entities": [{"indices": [0, 1], "type": "text", "text": "\ud83d\udc47"}], "favorite_count": 0, "id_str": "1786533515875508616", "quoted_status_id_str": "1786518726537318734", "lang": "art", "user": {"id_str": "14423278", "name": "Rub\u00e9n Aros", "screen_name": "rubenaros", "profile_image_url_https": "https://pbs.twimg.com/profile_images/989626692665823232/TsEZQCrN_normal.jpg", "description": "Hablo de Inteligencia Artificial. Me gusta emprender. Tambi\u00e9n hago jalot para la @adelaboltansky", "entities": {"description": {"urls": []}}, "followers_count": 908, "location": "Santiago, Chile", "url": "https://x.com/rubenaros", "follow_url": "https://x.com/intent/follow?screen_name=rubenaros"}, "url": "https://x.com/rubenaros/status/1786533515875508616", "like_url": "https://x.com/intent/like?tweet_id=1786533515875508616", "reply_url": "https://x.com/intent/tweet?in_reply_to=1786533515875508616", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0}, "1786630651707314409": {"created_at": "Sat May 04 05:35:16 +0000 2024", "entities": [{"indices": [14, 62], "type": "text", "text": "that is some big brain stuff. Kudos to the team!"}], "favorite_count": 1, "id_str": "1786630651707314409", "in_reply_to_status_id_str": "1786518726537318734", "lang": "en", "user": {"id_str": "1624165115653152771", "name": "Omar", "screen_name": "actualrealyorth", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1760663550748495872/JD2bXBYV_normal.jpg", "description": "I'm a writer, data scientist, and obsessed with Deep Learning.\nMy story: https://t.co/Azz8nD0UoZ", "entities": {"description": {"urls": [{"display_url": "royalroad.com/fiction/66453/\u2026", "expanded_url": "https://www.royalroad.com/fiction/66453/apocalypse-reborn-as-a-monster-litrpg-evolution", "indices": [73, 96], "url": "https://t.co/Azz8nD0UoZ"}]}}, "followers_count": 52, "location": "", "url": "https://x.com/actualrealyorth", "follow_url": "https://x.com/intent/follow?screen_name=actualrealyorth"}, "url": "https://x.com/actualrealyorth/status/1786630651707314409", "like_url": "https://x.com/intent/like?tweet_id=1786630651707314409", "reply_url": "https://x.com/intent/tweet?in_reply_to=1786630651707314409", "replies": [], "score": 0.1, "thread_score": 0.1, "reply_count": 0, "is_branch": true}, "1786841198189060415": {"created_at": "Sat May 04 19:31:54 +0000 2024", "entities": [{"indices": [14, 40], "type": "text", "text": "Sounds like portable LoRA."}], "favorite_count": 0, "id_str": "1786841198189060415", "in_reply_to_status_id_str": "1786518726537318734", "lang": "en", "user": {"id_str": "52089759", "name": "Antonio Oliveira", "screen_name": "oliveiraacc", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1604258098516037633/KyNO13rH_normal.jpg", "description": "1-on-1 mentorship and fractional CTO services.", "entities": {"description": {"urls": []}}, "followers_count": 187, "location": "Lisbon, Portugal", "url": "https://x.com/oliveiraacc", "follow_url": "https://x.com/intent/follow?screen_name=oliveiraacc"}, "url": "https://x.com/oliveiraacc/status/1786841198189060415", "like_url": "https://x.com/intent/like?tweet_id=1786841198189060415", "reply_url": "https://x.com/intent/tweet?in_reply_to=1786841198189060415", "replies": [], "score": 0.1, "thread_score": 0.1, "reply_count": 0, "is_branch": true}, "1786852045577994702": {"created_at": "Sat May 04 20:15:00 +0000 2024", "entities": [{"indices": [0, 206], "type": "text", "text": "Most interesting thing is when fine tuned on TruthfulQA, the performance for proxy tuned model is better compared to SFT model, as that's better able to retain factual knowledge from its pre-training stage."}], "favorite_count": 3, "id_str": "1786852045577994702", "quoted_status_id_str": "1786518726537318734", "lang": "en", "user": {"id_str": "1055176610134085632", "name": "Harsh Maheshwari", "screen_name": "HarshMheshwari", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1681549874364313601/MbT61BfV_normal.jpg", "description": "Enthusiastic about #GenerativeAI #DataScience \ud83e\udd16 | Constantly curious learner \ud83c\udf31 | Applied scientist 2 at @amazon | Writer at @medium | @IITKGP Graduate", "entities": {"description": {"urls": []}}, "followers_count": 2072, "location": "", "url": "https://x.com/HarshMheshwari", "follow_url": "https://x.com/intent/follow?screen_name=HarshMheshwari"}, "url": "https://x.com/HarshMheshwari/status/1786852045577994702", "like_url": "https://x.com/intent/like?tweet_id=1786852045577994702", "reply_url": "https://x.com/intent/tweet?in_reply_to=1786852045577994702", "replies": [], "score": 0, "thread_score": 0.6, "reply_count": 0, "tweet_type": "Perspective", "location": "on", "is_branch": true}, "1811135369519452192": {"created_at": "Wed Jul 10 20:28:16 +0000 2024", "entities": [{"indices": [0, 243], "type": "text", "text": "Accepted to COLM! \ud83c\udf89 Proxy-tuning achieves finetuning, but at decoding-time! Enables easy customization, adapting to private data, and tuning an arbitrary # of models for the cost of training one proxy.\n\nSuper excited to be a part of the first "}, {"id_str": "1748385374118772741", "indices": [243, 253], "name": "Conference on Language Modeling", "screen_name": "COLM_conf", "type": "mention", "href": "https://x.com/COLM_conf", "text": "@COLM_conf"}, {"indices": [253, 255], "type": "text", "text": " \ud83d\ude00"}], "favorite_count": 125, "id_str": "1811135369519452192", "quoted_status_id_str": "1750549967599804916", "lang": "en", "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1811135369519452192", "like_url": "https://x.com/intent/like?tweet_id=1811135369519452192", "reply_url": "https://x.com/intent/tweet?in_reply_to=1811135369519452192", "replies": [], "score": 0.2, "thread_score": 0.4, "reply_count": 0, "tweet_type": "Teaser", "is_author": true, "is_branch": true}, "1828153656010502415": {"created_at": "Mon Aug 26 19:32:51 +0000 2024", "entities": [{"indices": [0, 33], "type": "text", "text": "Tuning Language Models by Proxy. "}, {"display_url": "arxiv.org/abs/2401.08565", "expanded_url": "https://arxiv.org/abs/2401.08565", "indices": [33, 56], "url": "https://t.co/vcJHbu1OWH", "type": "url", "href": "https://arxiv.org/abs/2401.08565", "text": "arxiv.org/abs/2401.08565"}], "favorite_count": 0, "id_str": "1828153656010502415", "lang": "en", "user": {"id_str": "223641087", "name": "Natural Language Processing Papers", "screen_name": "HEI", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1670846378988257287/wiYGfvHI_normal.jpg", "description": "New Natural Language Processing (includes LLMs) submissions to https://t.co/qq1SHrGj56 (not affiliated with https://t.co/qq1SHrGj56)", "entities": {"description": {"urls": [{"display_url": "arxiv.org", "expanded_url": "http://arxiv.org", "indices": [63, 86], "url": "https://t.co/qq1SHrGj56"}, {"display_url": "arxiv.org", "expanded_url": "http://arxiv.org", "indices": [108, 131], "url": "https://t.co/qq1SHrGj56"}]}, "url": {"urls": [{"display_url": "arxiv.org/list/cs.CL/new", "expanded_url": "https://arxiv.org/list/cs.CL/new", "indices": [0, 23], "url": "https://t.co/CltAIWNjrv"}]}}, "followers_count": 1021, "location": "", "url": "https://x.com/HEI", "follow_url": "https://x.com/intent/follow?screen_name=HEI"}, "url": "https://x.com/HEI/status/1828153656010502415", "like_url": "https://x.com/intent/like?tweet_id=1828153656010502415", "reply_url": "https://x.com/intent/tweet?in_reply_to=1828153656010502415", "replies": [], "score": 0, "thread_score": 0, "reply_count": 0, "is_branch": true}, "1843133644950618159": {"created_at": "Mon Oct 07 03:37:59 +0000 2024", "entities": [{"indices": [0, 33], "type": "text", "text": "very excited to attend the first "}, {"id_str": "1748385374118772741", "indices": [33, 43], "name": "Conference on Language Modeling", "screen_name": "COLM_conf", "type": "mention", "href": "https://x.com/COLM_conf", "text": "@COLM_conf"}, {"indices": [43, 232], "type": "text", "text": "!\ud83e\udd29 I will be presenting proxy-tuning as a spotlight talk\ud83d\udd26 on Wed @ 10am.\n\nI would love to make new friends and chat about decoding-time algorithms, tokenizers, and whatever is on your mind!"}], "favorite_count": 89, "id_str": "1843133644950618159", "quoted_status_id_str": "1750549967599804916", "lang": "en", "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1843133644950618159", "like_url": "https://x.com/intent/like?tweet_id=1843133644950618159", "reply_url": "https://x.com/intent/tweet?in_reply_to=1843133644950618159", "replies": ["1843133857597628889", "1843389856472609153"], "score": 0.2, "thread_score": 0.2, "reply_count": 3, "is_author": true, "is_branch": true}, "1843133857597628889": {"created_at": "Mon Oct 07 03:38:50 +0000 2024", "entities": [{"id_str": "932813494256271361", "indices": [11, 21], "name": "Jiacheng Liu", "screen_name": "liujc1998", "type": "mention", "href": "https://x.com/liujc1998", "text": "@liujc1998"}, {"indices": [21, 99], "type": "text", "text": " is presenting infini-gram in the same oral session, it will be a good time! \ud83d\ude0e"}], "favorite_count": 6, "id_str": "1843133857597628889", "in_reply_to_status_id_str": "1843133644950618159", "lang": "en", "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1843133857597628889", "like_url": "https://x.com/intent/like?tweet_id=1843133857597628889", "reply_url": "https://x.com/intent/tweet?in_reply_to=1843133857597628889", "replies": [], "score": 0.2, "thread_score": 0.2, "reply_count": 0, "is_author": true, "is_branch": true}, "1843389856472609153": {"created_at": "Mon Oct 07 20:36:04 +0000 2024", "entities": [{"indices": [25, 116], "type": "text", "text": "Amazing, congrats! \ud83d\ude42 Just a quick Q -- isn't this pretty much equivalent to e.g. DExperts? "}, {"display_url": "arxiv.org/abs/2105.03023", "expanded_url": "https://arxiv.org/abs/2105.03023", "indices": [116, 139], "url": "https://t.co/wmdolMhfpt", "type": "url", "href": "https://arxiv.org/abs/2105.03023", "text": "arxiv.org/abs/2105.03023"}], "favorite_count": 2, "id_str": "1843389856472609153", "in_reply_to_status_id_str": "1843133644950618159", "lang": "en", "user": {"id_str": "512275659", "name": "Pasquale Minervini is hiring postdocs! \ud83d\ude80", "screen_name": "PMinervini", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1535176863827501056/q8SjC8WM_normal.jpg", "description": "Research in ML/NLP at the U of Edinburgh (tenured faculty @InfAtEd @EdinburghNLP), Co-Founder @Miniml_AI, @ELLISforEurope Scholar, https://t.co/5dUI3EFexo", "entities": {"description": {"urls": [{"display_url": "neuralnoise.com", "expanded_url": "https://www.neuralnoise.com", "indices": [131, 154], "url": "https://t.co/5dUI3EFexo"}]}, "url": {"urls": [{"display_url": "neuralnoise.com", "expanded_url": "https://www.neuralnoise.com", "indices": [0, 23], "url": "https://t.co/5dUI3EFexo"}]}}, "followers_count": 8404, "location": "Edinburgh, United Kingdom", "url": "https://x.com/PMinervini", "follow_url": "https://x.com/intent/follow?screen_name=PMinervini"}, "url": "https://x.com/PMinervini/status/1843389856472609153", "like_url": "https://x.com/intent/like?tweet_id=1843389856472609153", "reply_url": "https://x.com/intent/tweet?in_reply_to=1843389856472609153", "replies": ["1843514974624460943"], "score": 0.4, "thread_score": 0.4, "reply_count": 1, "tweet_type": "Related Work", "location": "related work", "is_branch": true}, "1843514974624460943": {"created_at": "Tue Oct 08 04:53:15 +0000 2024", "entities": [{"indices": [23, 241], "type": "text", "text": "it is a direct application of DExperts!\ud83d\ude42 back then we studied much simpler attributes to steer toward (e.g., positive sentiment), so we thought it was surprising and impactful that it can also achieve black-box tuning!"}], "favorite_count": 1, "id_str": "1843514974624460943", "in_reply_to_status_id_str": "1843389856472609153", "lang": "en", "user": {"id_str": "1197247629136203776", "name": "Alisa Liu", "screen_name": "alisawuffles", "profile_image_url_https": "https://pbs.twimg.com/profile_images/1410025901602058245/NErTT3ki_normal.jpg", "description": "PhD student at @uwcse @uwnlp", "entities": {"description": {"urls": []}, "url": {"urls": [{"display_url": "alisawuffles.github.io", "expanded_url": "https://alisawuffles.github.io/", "indices": [0, 23], "url": "https://t.co/I2EvJHwSvP"}]}}, "followers_count": 1836, "location": "", "url": "https://x.com/alisawuffles", "follow_url": "https://x.com/intent/follow?screen_name=alisawuffles"}, "url": "https://x.com/alisawuffles/status/1843514974624460943", "like_url": "https://x.com/intent/like?tweet_id=1843514974624460943", "reply_url": "https://x.com/intent/tweet?in_reply_to=1843514974624460943", "replies": [], "score": 0.7, "thread_score": 0.2, "reply_count": 0, "is_author": true}}, "locations": {"0": [{"title": "author", "types": ["Overview"], "dimensions": {"width": 612.0, "height": 792.0}, "box": [0, 113.98, 155.75, 120.18]}, {"title": "abstract", "types": ["Overview", "Perspective", "Q&A"], "dimensions": {"width": 612.0, "height": 792.0}, "box": [0, 143.45, 469.8, 224.97]}, {"title": "introduction", "types": ["Overview", "Perspective", "Q&A"], "dimensions": {"width": 612.0, "height": 792.0}, "box": [0, 108.0, 504.39, 477.31]}], "2": [{"title": "method", "types": ["Overview", "Q&A"], "dimensions": {"width": 612.0, "height": 792.0}, "box": [2, 108.0, 504.0, 476.2]}], "4": [{"title": "on", "types": ["Overview", "Perspective"], "dimensions": {"width": 612.0, "height": 792.0}, "box": [4, 108.0, 505.65, 123.9]}], "8": [{"title": "related work", "types": ["Overview", "Related Work", "Resource", "Critique"], "dimensions": {"width": 612.0, "height": 792.0}, "box": [8, 108.0, 505.74, 83.79]}, {"title": "conclusion", "types": ["Overview", "Perspective", "Q&A"], "dimensions": {"width": 612.0, "height": 792.0}, "box": [8, 108.0, 505.74, 572.27]}], "3": [{"title": "instruction-tuning experiments", "types": ["Q&A"], "dimensions": {"width": 612.0, "height": 792.0}, "box": [3, 108.0, 505.65, 456.13]}], "7": [{"title": "case study: proxy-tuning gpt-3.5 for the present", "types": ["Q&A"], "dimensions": {"width": 612.0, "height": 792.0}, "box": [7, 108.0, 505.25, 317.53]}]}, "summaries": {"Resource": {"related work": ["<1752616549347954814> shared the official implementation of the paper, allowing readers to directly experiment with the proxy-tuning method and further explore its capabilities.", "<1747858959023681759> suggested an alternative approach for resource-efficient fine-tuning by using smaller, task-specific models like Llama 2, contrasting with the proxy-tuning method's focus on leveraging large, pre-trained models.", "<1749702066799354301> mentioned ColBERTv2 [[arxiv.org/abs/2112.01488]] for semantic retrieval, which could complement proxy-tuning by enhancing the retrieval of relevant information for specific tasks."]}, "Related Work": {"related work": ["<1784858642732241362> and <1843389856472609153> mentioned DExperts [[aclanthology.org/2021.acl-long.\u2026]] [[arxiv.org/abs/2105.03023]] as a highly related prior work. <1843514974624460943> further clarified that proxy-tuning directly applies the DExperts method to the novel context of black-box tuning for large language models.", "<1748034121383719132> suggested Model Arithmetic [[arxiv.org/abs/2311.14479]] as related work, highlighting an alternative approach to adapting language models.  The ensuing discussion between <1749236068296298904> and <1749380148443427013> further distinguished and compared the two methods."]}, "Critique": {"related work": ["<1748030792624935034> pointed out a similar work on arXiv from October 2023. <1748075477703479741> elaborated on the similarities and minor differences between the two approaches.", "<1748169662196551883> questioned the novelty, citing a 2023 EMNLP paper. <1748202358595817950> acknowledged the similarity but highlighted the frequent occurrence of multiple discoveries in science.", "<1748485259224887353> clarified that their work goes beyond previous research by quantifying effectiveness on benchmarks and exploring domain adaptation and task-specific fine-tuning. <1748485553576907177> thanked <1748202358595817950> for pointing out the connection to DExperts."]}, "Perspective": {"abstract": ["<1748028787995086906> highlighted the potential of proxy-tuning for further improvements in both upstream (data curation) and downstream (finetuning, prompt engineering) tasks, suggesting that base models are becoming sufficiently capable.", "<1748024347183480838> emphasized the shift towards higher-level abstractions in ML, focusing on specifications rather than implementation details, aligning with the proxy-tuning approach."], "introduction": ["<1748027644677914844> likened the proxy-tuning approach to first-order approximations commonly used in physics, suggesting that simpler models can often achieve comparable results to more complex computations.", "<1748025974669901910> praised the benchmark results and discussed the possibility of using techniques like \"Twist Decoding\" to address vocabulary mismatches between models."], "on": ["<1786852045577994702> highlights the surprising result that proxy-tuned models perform better than directly fine-tuned models on TruthfulQA, suggesting better factual knowledge retention."], "conclusion": ["<1784865923309977916> shared their experience of using the proposed method, reporting that the performance deteriorated on serious tasks."]}, "Q&A": {"abstract": ["<1748023768037933546> questioned the GPU efficiency of proxy-tuning for edge devices, given its seemingly higher GPU usage. <1748024634241348048> suggested the main application is R&D efficiency, enabling cost-effective development and boosting larger models.", "<1753173434366861712> analyzed the cost benefits of proxy-tuning, considering the reduced hardware needs for fine-tuning smaller models and quantized inference.", "Other discussions explored the potential of proxy-tuning to replicate the performance gains observed in instruction-tuned models."], "introduction": ["<1748085650664910906> suggests applying the difference between a tuned and untuned 70B model to smaller models for potential improvement."], "method": ["<1749342873039110303> asked if backpropagation is involved in proxy tuning. <1749409290077491209> confirmed that it's not and both smaller models are needed for inference, leading to <1749342873039110303>'s mixed feelings about the method's efficiency.", "<1748030281058288020> wondered why proxy tuning is effective. <1748031001618464839> suggested it's because the difference between base and tuned models is similar across different model sizes.", "<1752368665704411276> clarified the process of combining logits from three models, noting that the delta varies with input and requires three model predictions, impacting speed. <1752373304218759426> drew an analogy with speculative decoding.", "Discussions also explored the applicability of proxy tuning across different model families (<1752374277171458498>) and its potential connection to boosting (<1747628376389550089>). <1748022920008364201> discussed leveraging OpenAI's logit outputs for similar tuning strategies."], "instruction-tuning experiments": ["<1748031547536544076> questioned the effectiveness of applying the proposed method to larger language models like 70B chat. <1748074367114793308> acknowledged the question and suggested that while it might not work optimally due to overcompensation, it would be an interesting experiment."], "case study: proxy-tuning gpt-3.5 for the present": ["<1748039405489516757> questioned if proxy tuning could be used for weak-to-strong generalization, where a smaller model guides a larger one's behavior."], "conclusion": ["<1748068042615976291> inquired about the applicability of proxy-tuning to other ML models equipped with decoders, such as Whisper.", "<1748031659167928553> wondered if proxy-tuning could be employed to counteract backdoors in LLMs, similar to those explored in Anthropic's Sleeper Agents paper."]}}, "context": {"Critique": {"related work": "The authors address the challenge of efficiently fine-tuning large language models (LLMs). They discuss existing methods, including parameter-efficient fine-tuning and decoding-time tuning, and position their work in relation to concurrent research, particularly Mitchell et al. (2024) and Ormazabal et al. (2023), emphasizing their focus on empirical effectiveness and broader applicability."}, "Perspective": {"abstract": "The authors introduce proxy-tuning, a method for adapting large language models (LLMs) without directly modifying their weights. This is achieved by tuning a smaller LLM and applying the difference in predictions between the tuned and untuned smaller models to guide the larger model's output. This method allows for efficient customization of large, potentially proprietary LLMs.", "introduction": "The authors introduce \"proxy-tuning,\" a method to improve large language models (LLMs) without directly modifying their weights. This is achieved by using a smaller, tuned LLM (\"expert\") and its untuned counterpart (\"anti-expert\") to guide the larger model's predictions during decoding.  This approach allows customization even for closed-source models.", "on": "The authors found that proxy-tuning a large language model outperforms direct fine-tuning on TruthfulQA, a benchmark for factual accuracy.  This suggests that proxy-tuning better preserves factual knowledge acquired during pre-training, unlike direct tuning which can sometimes degrade performance on knowledge-intensive tasks.", "conclusion": "The authors propose a method called proxy-tuning, which allows customization of large language models at decoding-time without requiring extensive resources for training. This addresses the challenge of adapting proprietary models to various use cases.  They suggest sharing output probabilities to enable wider use of this technique."}, "Q&A": {"abstract": "The authors introduce proxy-tuning, a method for efficiently customizing large language models (LLMs) without direct access to their parameters. It involves tuning a smaller LLM and using the difference between its tuned and untuned predictions to guide the larger LLM's output, effectively transferring the tuning effect.", "introduction": "The authors introduce \"proxy-tuning,\" a method to improve large language models (LLMs) without directly modifying their weights. This involves using a smaller, tuned LLM (\"expert\") and its untuned counterpart (\"anti-expert\") to guide the larger model's predictions.  The difference between the expert and anti-expert predictions is used to adjust the larger model's output, effectively transferring the benefits of tuning.", "method": "The authors propose proxy-tuning, a method to mimic the behavior of a fine-tuned large language model (M) without altering its parameters. This involves using two smaller models: a base (M-) and a fine-tuned version (M+).  The difference in logits between M- and M+ is added to M's logits, effectively transferring the tuning effect.", "instruction-tuning experiments": "The authors experimented with instruction-tuning language models using a proxy-tuning method. They used LLAMA2 models, including BASE (pretrained on text) and CHAT (further aligned for dialogue) versions, with different parameter sizes (7B, 13B, 70B).  7B-CHAT was used as the expert, 7B-BASE as the anti-expert, and 13B and 70B-BASE models were steered.", "case study: proxy-tuning gpt-3.5 for the present": "The authors explored adapting a large language model (LLM) to more recent data using a technique called proxy-tuning. They tested this on GPT-3.5, whose training data is older, using a multiple-choice question dataset based on recent news.", "conclusion": "The authors introduce proxy-tuning, a decoding-time method for \"tuning\" large language models without altering their weights. This approach enhances accessibility to large LMs and facilitates their adaptation to various applications.  It involves modifying the target model's logits based on the difference between smaller base and fine-tuned models."}}, "quality": {"Resource": {"related work": 0.30000000000000004}, "Related Work": {"related work": 0.4}, "Critique": {"related work": 0.75}, "Perspective": {"conclusion": 0.3, "abstract": 0, "introduction": 0.5, "on": 0}, "Q&A": {"conclusion": 0.4, "method": 0.7, "abstract": 0.9, "introduction": 0.4, "instruction-tuning experiments": 0.6, "case study: proxy-tuning gpt-3.5 for the present": 0.4}}, "titles": {"abstract": {"number": "", "name": "Abstract"}, "introduction": {"number": "1", "name": "Introduction"}, "method": {"number": "2", "name": "Method"}, "instruction-tuning experiments": {"number": "3", "name": "Instruction-Tuning Experiments"}, "on": {"number": "3.2", "name": "Results"}, "case study: proxy-tuning gpt-3.5 for the present": {"number": "7", "name": "Case Study: Proxy-Tuning GPT-3.5 for the Present"}, "related work": {"number": "8", "name": "Related Work"}, "conclusion": {"number": "9", "name": "Conclusion"}}}